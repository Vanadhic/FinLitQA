{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rck9JV_eWlEz"
   },
   "source": [
    "# Task adaptive Fine Tuning with the Custom QA dataset \n",
    "\n",
    "Initialization - Set Runtime type as GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is part of the final Thesis.\n",
    "\n",
    "The models resulting from the preceding LM pre-training steps, FiQA fine-tuning step and SQuAD fine-tuning step are all further fine-tuned with the custom created QA dataset.\n",
    "\n",
    "This step is the second Task adaptive fine-tuning step where the models are fine-tuned to be ready for the downstream Question answering task specifically using custom dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvZ4bjfU2Cpa",
    "outputId": "f1739e41-bb6a-4bf7-ba50-d6e7b5677bb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformers'...\n",
      "remote: Enumerating objects: 93052, done.\u001b[K\n",
      "remote: Counting objects: 100% (385/385), done.\u001b[K\n",
      "remote: Compressing objects: 100% (361/361), done.\u001b[K\n",
      "remote: Total 93052 (delta 122), reused 135 (delta 21), pack-reused 92667\u001b[K\n",
      "Receiving objects: 100% (93052/93052), 78.04 MiB | 22.94 MiB/s, done.\n",
      "Resolving deltas: 100% (67142/67142), done.\n",
      "Processing /content/transformers\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0.dev0) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 479 kB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0.dev0) (2.23.0)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 18.1 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0.dev0) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0.dev0) (1.19.5)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 40.7 MB/s \n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
      "\u001b[K     |████████████████████████████████| 596 kB 48.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0.dev0) (2019.12.20)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0.dev0) (4.8.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.15.0.dev0) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.15.0.dev0) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.15.0.dev0) (3.0.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.15.0.dev0) (3.6.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0.dev0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0.dev0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0.dev0) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.15.0.dev0) (3.0.4)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0.dev0) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0.dev0) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.15.0.dev0) (1.15.0)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for transformers: filename=transformers-4.15.0.dev0-py3-none-any.whl size=3358316 sha256=6ee35ea7a66d45109ba2e46cb841fda6e9f0941423291bcb91c06e118f7d3578\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-e6x9q1cd/wheels/49/62/f4/6730819eed4e6468662b1519bf3bf46419b2335990c77f8767\n",
      "Successfully built transformers\n",
      "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0.dev0\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/transformers\n",
    "!cd /content/transformers && pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRKR7m2m9ECb",
    "outputId": "bea5ec72-3964-4fac-97ad-bd877834bb4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ixLaSr6ky6PV",
    "outputId": "f686a434-7bad-4c09-e328-3e7a5423cb3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 298 kB 9.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 243 kB 47.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 132 kB 48.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 38.4 MB/s \n",
      "\u001b[K     |████████████████████████████████| 160 kB 45.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 192 kB 47.9 MB/s \n",
      "\u001b[K     |████████████████████████████████| 271 kB 50.0 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GpDNjR6l2KLP",
    "outputId": "6e939120-51ef-4f17-f7b4-1c3cb2df1036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec 21 17:08:35 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   42C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBE2jUBLX3y9"
   },
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/utils_qa.py\n",
    "# !wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/trainer_qa.py\n",
    "# !wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/question-answering/run_qa.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1uk_QxCrlbo"
   },
   "source": [
    "# Fine Tuning and evaluation on Custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Vlwe5wiLr3Y"
   },
   "source": [
    "## Model 1 - bert-base-uncased-sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rVKQP0jqK1Z",
    "outputId": "67abf834-796b-4d50-e615-e44a476c87a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 17:56:56 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 17:56:56 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/runs/Dec20_17-56-56_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 17:56:56 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 17:56:56 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n",
      "100% 2/2 [00:00<00:00, 2666.44it/s]\n",
      "12/20/2021 17:56:56 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
      "12/20/2021 17:56:57 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
      "100% 2/2 [00:00<00:00, 88.75it/s]\n",
      "12/20/2021 17:56:57 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
      "12/20/2021 17:56:57 - INFO - datasets.builder - Generating split train\n",
      "12/20/2021 17:56:57 - INFO - datasets.builder - Generating split validation\n",
      "12/20/2021 17:56:57 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n",
      "100% 2/2 [00:00<00:00, 290.51it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 17:56:57,657 >> loading configuration file /content/drive/MyDrive/Models/bert-base-uncased-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 17:56:57,658 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/bert-base-uncased-sq\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 17:56:57,892 >> Didn't find file /content/drive/MyDrive/Models/bert-base-uncased-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 17:56:57,894 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-sq/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 17:56:57,894 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 17:56:57,895 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 17:56:57,895 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 17:56:57,895 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 17:56:58,455 >> loading weights file /content/drive/MyDrive/Models/bert-base-uncased-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 17:57:03,993 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 17:57:03,994 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/bert-base-uncased-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 17:57:06 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-eb6e4857cbf9ffec.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:03<00:00,  3.13s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 17:57:07 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-a32ca7be806e51f7.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:03<00:00,  3.62s/ba]\n",
      "12/20/2021 17:57:11 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/squad_v2.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpmnldl68y\n",
      "Downloading: 6.49kB [00:00, 6.23MB/s]       \n",
      "12/20/2021 17:57:11 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/squad_v2.py in cache at /root/.cache/huggingface/datasets/downloads/0b3aa4626c2b631dc45b2bf3f7c968f6165a3ad6b3c7792564675873e2d22fd2.55618b68ec0f2e152f32610f6601b047ef46121780662ab1208d50ddcfbcafed.py\n",
      "12/20/2021 17:57:11 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/0b3aa4626c2b631dc45b2bf3f7c968f6165a3ad6b3c7792564675873e2d22fd2.55618b68ec0f2e152f32610f6601b047ef46121780662ab1208d50ddcfbcafed.py\n",
      "12/20/2021 17:57:11 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/evaluate.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpkp9ewsoj\n",
      "Downloading: 11.3kB [00:00, 11.8MB/s]       \n",
      "12/20/2021 17:57:11 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/evaluate.py in cache at /root/.cache/huggingface/datasets/downloads/6447ac1aeba6266d8ff009449c27843a180b7359a4d1b0594f2836e2726a0380.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n",
      "12/20/2021 17:57:11 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/6447ac1aeba6266d8ff009449c27843a180b7359a4d1b0594f2836e2726a0380.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n",
      "[INFO|trainer.py:1208] 2021-12-20 17:57:22,631 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 17:57:22,631 >>   Num examples = 3463\n",
      "[INFO|trainer.py:1210] 2021-12-20 17:57:22,631 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-20 17:57:22,631 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 17:57:22,631 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 17:57:22,631 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 17:57:22,631 >>   Total optimization steps = 866\n",
      " 23% 200/866 [01:11<03:56,  2.82it/s][INFO|trainer.py:549] 2021-12-20 17:58:33,920 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 17:58:33,922 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 17:58:33,922 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 17:58:33,922 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.00it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.73it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.59it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.14it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  9.00it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.89it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.81it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:15,  6.57it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:13,  7.03it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:13,  7.40it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:12,  7.64it/s]\u001b[A\n",
      " 15% 17/112 [00:02<00:12,  7.89it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.07it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:11,  8.21it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:11,  8.30it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.37it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.34it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.38it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.43it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.45it/s]\u001b[A\n",
      " 23% 26/112 [00:03<00:10,  8.47it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:10,  8.47it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.44it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.46it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.43it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.45it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.48it/s]\u001b[A\n",
      " 30% 34/112 [00:04<00:09,  8.50it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.50it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.47it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.47it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.47it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.40it/s]\u001b[A\n",
      " 38% 43/112 [00:05<00:08,  8.43it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:08,  8.46it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.41it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.44it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.46it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.47it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.48it/s]\u001b[A\n",
      " 46% 51/112 [00:06<00:07,  8.44it/s]\u001b[A\n",
      " 46% 52/112 [00:06<00:07,  8.45it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.46it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 54% 60/112 [00:07<00:06,  8.47it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.48it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.47it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.47it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 61% 68/112 [00:08<00:05,  8.41it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.44it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.46it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.49it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.40it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.44it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.46it/s]\u001b[A\n",
      " 69% 77/112 [00:09<00:04,  8.47it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:04,  8.48it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.45it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 76% 85/112 [00:10<00:03,  8.46it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.48it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.45it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 84% 94/112 [00:11<00:02,  8.47it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.48it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.38it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.42it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.43it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 91% 102/112 [00:12<00:01,  8.44it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.45it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.41it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.45it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.45it/s]\u001b[A\n",
      " 99% 111/112 [00:13<00:00,  8.46it/s]\u001b[A12/20/2021 17:58:48 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 81.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 79.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 85.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 39/221 [00:00<00:01, 93.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 49/221 [00:00<00:01, 91.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 59/221 [00:00<00:02, 80.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 68/221 [00:00<00:01, 79.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 77/221 [00:00<00:01, 79.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 86/221 [00:01<00:01, 78.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 94/221 [00:01<00:01, 77.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 102/221 [00:01<00:01, 77.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 110/221 [00:01<00:01, 75.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 118/221 [00:01<00:01, 75.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 126/221 [00:01<00:01, 74.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 72.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 142/221 [00:01<00:01, 73.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 150/221 [00:01<00:00, 71.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 158/221 [00:02<00:00, 70.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 166/221 [00:02<00:00, 68.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 173/221 [00:02<00:00, 65.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 180/221 [00:02<00:00, 62.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 188/221 [00:02<00:00, 67.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 196/221 [00:02<00:00, 70.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 204/221 [00:02<00:00, 71.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 212/221 [00:02<00:00, 72.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 74.87it/s]\n",
      "12/20/2021 17:58:51 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_predictions.json.\n",
      "12/20/2021 17:58:51 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 17:58:51 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 17:58:51 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "\n",
      "{'eval_exact': 28.959276018099548, 'eval_f1': 47.1955787317607, 'eval_total': 221, 'eval_HasAns_exact': 28.959276018099548, 'eval_HasAns_f1': 47.1955787317607, 'eval_HasAns_total': 221, 'eval_best_exact': 28.959276018099548, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 47.1955787317607, 'eval_best_f1_thresh': 0.0, 'epoch': 0.46}\n",
      "\n",
      " 23% 200/866 [01:28<03:56,  2.82it/s]\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 17:58:51,541 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 17:58:51,566 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 17:58:53,849 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 17:58:53,855 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 17:58:53,860 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-200/special_tokens_map.json\n",
      " 46% 400/866 [02:48<02:46,  2.80it/s][INFO|trainer.py:549] 2021-12-20 18:00:11,451 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:00:11,453 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:00:11,453 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:00:11,453 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.05it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.65it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.56it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.11it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.97it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.86it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.76it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.45it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.43it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.45it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.46it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.47it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.46it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.46it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:10,  8.48it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.43it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.43it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.45it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.47it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.47it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.47it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.43it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.45it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.45it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:08,  8.47it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.48it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.48it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.46it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.47it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.40it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.44it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.45it/s]\u001b[A\n",
      " 46% 52/112 [00:06<00:07,  8.43it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.39it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.43it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.46it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.53it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.52it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.39it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.37it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.41it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.35it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.40it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.42it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.44it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.46it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.48it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.48it/s]\u001b[A12/20/2021 18:00:25 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 76.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 75.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 24/221 [00:00<00:02, 77.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 35/221 [00:00<00:02, 88.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 44/221 [00:00<00:01, 88.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 53/221 [00:00<00:02, 82.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:01, 80.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 71/221 [00:00<00:01, 77.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 79/221 [00:00<00:01, 77.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 87/221 [00:01<00:01, 75.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 95/221 [00:01<00:01, 75.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 103/221 [00:01<00:01, 75.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 111/221 [00:01<00:01, 72.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 119/221 [00:01<00:01, 73.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 127/221 [00:01<00:01, 70.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 135/221 [00:01<00:01, 71.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:01, 71.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:02<00:01, 69.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 158/221 [00:02<00:00, 68.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 165/221 [00:02<00:00, 66.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 172/221 [00:02<00:00, 64.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 179/221 [00:02<00:00, 62.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 186/221 [00:02<00:00, 64.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 194/221 [00:02<00:00, 66.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 202/221 [00:02<00:00, 69.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 210/221 [00:02<00:00, 67.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:03<00:00, 72.55it/s]\n",
      "12/20/2021 18:00:28 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:00:28 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:00:28 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:00:29 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "\n",
      "{'eval_exact': 33.0316742081448, 'eval_f1': 54.07153826698584, 'eval_total': 221, 'eval_HasAns_exact': 33.0316742081448, 'eval_HasAns_f1': 54.07153826698584, 'eval_HasAns_total': 221, 'eval_best_exact': 33.0316742081448, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 54.07153826698584, 'eval_best_f1_thresh': 0.0, 'epoch': 0.92}\n",
      "\n",
      " 46% 400/866 [03:06<02:46,  2.80it/s]\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:00:29,059 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:00:29,089 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:00:31,501 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:00:31,515 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:00:31,520 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:00:36,277 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 1.0666, 'learning_rate': 1.0578034682080927e-05, 'epoch': 1.15}\n",
      " 69% 600/866 [04:26<01:34,  2.81it/s][INFO|trainer.py:549] 2021-12-20 18:01:48,758 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:01:48,760 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:01:48,760 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:01:48,760 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.05it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.74it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.58it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.15it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  9.01it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.90it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.81it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.74it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 16% 18/112 [00:01<00:10,  8.58it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.48it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.45it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.48it/s]\u001b[A\n",
      " 31% 35/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 52/112 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 62% 69/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 77% 86/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.42it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.49it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 92% 103/112 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.54it/s]\u001b[A12/20/2021 18:02:03 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 83.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 80.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 83.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 38/221 [00:00<00:01, 92.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 88.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 57/221 [00:00<00:01, 82.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 66/221 [00:00<00:01, 81.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 75/221 [00:00<00:01, 77.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 83/221 [00:01<00:01, 77.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 91/221 [00:01<00:01, 77.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 99/221 [00:01<00:01, 74.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 108/221 [00:01<00:01, 76.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 116/221 [00:01<00:01, 76.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 124/221 [00:01<00:01, 75.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 132/221 [00:01<00:01, 73.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 140/221 [00:01<00:01, 75.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 148/221 [00:01<00:00, 73.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 156/221 [00:02<00:00, 72.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 164/221 [00:02<00:00, 69.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 171/221 [00:02<00:00, 66.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 178/221 [00:02<00:00, 65.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 185/221 [00:02<00:00, 65.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 194/221 [00:02<00:00, 70.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 202/221 [00:02<00:00, 71.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 210/221 [00:02<00:00, 73.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 75.36it/s]\n",
      "12/20/2021 18:02:05 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:02:05 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:02:06 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:02:06 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "\n",
      "{'eval_exact': 35.74660633484163, 'eval_f1': 57.34888617726352, 'eval_total': 221, 'eval_HasAns_exact': 35.74660633484163, 'eval_HasAns_f1': 57.34888617726352, 'eval_HasAns_total': 221, 'eval_best_exact': 35.74660633484163, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 57.34888617726352, 'eval_best_f1_thresh': 0.0, 'epoch': 1.39}\n",
      "\n",
      " 69% 600/866 [04:43<01:34,  2.81it/s]\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:02:06,149 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:02:06,158 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:02:08,085 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:02:08,091 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:02:08,097 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:02:12,565 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 92% 800/866 [06:01<00:23,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:03:23,856 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:03:23,858 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:03:23,858 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:03:23,858 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.05it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.75it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.55it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.13it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.99it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.88it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.80it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.73it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 16% 18/112 [00:01<00:10,  8.58it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 31% 35/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 46% 52/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.45it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 62% 69/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 77% 86/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.48it/s]\u001b[A\n",
      " 92% 103/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.53it/s]\u001b[A12/20/2021 18:03:38 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 78.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 77.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 24/221 [00:00<00:02, 78.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 35/221 [00:00<00:02, 90.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 45/221 [00:00<00:01, 89.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 54/221 [00:00<00:01, 84.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 63/221 [00:00<00:01, 82.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 72/221 [00:00<00:01, 80.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 81/221 [00:00<00:01, 78.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 89/221 [00:01<00:01, 77.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 97/221 [00:01<00:01, 75.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 75.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 113/221 [00:01<00:01, 76.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 121/221 [00:01<00:01, 70.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 129/221 [00:01<00:01, 72.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 137/221 [00:01<00:01, 73.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 145/221 [00:01<00:01, 71.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 153/221 [00:01<00:00, 71.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:02<00:00, 69.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 168/221 [00:02<00:00, 65.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:02<00:00, 64.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 182/221 [00:02<00:00, 64.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 189/221 [00:02<00:00, 65.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 197/221 [00:02<00:00, 69.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 205/221 [00:02<00:00, 71.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 213/221 [00:02<00:00, 70.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 73.91it/s]\n",
      "12/20/2021 18:03:41 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:03:41 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:03:41 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:03:41 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 35.294117647058826, 'eval_f1': 55.30018772950486, 'eval_total': 221, 'eval_HasAns_exact': 35.294117647058826, 'eval_HasAns_f1': 55.30018772950486, 'eval_HasAns_total': 221, 'eval_best_exact': 35.294117647058826, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 55.30018772950486, 'eval_best_f1_thresh': 0.0, 'epoch': 1.85}\n",
      " 92% 800/866 [06:18<00:23,  2.82it/s]\n",
      "100% 112/112 [00:17<00:00,  8.53it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:03:41,289 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:03:41,296 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:03:43,197 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:03:43,204 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:03:43,209 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:03:47,218 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "100% 866/866 [06:48<00:00,  2.85it/s][INFO|trainer.py:1429] 2021-12-20 18:04:10,825 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 408.1943, 'train_samples_per_second': 16.967, 'train_steps_per_second': 2.122, 'train_loss': 0.8824944793489734, 'epoch': 2.0}\n",
      "100% 866/866 [06:48<00:00,  2.12it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 18:04:10,833 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:04:10,855 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:04:13,087 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:04:13,092 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:04:13,097 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =     0.8825\n",
      "  train_runtime            = 0:06:48.19\n",
      "  train_samples            =       3463\n",
      "  train_samples_per_second =     16.967\n",
      "  train_steps_per_second   =      2.122\n",
      "12/20/2021 18:04:13 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 18:04:13,171 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:04:13,173 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:04:13,173 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:04:13,173 >>   Batch size = 8\n",
      " 99% 111/112 [00:13<00:00,  7.70it/s]12/20/2021 18:04:28 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  3% 7/221 [00:00<00:03, 63.30it/s]\u001b[A\n",
      "  6% 14/221 [00:00<00:03, 55.39it/s]\u001b[A\n",
      "  9% 20/221 [00:00<00:04, 47.67it/s]\u001b[A\n",
      " 12% 26/221 [00:00<00:03, 49.70it/s]\u001b[A\n",
      " 16% 35/221 [00:00<00:03, 60.46it/s]\u001b[A\n",
      " 19% 42/221 [00:00<00:02, 62.22it/s]\u001b[A\n",
      " 22% 49/221 [00:00<00:02, 62.07it/s]\u001b[A\n",
      " 25% 56/221 [00:00<00:02, 57.99it/s]\u001b[A\n",
      " 29% 63/221 [00:01<00:02, 57.82it/s]\u001b[A\n",
      " 32% 70/221 [00:01<00:02, 58.34it/s]\u001b[A\n",
      " 34% 76/221 [00:01<00:02, 58.09it/s]\u001b[A\n",
      " 37% 82/221 [00:01<00:02, 52.55it/s]\u001b[A\n",
      " 40% 88/221 [00:01<00:02, 53.83it/s]\u001b[A\n",
      " 43% 94/221 [00:01<00:02, 51.71it/s]\u001b[A\n",
      " 45% 100/221 [00:01<00:02, 51.35it/s]\u001b[A\n",
      " 48% 106/221 [00:01<00:02, 52.94it/s]\u001b[A\n",
      " 51% 112/221 [00:02<00:02, 51.72it/s]\u001b[A\n",
      " 54% 119/221 [00:02<00:01, 56.59it/s]\u001b[A\n",
      " 57% 127/221 [00:02<00:01, 61.31it/s]\u001b[A\n",
      " 61% 135/221 [00:02<00:01, 65.28it/s]\u001b[A\n",
      " 64% 142/221 [00:02<00:01, 64.68it/s]\u001b[A\n",
      " 68% 150/221 [00:02<00:01, 66.19it/s]\u001b[A\n",
      " 71% 158/221 [00:02<00:00, 67.65it/s]\u001b[A\n",
      " 75% 165/221 [00:02<00:00, 66.04it/s]\u001b[A\n",
      " 78% 172/221 [00:02<00:00, 64.30it/s]\u001b[A\n",
      " 81% 179/221 [00:03<00:00, 62.18it/s]\u001b[A\n",
      " 85% 187/221 [00:03<00:00, 66.11it/s]\u001b[A\n",
      " 88% 195/221 [00:03<00:00, 68.96it/s]\u001b[A\n",
      " 92% 203/221 [00:03<00:00, 70.02it/s]\u001b[A\n",
      " 95% 211/221 [00:03<00:00, 70.64it/s]\u001b[A\n",
      "100% 221/221 [00:03<00:00, 61.01it/s]\n",
      "12/20/2021 18:04:32 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:04:32 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:04:32 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:04:32 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 112/112 [00:19<00:00,  5.83it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     2.0\n",
      "  eval_HasAns_exact      = 35.2941\n",
      "  eval_HasAns_f1         = 55.2127\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 35.2941\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 55.2127\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 35.2941\n",
      "  eval_f1                = 55.2127\n",
      "  eval_samples           =     892\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 18:04:32,897 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/bert-base-uncased-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/bert-base-uncased-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPZgrk1o9f_v"
   },
   "source": [
    "## Model 1 - bert-base-uncased-sq - Evaluation Only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sACp6f69f_6",
    "outputId": "e530713e-aa2a-4c78-fc09-05cf84b7e766"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/21/2021 17:08:57 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/21/2021 17:08:57 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-sq/runs/Dec21_17-08-56_b81a4c299d8a,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-sq/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/bert-base-uncased-sq/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/21/2021 17:08:57 - WARNING - datasets.builder - Using custom data configuration default-ffa96d8b15b57461\n",
      "12/21/2021 17:08:57 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-ffa96d8b15b57461/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-ffa96d8b15b57461/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n",
      "100% 1/1 [00:00<00:00, 2600.31it/s]\n",
      "12/21/2021 17:08:57 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
      "12/21/2021 17:08:57 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
      "100% 1/1 [00:00<00:00, 84.78it/s]\n",
      "12/21/2021 17:08:57 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
      "12/21/2021 17:08:57 - INFO - datasets.builder - Generating split validation\n",
      "12/21/2021 17:08:58 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-ffa96d8b15b57461/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n",
      "100% 1/1 [00:00<00:00, 164.06it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-21 17:08:59,798 >> loading configuration file /content/drive/MyDrive/Models/bert-base-uncased-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-21 17:08:59,799 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/bert-base-uncased-sq\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-21 17:09:00,162 >> Didn't find file /content/drive/MyDrive/Models/bert-base-uncased-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 17:09:00,164 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-sq/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 17:09:00,164 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 17:09:00,164 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 17:09:00,164 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 17:09:00,164 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-21 17:09:00,768 >> loading weights file /content/drive/MyDrive/Models/bert-base-uncased-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-21 17:09:08,010 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-21 17:09:08,010 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/bert-base-uncased-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/21/2021 17:09:08 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-ffa96d8b15b57461/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-fc8d9ded112be269.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:03<00:00,  3.93s/ba]\n",
      "12/21/2021 17:09:12 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/squad_v2.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmp80q8674d\n",
      "Downloading: 6.49kB [00:00, 8.09MB/s]       \n",
      "12/21/2021 17:09:12 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/squad_v2.py in cache at /root/.cache/huggingface/datasets/downloads/0b3aa4626c2b631dc45b2bf3f7c968f6165a3ad6b3c7792564675873e2d22fd2.55618b68ec0f2e152f32610f6601b047ef46121780662ab1208d50ddcfbcafed.py\n",
      "12/21/2021 17:09:12 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/0b3aa4626c2b631dc45b2bf3f7c968f6165a3ad6b3c7792564675873e2d22fd2.55618b68ec0f2e152f32610f6601b047ef46121780662ab1208d50ddcfbcafed.py\n",
      "12/21/2021 17:09:13 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/evaluate.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpt96jzxq_\n",
      "Downloading: 11.3kB [00:00, 11.0MB/s]       \n",
      "12/21/2021 17:09:13 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/evaluate.py in cache at /root/.cache/huggingface/datasets/downloads/6447ac1aeba6266d8ff009449c27843a180b7359a4d1b0594f2836e2726a0380.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n",
      "12/21/2021 17:09:13 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/6447ac1aeba6266d8ff009449c27843a180b7359a4d1b0594f2836e2726a0380.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n",
      "12/21/2021 17:09:25 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-21 17:09:25,525 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 17:09:25,528 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 17:09:25,528 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-21 17:09:25,528 >>   Batch size = 8\n",
      " 99% 111/112 [00:12<00:00,  8.56it/s]12/21/2021 17:09:39 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 9/221 [00:00<00:02, 82.86it/s]\u001b[A\n",
      "  8% 18/221 [00:00<00:02, 81.20it/s]\u001b[A\n",
      " 13% 28/221 [00:00<00:02, 86.89it/s]\u001b[A\n",
      " 18% 40/221 [00:00<00:01, 96.54it/s]\u001b[A\n",
      " 23% 50/221 [00:00<00:01, 89.86it/s]\u001b[A\n",
      " 27% 60/221 [00:00<00:01, 84.03it/s]\u001b[A\n",
      " 31% 69/221 [00:00<00:01, 81.98it/s]\u001b[A\n",
      " 35% 78/221 [00:00<00:01, 79.15it/s]\u001b[A\n",
      " 39% 86/221 [00:01<00:01, 78.69it/s]\u001b[A\n",
      " 43% 95/221 [00:01<00:01, 78.18it/s]\u001b[A\n",
      " 47% 103/221 [00:01<00:01, 77.05it/s]\u001b[A\n",
      " 50% 111/221 [00:01<00:01, 77.68it/s]\u001b[A\n",
      " 54% 119/221 [00:01<00:01, 76.41it/s]\u001b[A\n",
      " 57% 127/221 [00:01<00:01, 76.45it/s]\u001b[A\n",
      " 61% 135/221 [00:01<00:01, 74.84it/s]\u001b[A\n",
      " 65% 143/221 [00:01<00:01, 74.48it/s]\u001b[A\n",
      " 68% 151/221 [00:01<00:00, 73.20it/s]\u001b[A\n",
      " 72% 159/221 [00:02<00:00, 71.55it/s]\u001b[A\n",
      " 76% 167/221 [00:02<00:00, 66.31it/s]\u001b[A\n",
      " 79% 174/221 [00:02<00:00, 64.70it/s]\u001b[A\n",
      " 82% 181/221 [00:02<00:00, 63.77it/s]\u001b[A\n",
      " 86% 189/221 [00:02<00:00, 67.11it/s]\u001b[A\n",
      " 90% 198/221 [00:02<00:00, 71.46it/s]\u001b[A\n",
      " 93% 206/221 [00:02<00:00, 70.73it/s]\u001b[A\n",
      "100% 221/221 [00:02<00:00, 75.32it/s]\n",
      "12/21/2021 17:09:42 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq/eval_predictions.json.\n",
      "12/21/2021 17:09:42 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq/eval_nbest_predictions.json.\n",
      "12/21/2021 17:09:42 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-sq/eval_null_odds.json.\n",
      "12/21/2021 17:09:43 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 112/112 [00:17<00:00,  6.48it/s]\n",
      "***** eval metrics *****\n",
      "  eval_HasAns_exact      = 26.2443\n",
      "  eval_HasAns_f1         = 45.9002\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 26.2443\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 45.9002\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 26.2443\n",
      "  eval_f1                = 45.9002\n",
      "  eval_samples           =     892\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-21 17:09:43,443 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/bert-base-uncased-sq \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/bert-base-uncased-sq/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TshsIyoYhiS"
   },
   "source": [
    "## Model 2 - bert-base-uncased-fiqa-sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x-7GPX-2Yhij",
    "outputId": "60e4143a-430e-4d72-fcc0-3eb9134e141b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 18:05:14 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 18:05:14 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/runs/Dec20_18-05-14_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 18:05:15 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 18:05:15 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/20/2021 18:05:15 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/20/2021 18:05:15 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/20/2021 18:05:15 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "100% 2/2 [00:00<00:00, 111.87it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 18:05:15,560 >> loading configuration file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 18:05:15,561 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 18:05:15,812 >> Didn't find file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:05:15,814 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:05:15,814 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:05:15,814 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:05:15,814 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:05:15,814 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 18:05:16,708 >> loading weights file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 18:05:22,147 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 18:05:22,147 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:05:24 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-1f4d8512cc51f9cf.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:03<00:00,  3.08s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:05:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-2f3b3f8e2c049569.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:03<00:00,  3.61s/ba]\n",
      "[INFO|trainer.py:1208] 2021-12-20 18:05:33,440 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 18:05:33,440 >>   Num examples = 3463\n",
      "[INFO|trainer.py:1210] 2021-12-20 18:05:33,440 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-20 18:05:33,440 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 18:05:33,440 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 18:05:33,440 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 18:05:33,440 >>   Total optimization steps = 866\n",
      " 23% 200/866 [01:11<03:56,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:06:44,598 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:06:44,600 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:06:44,600 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:06:44,600 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 16.98it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.57it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.53it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.11it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.97it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.87it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.79it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.73it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.49it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.43it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.47it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.46it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 31% 35/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.43it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.46it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 52/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.48it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 62% 69/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.43it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 77% 86/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 92% 103/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.40it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.45it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.41it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.44it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.47it/s]\u001b[A12/20/2021 18:06:58 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 80.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 75.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 80.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 38/221 [00:00<00:02, 89.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 89.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 57/221 [00:00<00:01, 85.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 66/221 [00:00<00:01, 84.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 75/221 [00:00<00:01, 83.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 84/221 [00:01<00:01, 80.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 93/221 [00:01<00:01, 80.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 102/221 [00:01<00:01, 76.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 110/221 [00:01<00:01, 75.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 118/221 [00:01<00:01, 75.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 126/221 [00:01<00:01, 76.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 76.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:01, 77.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 75.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 159/221 [00:02<00:00, 73.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 167/221 [00:02<00:00, 69.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:02<00:00, 66.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 182/221 [00:02<00:00, 65.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 191/221 [00:02<00:00, 70.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 200/221 [00:02<00:00, 73.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 75.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 77.09it/s]\n",
      "12/20/2021 18:07:01 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:07:01 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:07:01 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:07:01 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 25.339366515837103, 'eval_f1': 41.04027403199884, 'eval_total': 221, 'eval_HasAns_exact': 25.339366515837103, 'eval_HasAns_f1': 41.04027403199884, 'eval_HasAns_total': 221, 'eval_best_exact': 25.339366515837103, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 41.04027403199884, 'eval_best_f1_thresh': 0.0, 'epoch': 0.46}\n",
      " 23% 200/866 [01:28<03:56,  2.82it/s]\n",
      "100% 112/112 [00:17<00:00,  8.47it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:07:01,940 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:07:01,949 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:07:04,253 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:07:04,258 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:07:04,263 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-200/special_tokens_map.json\n",
      " 46% 400/866 [02:47<02:46,  2.80it/s][INFO|trainer.py:549] 2021-12-20 18:08:21,024 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:08:21,026 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:08:21,026 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:08:21,026 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.12it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.77it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.62it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.16it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  9.00it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.88it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.78it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.50it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.51it/s]\u001b[A\n",
      " 16% 18/112 [00:01<00:11,  8.50it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:10,  8.45it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.42it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.45it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.46it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 46% 52/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.49it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.44it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.46it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.51it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.43it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.42it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.45it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:04,  8.48it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.52it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.47it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.48it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.48it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.46it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.41it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.43it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.46it/s]\u001b[A12/20/2021 18:08:35 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 80.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 78.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 82.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 38/221 [00:00<00:02, 90.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 89.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 57/221 [00:00<00:01, 84.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 66/221 [00:00<00:01, 82.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 75/221 [00:00<00:01, 77.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 83/221 [00:01<00:01, 77.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 91/221 [00:01<00:01, 76.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 99/221 [00:01<00:01, 75.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 107/221 [00:01<00:01, 76.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 115/221 [00:01<00:01, 74.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 123/221 [00:01<00:01, 71.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 131/221 [00:01<00:01, 72.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 139/221 [00:01<00:01, 73.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 147/221 [00:01<00:01, 69.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 155/221 [00:02<00:00, 70.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 163/221 [00:02<00:01, 50.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:02<00:00, 53.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 55.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 57.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 193/221 [00:02<00:00, 64.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 68.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 68.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:03<00:00, 71.14it/s]\n",
      "12/20/2021 18:08:38 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:08:38 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:08:38 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:08:38 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 33.0316742081448, 'eval_f1': 54.158906764549165, 'eval_total': 221, 'eval_HasAns_exact': 33.0316742081448, 'eval_HasAns_f1': 54.158906764549165, 'eval_HasAns_total': 221, 'eval_best_exact': 33.0316742081448, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 54.158906764549165, 'eval_best_f1_thresh': 0.0, 'epoch': 0.92}\n",
      " 46% 400/866 [03:05<02:46,  2.80it/s]\n",
      "100% 112/112 [00:17<00:00,  8.46it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:08:38,662 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:08:38,670 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:08:41,033 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:08:41,389 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:08:41,402 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:08:45,977 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 1.0724, 'learning_rate': 1.0578034682080927e-05, 'epoch': 1.15}\n",
      " 69% 600/866 [04:24<01:34,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:09:58,454 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:09:58,456 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:09:58,456 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:09:58,456 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.08it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.75it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.62it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.12it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.98it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.87it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.79it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.73it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 16% 18/112 [00:01<00:10,  8.56it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 31% 35/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.49it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 46% 52/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.46it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 62% 69/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.44it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.40it/s]\u001b[A\n",
      " 77% 86/112 [00:09<00:03,  8.44it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.47it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.47it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.44it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.47it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.49it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 92% 103/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.50it/s]\u001b[A12/20/2021 18:10:12 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 80.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 76.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 79.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 38/221 [00:00<00:02, 89.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 47/221 [00:00<00:01, 87.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 56/221 [00:00<00:01, 83.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 65/221 [00:00<00:01, 82.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 77.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 82/221 [00:01<00:01, 75.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 90/221 [00:01<00:01, 75.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 76.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 74.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 74.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 122/221 [00:01<00:01, 75.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:01, 73.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:01, 74.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 146/221 [00:01<00:01, 70.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 154/221 [00:02<00:00, 69.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:02<00:00, 68.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 168/221 [00:02<00:00, 65.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:02<00:00, 64.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 182/221 [00:02<00:00, 62.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 191/221 [00:02<00:00, 67.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 199/221 [00:02<00:00, 70.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 207/221 [00:02<00:00, 72.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 74.02it/s]\n",
      "12/20/2021 18:10:15 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:10:15 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:10:15 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:10:15 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 34.841628959276015, 'eval_f1': 54.36173454761952, 'eval_total': 221, 'eval_HasAns_exact': 34.841628959276015, 'eval_HasAns_f1': 54.36173454761952, 'eval_HasAns_total': 221, 'eval_best_exact': 34.841628959276015, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 54.36173454761952, 'eval_best_f1_thresh': 0.0, 'epoch': 1.39}\n",
      " 69% 600/866 [04:42<01:34,  2.82it/s]\n",
      "100% 112/112 [00:17<00:00,  8.50it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:10:15,933 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:10:15,961 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:10:18,062 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:10:18,068 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:10:18,073 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:10:22,849 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 92% 800/866 [06:00<00:23,  2.81it/s][INFO|trainer.py:549] 2021-12-20 18:11:34,130 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:11:34,133 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:11:34,133 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:11:34,133 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.05it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.73it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.60it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.15it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  9.00it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.88it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.79it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.72it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.52it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.52it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.53it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 16% 18/112 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.46it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.44it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.46it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.50it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.40it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.44it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.46it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.43it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.47it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.46it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 46% 52/112 [00:06<00:07,  8.51it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.42it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.43it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.47it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.51it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.41it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.44it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.40it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:04,  8.44it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.41it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.45it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.49it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.42it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.37it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.41it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.43it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.45it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.45it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.45it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.41it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.44it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.45it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.46it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.48it/s]\u001b[A12/20/2021 18:11:48 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 74.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 17/221 [00:00<00:02, 75.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 25/221 [00:00<00:02, 77.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:02, 86.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 46/221 [00:00<00:01, 87.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 55/221 [00:00<00:01, 83.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 64/221 [00:00<00:01, 81.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 73/221 [00:00<00:01, 79.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 82/221 [00:01<00:01, 77.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 90/221 [00:01<00:01, 76.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 75.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 74.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 74.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 122/221 [00:01<00:01, 73.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:01, 73.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:01, 73.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 146/221 [00:01<00:01, 73.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 154/221 [00:02<00:00, 72.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 162/221 [00:02<00:00, 69.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:02<00:00, 66.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 63.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 65.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 193/221 [00:02<00:00, 69.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 71.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 72.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 74.18it/s]\n",
      "12/20/2021 18:11:51 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:11:51 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:11:51 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:11:51 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 33.484162895927604, 'eval_f1': 54.6455414272345, 'eval_total': 221, 'eval_HasAns_exact': 33.484162895927604, 'eval_HasAns_f1': 54.6455414272345, 'eval_HasAns_total': 221, 'eval_best_exact': 33.484162895927604, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 54.6455414272345, 'eval_best_f1_thresh': 0.0, 'epoch': 1.85}\n",
      " 92% 800/866 [06:18<00:23,  2.81it/s]\n",
      "100% 112/112 [00:17<00:00,  8.48it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:11:51,650 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:11:51,657 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:11:53,864 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:11:53,939 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:11:53,944 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:11:58,366 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "100% 866/866 [06:48<00:00,  2.88it/s][INFO|trainer.py:1429] 2021-12-20 18:12:21,947 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 408.507, 'train_samples_per_second': 16.954, 'train_steps_per_second': 2.12, 'train_loss': 0.8891521920783415, 'epoch': 2.0}\n",
      "100% 866/866 [06:48<00:00,  2.12it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 18:12:21,960 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:12:21,967 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:12:23,997 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:12:24,003 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:12:24,018 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =     0.8892\n",
      "  train_runtime            = 0:06:48.50\n",
      "  train_samples            =       3463\n",
      "  train_samples_per_second =     16.954\n",
      "  train_steps_per_second   =       2.12\n",
      "12/20/2021 18:12:24 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 18:12:24,308 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:12:24,310 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:12:24,311 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:12:24,311 >>   Batch size = 8\n",
      " 99% 111/112 [00:13<00:00,  8.21it/s]12/20/2021 18:12:39 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  3% 6/221 [00:00<00:03, 59.06it/s]\u001b[A\n",
      "  6% 13/221 [00:00<00:03, 61.02it/s]\u001b[A\n",
      "  9% 20/221 [00:00<00:03, 58.57it/s]\u001b[A\n",
      " 13% 28/221 [00:00<00:02, 64.73it/s]\u001b[A\n",
      " 17% 38/221 [00:00<00:02, 73.15it/s]\u001b[A\n",
      " 21% 46/221 [00:00<00:02, 69.28it/s]\u001b[A\n",
      " 24% 54/221 [00:00<00:02, 68.78it/s]\u001b[A\n",
      " 28% 61/221 [00:00<00:02, 63.76it/s]\u001b[A\n",
      " 31% 68/221 [00:01<00:02, 64.56it/s]\u001b[A\n",
      " 34% 75/221 [00:01<00:02, 56.89it/s]\u001b[A\n",
      " 37% 81/221 [00:01<00:02, 57.44it/s]\u001b[A\n",
      " 39% 87/221 [00:01<00:02, 56.77it/s]\u001b[A\n",
      " 42% 93/221 [00:01<00:02, 54.43it/s]\u001b[A\n",
      " 45% 100/221 [00:01<00:02, 57.43it/s]\u001b[A\n",
      " 48% 106/221 [00:01<00:02, 54.54it/s]\u001b[A\n",
      " 51% 113/221 [00:01<00:01, 57.27it/s]\u001b[A\n",
      " 54% 120/221 [00:01<00:01, 59.19it/s]\u001b[A\n",
      " 57% 126/221 [00:02<00:01, 56.21it/s]\u001b[A\n",
      " 60% 133/221 [00:02<00:01, 58.11it/s]\u001b[A\n",
      " 63% 139/221 [00:02<00:01, 56.02it/s]\u001b[A\n",
      " 66% 145/221 [00:02<00:01, 55.52it/s]\u001b[A\n",
      " 68% 151/221 [00:02<00:01, 54.70it/s]\u001b[A\n",
      " 71% 157/221 [00:02<00:01, 54.35it/s]\u001b[A\n",
      " 74% 163/221 [00:02<00:01, 52.69it/s]\u001b[A\n",
      " 76% 169/221 [00:02<00:01, 49.55it/s]\u001b[A\n",
      " 79% 175/221 [00:03<00:00, 48.78it/s]\u001b[A\n",
      " 82% 182/221 [00:03<00:00, 53.08it/s]\u001b[A\n",
      " 86% 191/221 [00:03<00:00, 60.21it/s]\u001b[A\n",
      " 90% 198/221 [00:03<00:00, 62.57it/s]\u001b[A\n",
      " 93% 205/221 [00:03<00:00, 64.08it/s]\u001b[A\n",
      " 96% 213/221 [00:03<00:00, 67.66it/s]\u001b[A\n",
      "100% 221/221 [00:03<00:00, 59.87it/s]\n",
      "12/20/2021 18:12:43 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:12:43 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:12:43 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:12:43 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 112/112 [00:18<00:00,  5.90it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     2.0\n",
      "  eval_HasAns_exact      = 34.3891\n",
      "  eval_HasAns_f1         = 55.3385\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 34.3891\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 55.3385\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 34.3891\n",
      "  eval_f1                = 55.3385\n",
      "  eval_samples           =     892\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 18:12:43,770 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/bert-base-uncased-fiqa-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXTDufFIygbw"
   },
   "source": [
    "## Model 3 - bert-base-uncased-flm-sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GZB2NogSygbz",
    "outputId": "0b06e6f5-e906-45c9-ac50-c9f073f682b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 18:13:52 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 18:13:52 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/runs/Dec20_18-13-52_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 18:13:53 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 18:13:53 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/20/2021 18:13:53 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/20/2021 18:13:53 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/20/2021 18:13:53 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "100% 2/2 [00:00<00:00, 142.05it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 18:13:53,397 >> loading configuration file /content/drive/MyDrive/Models/bert-base-uncased-flm-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 18:13:53,398 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/bert-base-uncased-flm-sq\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 18:13:53,699 >> Didn't find file /content/drive/MyDrive/Models/bert-base-uncased-flm-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:13:53,701 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-flm-sq/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:13:53,701 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-flm-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:13:53,701 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:13:53,701 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-flm-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:13:53,701 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-flm-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 18:13:54,297 >> loading weights file /content/drive/MyDrive/Models/bert-base-uncased-flm-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 18:14:00,612 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 18:14:00,612 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/bert-base-uncased-flm-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:14:03 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-2cdde056c9f896c6.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:03<00:00,  3.39s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:14:04 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-80f3a3d59e415569.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:03<00:00,  3.66s/ba]\n",
      "[INFO|trainer.py:1208] 2021-12-20 18:14:12,365 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 18:14:12,365 >>   Num examples = 3463\n",
      "[INFO|trainer.py:1210] 2021-12-20 18:14:12,365 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-20 18:14:12,365 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 18:14:12,366 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 18:14:12,366 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 18:14:12,366 >>   Total optimization steps = 866\n",
      " 23% 200/866 [01:10<03:55,  2.83it/s][INFO|trainer.py:549] 2021-12-20 18:15:23,219 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:15:23,222 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:15:23,222 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:15:23,222 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.04it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.60it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.52it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.06it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.93it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.82it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.73it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.53it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.45it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:11,  8.45it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.39it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.43it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.45it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.47it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.41it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:10,  8.44it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.46it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.48it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.39it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.42it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:09,  8.43it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.37it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.41it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.43it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.46it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.47it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.49it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:08,  8.50it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.45it/s]\u001b[A\n",
      " 46% 52/112 [00:06<00:07,  8.48it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.39it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.42it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.45it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.47it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.47it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.46it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.43it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.45it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.46it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.47it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.49it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.49it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.49it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.45it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.46it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:04,  8.48it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.45it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.37it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.41it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.44it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.47it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.47it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.48it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.46it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.47it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.50it/s]\u001b[A12/20/2021 18:15:37 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 79.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 77.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 25/221 [00:00<00:02, 79.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:02, 89.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 46/221 [00:00<00:01, 88.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 55/221 [00:00<00:01, 85.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 64/221 [00:00<00:01, 79.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 73/221 [00:00<00:01, 76.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 81/221 [00:01<00:01, 76.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 89/221 [00:01<00:01, 76.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 97/221 [00:01<00:01, 75.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 74.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 113/221 [00:01<00:01, 75.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 121/221 [00:01<00:01, 75.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 129/221 [00:01<00:01, 75.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 137/221 [00:01<00:01, 74.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 145/221 [00:01<00:01, 71.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 153/221 [00:01<00:00, 71.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:02<00:00, 69.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 169/221 [00:02<00:00, 66.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 176/221 [00:02<00:00, 64.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 183/221 [00:02<00:00, 64.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 192/221 [00:02<00:00, 69.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 200/221 [00:02<00:00, 70.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 208/221 [00:02<00:00, 71.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 74.26it/s]\n",
      "12/20/2021 18:15:40 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:15:40 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:15:40 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:15:40 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 29.41176470588235, 'eval_f1': 47.077082206670525, 'eval_total': 221, 'eval_HasAns_exact': 29.41176470588235, 'eval_HasAns_f1': 47.077082206670525, 'eval_HasAns_total': 221, 'eval_best_exact': 29.41176470588235, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 47.077082206670525, 'eval_best_f1_thresh': 0.0, 'epoch': 0.46}\n",
      " 23% 200/866 [01:28<03:55,  2.83it/s]\n",
      "100% 112/112 [00:17<00:00,  8.50it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:15:40,754 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:15:40,761 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:15:43,585 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:15:43,591 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:15:43,595 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-200/special_tokens_map.json\n",
      " 46% 400/866 [02:48<02:44,  2.83it/s][INFO|trainer.py:549] 2021-12-20 18:17:00,872 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:17:00,874 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:17:00,874 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:17:00,874 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.11it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.68it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.50it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.09it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.95it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.83it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.76it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.52it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.51it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.43it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.46it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 31% 35/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 52/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.42it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.39it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.43it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.48it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 62% 69/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.41it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.44it/s]\u001b[A\n",
      " 77% 86/112 [00:09<00:03,  8.38it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.43it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.43it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.50it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.46it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 92% 103/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.42it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.46it/s]\u001b[A12/20/2021 18:17:15 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 79.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 17/221 [00:00<00:02, 79.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 26/221 [00:00<00:02, 83.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 37/221 [00:00<00:01, 93.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 47/221 [00:00<00:01, 88.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 56/221 [00:00<00:01, 84.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 65/221 [00:00<00:01, 82.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 78.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 82/221 [00:01<00:01, 76.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 90/221 [00:01<00:01, 77.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 76.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 76.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 77.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 122/221 [00:01<00:01, 73.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:01, 74.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:01, 75.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 146/221 [00:01<00:01, 73.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 154/221 [00:01<00:00, 72.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 162/221 [00:02<00:00, 68.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 169/221 [00:02<00:00, 66.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 176/221 [00:02<00:00, 65.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 183/221 [00:02<00:00, 65.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 192/221 [00:02<00:00, 68.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 71.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 73.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 75.32it/s]\n",
      "12/20/2021 18:17:18 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:17:18 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:17:18 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:17:18 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 33.0316742081448, 'eval_f1': 53.54256347237909, 'eval_total': 221, 'eval_HasAns_exact': 33.0316742081448, 'eval_HasAns_f1': 53.54256347237909, 'eval_HasAns_total': 221, 'eval_best_exact': 33.0316742081448, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 53.54256347237909, 'eval_best_f1_thresh': 0.0, 'epoch': 0.92}\n",
      " 46% 400/866 [03:06<02:44,  2.83it/s]\n",
      "100% 112/112 [00:17<00:00,  8.46it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:17:18,474 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:17:18,481 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:17:20,901 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:17:20,907 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:17:20,912 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:17:25,794 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 1.0653, 'learning_rate': 1.0578034682080927e-05, 'epoch': 1.15}\n",
      " 69% 600/866 [04:25<01:34,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:18:37,860 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:18:37,863 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:18:37,863 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:18:37,863 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.12it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.77it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.61it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.14it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.93it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.83it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.75it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.66it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 16% 18/112 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 31% 35/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:08,  8.42it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.45it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.47it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.42it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.45it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.47it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 46% 52/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.44it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.48it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 62% 69/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.42it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.40it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.44it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 77% 86/112 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.45it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.40it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.39it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.42it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.40it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.43it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.47it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.45it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.44it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.35it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.40it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.43it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.38it/s]\u001b[A12/20/2021 18:18:52 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 80.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 77.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 81.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 38/221 [00:00<00:02, 90.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 88.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 57/221 [00:00<00:01, 84.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 66/221 [00:00<00:01, 81.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 75/221 [00:00<00:01, 77.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 83/221 [00:01<00:01, 76.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 91/221 [00:01<00:01, 76.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 99/221 [00:01<00:01, 74.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 107/221 [00:01<00:01, 74.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 115/221 [00:01<00:01, 73.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 123/221 [00:01<00:01, 73.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 131/221 [00:01<00:01, 74.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 139/221 [00:01<00:01, 75.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 147/221 [00:01<00:01, 72.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 155/221 [00:02<00:00, 70.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 163/221 [00:02<00:00, 68.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:02<00:00, 65.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 64.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 65.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 192/221 [00:02<00:00, 67.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 72.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 73.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 74.51it/s]\n",
      "12/20/2021 18:18:55 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:18:55 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:18:55 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:18:55 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 33.484162895927604, 'eval_f1': 55.97694455165995, 'eval_total': 221, 'eval_HasAns_exact': 33.484162895927604, 'eval_HasAns_f1': 55.97694455165995, 'eval_HasAns_total': 221, 'eval_best_exact': 33.484162895927604, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 55.97694455165995, 'eval_best_f1_thresh': 0.0, 'epoch': 1.39}\n",
      " 69% 600/866 [04:42<01:34,  2.82it/s]\n",
      "100% 112/112 [00:17<00:00,  8.38it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:18:55,388 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:18:55,395 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:18:57,965 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:18:57,971 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:18:57,979 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:19:02,664 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 92% 800/866 [06:01<00:23,  2.83it/s][INFO|trainer.py:549] 2021-12-20 18:20:13,702 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:20:13,704 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:20:13,704 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:20:13,704 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 16.45it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.53it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.52it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.10it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.96it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.86it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.74it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.69it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.53it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.51it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.52it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:10,  8.45it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.42it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.45it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.38it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.42it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.41it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.45it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.49it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.43it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.46it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 46% 52/112 [00:06<00:07,  8.52it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.42it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.43it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.47it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.45it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.49it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.43it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.46it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:04,  8.49it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.40it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.44it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.48it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.42it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.53it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.43it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.41it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.44it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.50it/s]\u001b[A12/20/2021 18:20:28 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 73.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 74.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 24/221 [00:00<00:02, 76.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 35/221 [00:00<00:02, 88.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 45/221 [00:00<00:01, 90.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 55/221 [00:00<00:01, 84.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 64/221 [00:00<00:01, 81.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 73/221 [00:00<00:01, 79.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 81/221 [00:01<00:01, 77.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 89/221 [00:01<00:01, 75.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 97/221 [00:01<00:01, 74.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 74.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 113/221 [00:01<00:01, 74.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 121/221 [00:01<00:01, 72.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 129/221 [00:01<00:01, 73.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 137/221 [00:01<00:01, 75.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 145/221 [00:01<00:01, 72.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 153/221 [00:01<00:00, 72.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:02<00:00, 69.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 168/221 [00:02<00:00, 65.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:02<00:00, 62.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 182/221 [00:02<00:00, 62.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 190/221 [00:02<00:00, 65.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 199/221 [00:02<00:00, 70.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 207/221 [00:02<00:00, 72.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 74.08it/s]\n",
      "12/20/2021 18:20:31 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:20:31 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:20:31 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:20:31 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 33.93665158371041, 'eval_f1': 56.76312570509507, 'eval_total': 221, 'eval_HasAns_exact': 33.93665158371041, 'eval_HasAns_f1': 56.76312570509507, 'eval_HasAns_total': 221, 'eval_best_exact': 33.93665158371041, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 56.76312570509507, 'eval_best_f1_thresh': 0.0, 'epoch': 1.85}\n",
      " 92% 800/866 [06:18<00:23,  2.83it/s]\n",
      "100% 112/112 [00:17<00:00,  8.50it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:20:31,252 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:20:31,259 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:20:33,434 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:20:33,442 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:20:33,448 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:20:38,061 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "100% 866/866 [06:49<00:00,  2.88it/s][INFO|trainer.py:1429] 2021-12-20 18:21:01,812 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 409.4465, 'train_samples_per_second': 16.916, 'train_steps_per_second': 2.115, 'train_loss': 0.8810298294173102, 'epoch': 2.0}\n",
      "100% 866/866 [06:49<00:00,  2.12it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 18:21:01,830 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:21:01,836 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:21:03,989 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:21:03,995 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:21:04,000 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =      0.881\n",
      "  train_runtime            = 0:06:49.44\n",
      "  train_samples            =       3463\n",
      "  train_samples_per_second =     16.916\n",
      "  train_steps_per_second   =      2.115\n",
      "12/20/2021 18:21:04 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 18:21:04,075 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:21:04,077 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:21:04,078 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:21:04,078 >>   Batch size = 8\n",
      " 99% 111/112 [00:13<00:00,  7.93it/s]12/20/2021 18:21:20 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 5/221 [00:00<00:05, 41.60it/s]\u001b[A\n",
      "  5% 10/221 [00:00<00:05, 37.53it/s]\u001b[A\n",
      "  6% 14/221 [00:00<00:05, 38.32it/s]\u001b[A\n",
      "  9% 19/221 [00:00<00:05, 39.87it/s]\u001b[A\n",
      " 11% 25/221 [00:00<00:04, 44.18it/s]\u001b[A\n",
      " 14% 31/221 [00:00<00:03, 48.88it/s]\u001b[A\n",
      " 17% 37/221 [00:00<00:03, 51.72it/s]\u001b[A\n",
      " 20% 45/221 [00:00<00:02, 59.91it/s]\u001b[A\n",
      " 24% 52/221 [00:01<00:02, 60.96it/s]\u001b[A\n",
      " 27% 59/221 [00:01<00:02, 59.39it/s]\u001b[A\n",
      " 29% 65/221 [00:01<00:02, 56.09it/s]\u001b[A\n",
      " 32% 71/221 [00:01<00:02, 56.68it/s]\u001b[A\n",
      " 35% 77/221 [00:01<00:02, 55.93it/s]\u001b[A\n",
      " 38% 83/221 [00:01<00:02, 52.95it/s]\u001b[A\n",
      " 41% 90/221 [00:01<00:02, 54.22it/s]\u001b[A\n",
      " 43% 96/221 [00:01<00:02, 53.86it/s]\u001b[A\n",
      " 46% 102/221 [00:01<00:02, 51.24it/s]\u001b[A\n",
      " 49% 109/221 [00:02<00:02, 53.98it/s]\u001b[A\n",
      " 52% 115/221 [00:02<00:02, 49.85it/s]\u001b[A\n",
      " 55% 121/221 [00:02<00:01, 50.09it/s]\u001b[A\n",
      " 57% 127/221 [00:02<00:01, 49.88it/s]\u001b[A\n",
      " 60% 133/221 [00:02<00:01, 52.42it/s]\u001b[A\n",
      " 63% 140/221 [00:02<00:01, 56.12it/s]\u001b[A\n",
      " 66% 146/221 [00:02<00:01, 53.67it/s]\u001b[A\n",
      " 69% 153/221 [00:02<00:01, 55.94it/s]\u001b[A\n",
      " 72% 159/221 [00:03<00:01, 54.15it/s]\u001b[A\n",
      " 75% 165/221 [00:03<00:01, 51.94it/s]\u001b[A\n",
      " 77% 171/221 [00:03<00:00, 52.42it/s]\u001b[A\n",
      " 80% 177/221 [00:03<00:00, 50.95it/s]\u001b[A\n",
      " 83% 183/221 [00:03<00:00, 48.57it/s]\u001b[A\n",
      " 86% 190/221 [00:03<00:00, 52.61it/s]\u001b[A\n",
      " 90% 198/221 [00:03<00:00, 57.17it/s]\u001b[A\n",
      " 92% 204/221 [00:03<00:00, 57.81it/s]\u001b[A\n",
      " 95% 211/221 [00:03<00:00, 58.77it/s]\u001b[A\n",
      "100% 221/221 [00:04<00:00, 53.29it/s]\n",
      "12/20/2021 18:21:24 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:21:24 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:21:24 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:21:24 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 112/112 [00:20<00:00,  5.48it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     2.0\n",
      "  eval_HasAns_exact      = 34.3891\n",
      "  eval_HasAns_f1         = 56.9335\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 34.3891\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 56.9335\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 34.3891\n",
      "  eval_f1                = 56.9335\n",
      "  eval_samples           =     892\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 18:21:25,039 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/bert-base-uncased-flm-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/bert-base-uncased-flm-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhRnh7e66__J"
   },
   "source": [
    "## Model 4 - bert-base-uncased-fiqa-flm-sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1qBVd4Fk6__c",
    "outputId": "2c5217ab-b845-4ad0-afb3-c0e98bac683a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 18:22:08 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 18:22:08 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/runs/Dec20_18-22-08_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 18:22:08 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 18:22:08 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/20/2021 18:22:08 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/20/2021 18:22:08 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/20/2021 18:22:08 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "100% 2/2 [00:00<00:00, 600.47it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 18:22:09,171 >> loading configuration file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 18:22:09,172 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq\",\n",
      "  \"architectures\": [\n",
      "    \"BertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 18:22:09,412 >> Didn't find file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:22:09,414 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:22:09,414 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:22:09,414 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:22:09,414 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:22:09,414 >> loading file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 18:22:09,990 >> loading weights file /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 18:22:15,123 >> All model checkpoint weights were used when initializing BertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 18:22:15,123 >> All the weights of BertForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:22:18 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-b5a15e6f200e3f82.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:03<00:00,  3.23s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:22:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-28c9fdab1c383615.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:03<00:00,  3.78s/ba]\n",
      "[INFO|trainer.py:1208] 2021-12-20 18:22:26,935 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 18:22:26,935 >>   Num examples = 3463\n",
      "[INFO|trainer.py:1210] 2021-12-20 18:22:26,935 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-20 18:22:26,936 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 18:22:26,936 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 18:22:26,936 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 18:22:26,936 >>   Total optimization steps = 866\n",
      " 23% 200/866 [01:11<03:58,  2.79it/s][INFO|trainer.py:549] 2021-12-20 18:23:38,520 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:23:38,522 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:23:38,522 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:23:38,522 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 16.95it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.63it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.51it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.08it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.94it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.84it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.74it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.53it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.51it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.51it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.45it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.47it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:10,  8.48it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.40it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.38it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.41it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.44it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.46it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.48it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.49it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.49it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.44it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.40it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.42it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.44it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.46it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:08,  8.49it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.48it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.42it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.45it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.47it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.48it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.48it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.38it/s]\u001b[A\n",
      " 46% 52/112 [00:06<00:07,  8.42it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.46it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.46it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.46it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.49it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.38it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.42it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.44it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.46it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.47it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.49it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.40it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:04,  8.43it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.44it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.37it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.41it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.44it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.48it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.46it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.48it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.40it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.43it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.45it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.48it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.50it/s]\u001b[A12/20/2021 18:23:52 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 79.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 78.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 25/221 [00:00<00:02, 80.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:02, 91.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 46/221 [00:00<00:01, 91.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 56/221 [00:00<00:01, 86.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 65/221 [00:00<00:01, 79.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 79.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 82/221 [00:01<00:01, 77.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 90/221 [00:01<00:01, 77.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 77.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 76.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 76.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 122/221 [00:01<00:01, 76.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:01, 76.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:01, 74.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 146/221 [00:01<00:01, 73.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 154/221 [00:01<00:00, 72.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 162/221 [00:02<00:00, 70.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:02<00:00, 67.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 64.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 65.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 192/221 [00:02<00:00, 69.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 73.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 72.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 75.70it/s]\n",
      "12/20/2021 18:23:55 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:23:55 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:23:55 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:23:56 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 30.76923076923077, 'eval_f1': 47.84025570684176, 'eval_total': 221, 'eval_HasAns_exact': 30.76923076923077, 'eval_HasAns_f1': 47.84025570684176, 'eval_HasAns_total': 221, 'eval_best_exact': 30.76923076923077, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 47.84025570684176, 'eval_best_f1_thresh': 0.0, 'epoch': 0.46}\n",
      " 23% 200/866 [01:29<03:58,  2.79it/s]\n",
      "100% 112/112 [00:17<00:00,  8.50it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:23:56,014 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:23:56,021 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:23:58,433 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:23:58,907 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:23:58,912 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-200/special_tokens_map.json\n",
      " 46% 400/866 [02:49<02:46,  2.80it/s][INFO|trainer.py:549] 2021-12-20 18:25:16,856 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:25:16,858 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:25:16,859 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:25:16,859 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 16.88it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.57it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.46it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.04it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.91it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.80it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.71it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.66it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.47it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.48it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.47it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.38it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.42it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.44it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.45it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.45it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.45it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.43it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:10,  8.42it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.43it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.44it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.46it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.40it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.41it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.43it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.44it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.45it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:09,  8.44it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.40it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.42it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.43it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.45it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.44it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.43it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.44it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:08,  8.45it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.46it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.46it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.47it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.40it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.42it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.44it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.45it/s]\u001b[A\n",
      " 46% 52/112 [00:06<00:07,  8.45it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.42it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.46it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.46it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.39it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.42it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.44it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.44it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.34it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.38it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.41it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.43it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.44it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.46it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.46it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.41it/s]\u001b[A\n",
      " 69% 77/112 [00:09<00:04,  8.43it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:04,  8.45it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.45it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.40it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.43it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.43it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.33it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.37it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:03,  8.31it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.36it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.39it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.41it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.42it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.43it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.44it/s]\u001b[A\n",
      " 84% 94/112 [00:11<00:02,  8.45it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.47it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.43it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.44it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.44it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.43it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.40it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.41it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.35it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.38it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.41it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.42it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.44it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.44it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.43it/s]\u001b[A\n",
      " 99% 111/112 [00:13<00:00,  8.45it/s]\u001b[A12/20/2021 18:25:31 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 79.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 77.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 25/221 [00:00<00:02, 80.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:02, 90.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 46/221 [00:00<00:01, 90.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 56/221 [00:00<00:02, 81.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 65/221 [00:00<00:01, 81.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 78.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 82/221 [00:01<00:01, 77.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 90/221 [00:01<00:01, 76.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 77.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 75.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 75.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 122/221 [00:01<00:01, 75.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:01, 73.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:01, 74.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 146/221 [00:01<00:01, 73.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 154/221 [00:02<00:00, 71.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 162/221 [00:02<00:00, 69.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:02<00:00, 67.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 66.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 65.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 193/221 [00:02<00:00, 69.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 69.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 208/221 [00:02<00:00, 50.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:03<00:00, 71.42it/s]\n",
      "12/20/2021 18:25:34 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:25:34 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:25:34 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:25:34 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 35.294117647058826, 'eval_f1': 55.643010655276335, 'eval_total': 221, 'eval_HasAns_exact': 35.294117647058826, 'eval_HasAns_f1': 55.643010655276335, 'eval_HasAns_total': 221, 'eval_best_exact': 35.294117647058826, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 55.643010655276335, 'eval_best_f1_thresh': 0.0, 'epoch': 0.92}\n",
      " 46% 400/866 [03:07<02:46,  2.80it/s]\n",
      "100% 112/112 [00:17<00:00,  8.45it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:25:34,595 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:25:34,603 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:25:37,198 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:25:37,204 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:25:37,209 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:25:42,251 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 1.0653, 'learning_rate': 1.0578034682080927e-05, 'epoch': 1.15}\n",
      " 69% 600/866 [04:28<01:35,  2.79it/s][INFO|trainer.py:549] 2021-12-20 18:26:55,118 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:26:55,121 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:26:55,121 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:26:55,121 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.08it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.76it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.59it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.13it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.98it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.86it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.78it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.71it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.66it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.46it/s]\u001b[A\n",
      " 16% 18/112 [00:02<00:11,  8.44it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.46it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.47it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.44it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.45it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:10,  8.46it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.41it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.44it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.48it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.42it/s]\u001b[A\n",
      " 31% 35/112 [00:04<00:09,  8.45it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.45it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.45it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.46it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.47it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.50it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:08,  8.41it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.39it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.43it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.47it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.40it/s]\u001b[A\n",
      " 46% 52/112 [00:06<00:07,  8.44it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.46it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.44it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.33it/s]\u001b[A\n",
      " 62% 69/112 [00:08<00:05,  8.34it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:05,  8.33it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.36it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.38it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.39it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.28it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.33it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.36it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.38it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:04,  8.37it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.33it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.36it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.40it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.43it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.44it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.46it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 77% 86/112 [00:10<00:03,  8.49it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.43it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.47it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.41it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.40it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.43it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.44it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.45it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.45it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.43it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.45it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.48it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.47it/s]\u001b[A\n",
      " 92% 103/112 [00:12<00:01,  8.48it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.46it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.47it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.39it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.41it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.44it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.46it/s]\u001b[A\n",
      " 99% 111/112 [00:13<00:00,  8.47it/s]\u001b[A12/20/2021 18:27:09 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 78.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 77.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 24/221 [00:00<00:02, 76.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 35/221 [00:00<00:02, 86.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20% 44/221 [00:00<00:02, 86.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 53/221 [00:00<00:01, 84.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:02, 78.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 70/221 [00:00<00:02, 72.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 78/221 [00:01<00:01, 73.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 86/221 [00:01<00:01, 74.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 94/221 [00:01<00:01, 74.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 102/221 [00:01<00:01, 75.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 110/221 [00:01<00:01, 74.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 118/221 [00:01<00:01, 73.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 126/221 [00:01<00:01, 74.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 74.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 142/221 [00:01<00:01, 73.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 150/221 [00:01<00:01, 70.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 158/221 [00:02<00:00, 69.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 166/221 [00:02<00:00, 66.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 173/221 [00:02<00:00, 65.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 180/221 [00:02<00:00, 64.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 188/221 [00:02<00:00, 66.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 196/221 [00:02<00:00, 69.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 204/221 [00:02<00:00, 71.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 212/221 [00:02<00:00, 69.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:03<00:00, 73.12it/s]\n",
      "12/20/2021 18:27:12 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:27:12 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:27:12 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:27:12 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 37.55656108597285, 'eval_f1': 57.33395418199089, 'eval_total': 221, 'eval_HasAns_exact': 37.55656108597285, 'eval_HasAns_f1': 57.33395418199089, 'eval_HasAns_total': 221, 'eval_best_exact': 37.55656108597285, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 57.33395418199089, 'eval_best_f1_thresh': 0.0, 'epoch': 1.39}\n",
      " 69% 600/866 [04:45<01:35,  2.79it/s]\n",
      "100% 112/112 [00:17<00:00,  8.47it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:27:12,730 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:27:12,736 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:27:15,005 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:27:15,464 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:27:15,469 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:27:19,994 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 92% 800/866 [06:04<00:23,  2.80it/s][INFO|trainer.py:549] 2021-12-20 18:28:31,650 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:28:31,652 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:28:31,652 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:28:31,652 >>   Batch size = 8\n",
      "\n",
      "  0% 0/112 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/112 [00:00<00:06, 17.10it/s]\u001b[A\n",
      "  4% 4/112 [00:00<00:10, 10.75it/s]\u001b[A\n",
      "  5% 6/112 [00:00<00:11,  9.50it/s]\u001b[A\n",
      "  7% 8/112 [00:00<00:11,  9.09it/s]\u001b[A\n",
      "  8% 9/112 [00:00<00:11,  8.97it/s]\u001b[A\n",
      "  9% 10/112 [00:01<00:11,  8.86it/s]\u001b[A\n",
      " 10% 11/112 [00:01<00:11,  8.78it/s]\u001b[A\n",
      " 11% 12/112 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 12% 13/112 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 12% 14/112 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 13% 15/112 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 14% 16/112 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 15% 17/112 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 16% 18/112 [00:01<00:10,  8.56it/s]\u001b[A\n",
      " 17% 19/112 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 18% 20/112 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 19% 21/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 20% 22/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 21% 23/112 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 21% 24/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 22% 25/112 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 23% 26/112 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 24% 27/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 25% 28/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 26% 29/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 27% 30/112 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 28% 31/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 29% 32/112 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 29% 33/112 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 30% 34/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 31% 35/112 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 32% 36/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 33% 37/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 34% 38/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 35% 39/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 36% 40/112 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 37% 41/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 38% 42/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 38% 43/112 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 39% 44/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 40% 45/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 41% 46/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 42% 47/112 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 43% 48/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 44% 49/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 45% 50/112 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 46% 51/112 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 46% 52/112 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 47% 53/112 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 48% 54/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 49% 55/112 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 50% 56/112 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 51% 57/112 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 52% 58/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 53% 59/112 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 54% 60/112 [00:06<00:06,  8.41it/s]\u001b[A\n",
      " 54% 61/112 [00:07<00:06,  8.44it/s]\u001b[A\n",
      " 55% 62/112 [00:07<00:05,  8.41it/s]\u001b[A\n",
      " 56% 63/112 [00:07<00:05,  8.44it/s]\u001b[A\n",
      " 57% 64/112 [00:07<00:05,  8.46it/s]\u001b[A\n",
      " 58% 65/112 [00:07<00:05,  8.47it/s]\u001b[A\n",
      " 59% 66/112 [00:07<00:05,  8.39it/s]\u001b[A\n",
      " 60% 67/112 [00:07<00:05,  8.44it/s]\u001b[A\n",
      " 61% 68/112 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 62% 69/112 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 62% 70/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 63% 71/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 64% 72/112 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 65% 73/112 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 66% 74/112 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 67% 75/112 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 68% 76/112 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 69% 77/112 [00:08<00:04,  8.49it/s]\u001b[A\n",
      " 70% 78/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 71% 79/112 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 71% 80/112 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 72% 81/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 73% 82/112 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 74% 83/112 [00:09<00:03,  8.45it/s]\u001b[A\n",
      " 75% 84/112 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 76% 85/112 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 77% 86/112 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 78% 87/112 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 79% 88/112 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 79% 89/112 [00:10<00:02,  8.43it/s]\u001b[A\n",
      " 80% 90/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 81% 91/112 [00:10<00:02,  8.47it/s]\u001b[A\n",
      " 82% 92/112 [00:10<00:02,  8.43it/s]\u001b[A\n",
      " 83% 93/112 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 84% 94/112 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 85% 95/112 [00:11<00:02,  8.49it/s]\u001b[A\n",
      " 86% 96/112 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 87% 97/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 88% 98/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 88% 99/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 89% 100/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 90% 101/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 91% 102/112 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 92% 103/112 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 93% 104/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 94% 105/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 95% 106/112 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 96% 107/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 96% 108/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 97% 109/112 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 98% 110/112 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 99% 111/112 [00:12<00:00,  8.54it/s]\u001b[A12/20/2021 18:28:46 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 80.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 78.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 82.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 37/221 [00:00<00:02, 86.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 47/221 [00:00<00:01, 88.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 56/221 [00:00<00:02, 80.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 65/221 [00:00<00:01, 79.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 77.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 82/221 [00:01<00:01, 74.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 90/221 [00:01<00:01, 75.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 73.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 74.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 73.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 122/221 [00:01<00:01, 73.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:01, 74.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:01, 75.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 146/221 [00:01<00:01, 71.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 154/221 [00:02<00:00, 72.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 162/221 [00:02<00:00, 70.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:02<00:00, 65.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 63.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 63.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 192/221 [00:02<00:00, 66.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 70.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 72.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 73.90it/s]\n",
      "12/20/2021 18:28:49 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:28:49 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:28:49 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:28:49 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 38.914027149321264, 'eval_f1': 59.19584379604189, 'eval_total': 221, 'eval_HasAns_exact': 38.914027149321264, 'eval_HasAns_f1': 59.19584379604189, 'eval_HasAns_total': 221, 'eval_best_exact': 38.914027149321264, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 59.19584379604189, 'eval_best_f1_thresh': 0.0, 'epoch': 1.85}\n",
      " 92% 800/866 [06:22<00:23,  2.80it/s]\n",
      "100% 112/112 [00:17<00:00,  8.54it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:28:49,155 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:28:49,161 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:28:51,319 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:28:51,325 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:28:51,330 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:28:56,575 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "100% 866/866 [06:53<00:00,  2.85it/s][INFO|trainer.py:1429] 2021-12-20 18:29:20,281 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 413.3455, 'train_samples_per_second': 16.756, 'train_steps_per_second': 2.095, 'train_loss': 0.8789484495378806, 'epoch': 2.0}\n",
      "100% 866/866 [06:53<00:00,  2.10it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 18:29:20,288 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:29:20,294 >> Configuration saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:29:22,451 >> Model weights saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:29:22,456 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:29:22,461 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =     0.8789\n",
      "  train_runtime            = 0:06:53.34\n",
      "  train_samples            =       3463\n",
      "  train_samples_per_second =     16.756\n",
      "  train_steps_per_second   =      2.095\n",
      "12/20/2021 18:29:22 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 18:29:22,788 >> The following columns in the evaluation set  don't have a corresponding argument in `BertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:29:22,790 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:29:22,790 >>   Num examples = 892\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:29:22,790 >>   Batch size = 8\n",
      " 99% 111/112 [00:13<00:00,  7.94it/s]12/20/2021 18:29:39 - INFO - utils_qa - Post-processing 221 example predictions split into 892 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 4/221 [00:00<00:06, 34.99it/s]\u001b[A\n",
      "  4% 8/221 [00:00<00:06, 34.27it/s]\u001b[A\n",
      "  5% 12/221 [00:00<00:06, 30.77it/s]\u001b[A\n",
      "  7% 16/221 [00:00<00:06, 31.79it/s]\u001b[A\n",
      "  9% 20/221 [00:00<00:06, 31.18it/s]\u001b[A\n",
      " 11% 25/221 [00:00<00:05, 34.65it/s]\u001b[A\n",
      " 14% 30/221 [00:00<00:04, 38.67it/s]\u001b[A\n",
      " 16% 35/221 [00:00<00:04, 40.97it/s]\u001b[A\n",
      " 18% 40/221 [00:01<00:04, 42.79it/s]\u001b[A\n",
      " 21% 47/221 [00:01<00:03, 48.87it/s]\u001b[A\n",
      " 24% 54/221 [00:01<00:03, 51.56it/s]\u001b[A\n",
      " 28% 61/221 [00:01<00:02, 56.14it/s]\u001b[A\n",
      " 30% 67/221 [00:01<00:02, 56.83it/s]\u001b[A\n",
      " 33% 74/221 [00:01<00:02, 57.11it/s]\u001b[A\n",
      " 36% 80/221 [00:01<00:02, 53.46it/s]\u001b[A\n",
      " 39% 87/221 [00:01<00:02, 56.59it/s]\u001b[A\n",
      " 42% 93/221 [00:01<00:02, 54.32it/s]\u001b[A\n",
      " 45% 100/221 [00:02<00:02, 57.06it/s]\u001b[A\n",
      " 48% 107/221 [00:02<00:01, 59.66it/s]\u001b[A\n",
      " 52% 114/221 [00:02<00:01, 54.80it/s]\u001b[A\n",
      " 54% 120/221 [00:02<00:01, 50.77it/s]\u001b[A\n",
      " 57% 126/221 [00:02<00:01, 51.06it/s]\u001b[A\n",
      " 60% 132/221 [00:02<00:01, 51.86it/s]\u001b[A\n",
      " 63% 139/221 [00:02<00:01, 54.78it/s]\u001b[A\n",
      " 66% 145/221 [00:02<00:01, 53.80it/s]\u001b[A\n",
      " 68% 151/221 [00:03<00:01, 54.85it/s]\u001b[A\n",
      " 71% 157/221 [00:03<00:01, 52.75it/s]\u001b[A\n",
      " 74% 163/221 [00:03<00:01, 53.68it/s]\u001b[A\n",
      " 76% 169/221 [00:03<00:01, 49.09it/s]\u001b[A\n",
      " 79% 175/221 [00:03<00:00, 48.68it/s]\u001b[A\n",
      " 81% 180/221 [00:03<00:00, 48.98it/s]\u001b[A\n",
      " 84% 185/221 [00:03<00:00, 47.71it/s]\u001b[A\n",
      " 87% 192/221 [00:03<00:00, 52.47it/s]\u001b[A\n",
      " 90% 198/221 [00:03<00:00, 53.51it/s]\u001b[A\n",
      " 92% 204/221 [00:04<00:00, 54.57it/s]\u001b[A\n",
      " 95% 211/221 [00:04<00:00, 57.99it/s]\u001b[A\n",
      "100% 221/221 [00:04<00:00, 50.26it/s]\n",
      "12/20/2021 18:29:43 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:29:43 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:29:43 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:29:43 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 112/112 [00:20<00:00,  5.38it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     2.0\n",
      "  eval_HasAns_exact      =  38.009\n",
      "  eval_HasAns_f1         = 58.7524\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        =  38.009\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 58.7524\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             =  38.009\n",
      "  eval_f1                = 58.7524\n",
      "  eval_samples           =     892\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 18:29:44,114 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/bert-base-uncased-fiqa-flm-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/bert-base-uncased-fiqa-flm-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDfgWdJG7kEM"
   },
   "source": [
    "## Model 5 - roberta-base-sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_v7l-WkqK6D",
    "outputId": "e9fb56bb-a3fd-4849-e930-8e1edb7505c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 18:37:37 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 18:37:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/roberta-base-sq-flit/runs/Dec20_18-37-37_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/roberta-base-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/roberta-base-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 18:37:38 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 18:37:38 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/20/2021 18:37:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/20/2021 18:37:38 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/20/2021 18:37:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "100% 2/2 [00:00<00:00, 603.11it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 18:37:38,676 >> loading configuration file /content/drive/MyDrive/Models/roberta-base-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 18:37:38,679 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/roberta-base-sq\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 18:37:38,939 >> Didn't find file /content/drive/MyDrive/Models/roberta-base-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:37:38,940 >> loading file /content/drive/MyDrive/Models/roberta-base-sq/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:37:38,940 >> loading file /content/drive/MyDrive/Models/roberta-base-sq/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:37:38,941 >> loading file /content/drive/MyDrive/Models/roberta-base-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:37:38,941 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:37:38,941 >> loading file /content/drive/MyDrive/Models/roberta-base-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:37:38,941 >> loading file /content/drive/MyDrive/Models/roberta-base-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 18:37:40,057 >> loading weights file /content/drive/MyDrive/Models/roberta-base-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 18:37:46,694 >> All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 18:37:46,694 >> All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/roberta-base-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:37:49 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-ee03e6ce5380cb71.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:02<00:00,  2.92s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:37:50 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-c191812146e334d3.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:03<00:00,  3.70s/ba]\n",
      "[INFO|trainer.py:1208] 2021-12-20 18:37:58,225 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 18:37:58,225 >>   Num examples = 3516\n",
      "[INFO|trainer.py:1210] 2021-12-20 18:37:58,226 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-20 18:37:58,226 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 18:37:58,226 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 18:37:58,226 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 18:37:58,226 >>   Total optimization steps = 880\n",
      " 23% 200/880 [01:11<04:01,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:39:09,513 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:39:09,515 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:39:09,515 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:39:09,515 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.16it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.80it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.65it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.19it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.04it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.90it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.78it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.72it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.60it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.60it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.59it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.58it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.54it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.55it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.49it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.58it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.52it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.56it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.58it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.57it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.58it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.60it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.60it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.60it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.55it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 68% 78/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.59it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.56it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.58it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.55it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.55it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.50it/s]\u001b[A12/20/2021 18:39:23 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 82.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 83.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 89.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 98.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 95.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 88.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 69/221 [00:00<00:01, 85.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 78/221 [00:00<00:01, 83.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 87/221 [00:01<00:02, 58.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 95/221 [00:01<00:02, 62.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 104/221 [00:01<00:01, 67.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 112/221 [00:01<00:01, 70.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 120/221 [00:01<00:01, 72.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 128/221 [00:01<00:01, 73.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 136/221 [00:01<00:01, 74.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 144/221 [00:01<00:01, 73.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 152/221 [00:02<00:00, 72.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 160/221 [00:02<00:00, 70.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 168/221 [00:02<00:00, 69.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:02<00:00, 68.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 182/221 [00:02<00:00, 67.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 191/221 [00:02<00:00, 72.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 199/221 [00:02<00:00, 74.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 208/221 [00:02<00:00, 76.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 75.39it/s]\n",
      "12/20/2021 18:39:26 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:39:26 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:39:26 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:39:26 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 45.248868778280546, 'eval_f1': 66.67890244289009, 'eval_total': 221, 'eval_HasAns_exact': 45.248868778280546, 'eval_HasAns_f1': 66.67890244289009, 'eval_HasAns_total': 221, 'eval_best_exact': 45.248868778280546, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 66.67890244289009, 'eval_best_f1_thresh': 0.0, 'epoch': 0.45}\n",
      " 23% 200/880 [01:28<04:01,  2.82it/s]\n",
      "100% 114/114 [00:17<00:00,  8.50it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:39:26,998 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:39:27,005 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:39:29,655 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:39:29,661 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:39:29,666 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-200/special_tokens_map.json\n",
      " 45% 400/880 [02:49<02:51,  2.80it/s][INFO|trainer.py:549] 2021-12-20 18:40:47,765 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:40:47,767 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:40:47,767 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:40:47,767 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.14it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.78it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.65it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.19it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.04it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.92it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.83it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.76it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.66it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.53it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.56it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.57it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.56it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.54it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.55it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.53it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.54it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.51it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.53it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.45it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.42it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.51it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.50it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.45it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.47it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.46it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.53it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.54it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.52it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.52it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.52it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.53it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.54it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.55it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.46it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.49it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.51it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.46it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 98% 112/114 [00:13<00:00,  8.44it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.42it/s]\u001b[A12/20/2021 18:41:02 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 84.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 84.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 90.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 98.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 94.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 87.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 69/221 [00:00<00:01, 85.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 78/221 [00:00<00:01, 82.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 87/221 [00:01<00:01, 81.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 96/221 [00:01<00:01, 82.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 81.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 82.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 123/221 [00:01<00:01, 83.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 132/221 [00:01<00:01, 79.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 140/221 [00:01<00:01, 78.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 148/221 [00:01<00:00, 75.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 156/221 [00:01<00:00, 73.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 164/221 [00:02<00:00, 71.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 172/221 [00:02<00:00, 68.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 179/221 [00:02<00:00, 68.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 188/221 [00:02<00:00, 72.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 197/221 [00:02<00:00, 75.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 206/221 [00:02<00:00, 78.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 79.90it/s]\n",
      "12/20/2021 18:41:04 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:41:04 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:41:05 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:41:05 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 47.05882352941177, 'eval_f1': 70.60301398822858, 'eval_total': 221, 'eval_HasAns_exact': 47.05882352941177, 'eval_HasAns_f1': 70.60301398822858, 'eval_HasAns_total': 221, 'eval_best_exact': 47.05882352941177, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 70.60301398822858, 'eval_best_f1_thresh': 0.0, 'epoch': 0.91}\n",
      " 45% 400/880 [03:06<02:51,  2.80it/s]\n",
      "100% 114/114 [00:17<00:00,  8.42it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:41:05,146 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:41:05,157 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:41:07,911 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:41:07,917 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:41:07,923 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:41:13,759 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 0.8748, 'learning_rate': 1.0795454545454547e-05, 'epoch': 1.14}\n",
      " 68% 600/880 [04:28<01:39,  2.81it/s][INFO|trainer.py:549] 2021-12-20 18:42:26,390 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:42:26,392 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:42:26,392 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:42:26,392 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.16it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.79it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.64it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.19it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.04it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.92it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.77it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.72it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.56it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.47it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.46it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.45it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.49it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.52it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.53it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:10,  8.49it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.57it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.56it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.57it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.51it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.53it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.54it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.55it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.54it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.55it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.56it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.57it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.59it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.59it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.59it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.59it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.59it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.59it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.59it/s]\u001b[A12/20/2021 18:42:40 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 80.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 82.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 85.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 38/221 [00:00<00:02, 91.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 89.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 57/221 [00:00<00:01, 88.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 66/221 [00:00<00:01, 87.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 75/221 [00:00<00:01, 84.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 84/221 [00:00<00:01, 82.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 93/221 [00:01<00:01, 80.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 102/221 [00:01<00:01, 79.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 111/221 [00:01<00:01, 80.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 120/221 [00:01<00:01, 77.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 129/221 [00:01<00:01, 78.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:01, 80.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 147/221 [00:01<00:00, 77.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 155/221 [00:01<00:00, 75.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 163/221 [00:02<00:00, 73.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 171/221 [00:02<00:00, 70.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 179/221 [00:02<00:00, 68.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 187/221 [00:02<00:00, 70.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 196/221 [00:02<00:00, 73.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 205/221 [00:02<00:00, 76.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 79.22it/s]\n",
      "12/20/2021 18:42:43 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:42:43 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:42:43 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:42:43 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 45.248868778280546, 'eval_f1': 67.61294582370903, 'eval_total': 221, 'eval_HasAns_exact': 45.248868778280546, 'eval_HasAns_f1': 67.61294582370903, 'eval_HasAns_total': 221, 'eval_best_exact': 45.248868778280546, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 67.61294582370903, 'eval_best_f1_thresh': 0.0, 'epoch': 1.36}\n",
      " 68% 600/880 [04:45<01:39,  2.81it/s]\n",
      "100% 114/114 [00:17<00:00,  8.59it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:42:43,746 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:42:43,753 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:42:46,431 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:42:46,437 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:42:46,442 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:42:52,568 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 91% 800/880 [06:05<00:28,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:44:03,971 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:44:03,974 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:44:03,974 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:44:03,974 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.19it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.72it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.64it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.20it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.02it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.91it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.82it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.76it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.71it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.49it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.52it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.53it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.59it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.59it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.58it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.58it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.58it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.56it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.53it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.54it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.54it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.54it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.50it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.59it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.58it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.60it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.59it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.59it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.57it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.54it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.56it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.58it/s]\u001b[A12/20/2021 18:44:18 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 83.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 83.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 88.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 97.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 93.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 89.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 69/221 [00:00<00:01, 87.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 78/221 [00:00<00:01, 84.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 87/221 [00:01<00:01, 79.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 96/221 [00:01<00:01, 80.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 81.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 78.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 123/221 [00:01<00:01, 79.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 132/221 [00:01<00:01, 80.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 141/221 [00:01<00:01, 79.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 149/221 [00:01<00:00, 76.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 157/221 [00:01<00:00, 72.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 165/221 [00:02<00:00, 69.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 172/221 [00:02<00:00, 66.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 179/221 [00:02<00:00, 64.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 188/221 [00:02<00:00, 69.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 197/221 [00:02<00:00, 73.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 206/221 [00:02<00:00, 75.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 79.08it/s]\n",
      "12/20/2021 18:44:21 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:44:21 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:44:21 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:44:21 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 47.51131221719457, 'eval_f1': 69.31509034249535, 'eval_total': 221, 'eval_HasAns_exact': 47.51131221719457, 'eval_HasAns_f1': 69.31509034249535, 'eval_HasAns_total': 221, 'eval_best_exact': 47.51131221719457, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 69.31509034249535, 'eval_best_f1_thresh': 0.0, 'epoch': 1.82}\n",
      " 91% 800/880 [06:23<00:28,  2.82it/s]\n",
      "100% 114/114 [00:17<00:00,  8.58it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:44:21,380 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:44:21,387 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:44:23,981 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:44:23,987 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:44:23,992 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:44:30,025 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "100% 880/880 [07:00<00:00,  3.21it/s][INFO|trainer.py:1429] 2021-12-20 18:44:58,459 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 420.233, 'train_samples_per_second': 16.734, 'train_steps_per_second': 2.094, 'train_loss': 0.7280803853815252, 'epoch': 2.0}\n",
      "100% 880/880 [07:00<00:00,  2.09it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 18:44:58,465 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:44:58,471 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:45:01,138 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:45:01,143 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:45:01,148 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =     0.7281\n",
      "  train_runtime            = 0:07:00.23\n",
      "  train_samples            =       3516\n",
      "  train_samples_per_second =     16.734\n",
      "  train_steps_per_second   =      2.094\n",
      "12/20/2021 18:45:01 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 18:45:01,332 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:45:01,335 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:45:01,335 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:45:01,335 >>   Batch size = 8\n",
      " 99% 113/114 [00:13<00:00,  7.90it/s]12/20/2021 18:45:18 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  3% 6/221 [00:00<00:03, 55.66it/s]\u001b[A\n",
      "  5% 12/221 [00:00<00:04, 49.20it/s]\u001b[A\n",
      "  8% 18/221 [00:00<00:03, 52.77it/s]\u001b[A\n",
      " 11% 25/221 [00:00<00:03, 57.30it/s]\u001b[A\n",
      " 14% 32/221 [00:00<00:03, 60.15it/s]\u001b[A\n",
      " 19% 41/221 [00:00<00:02, 67.26it/s]\u001b[A\n",
      " 22% 48/221 [00:00<00:02, 60.68it/s]\u001b[A\n",
      " 25% 55/221 [00:00<00:02, 58.54it/s]\u001b[A\n",
      " 28% 61/221 [00:01<00:03, 49.07it/s]\u001b[A\n",
      " 30% 67/221 [00:01<00:03, 50.08it/s]\u001b[A\n",
      " 33% 74/221 [00:01<00:02, 53.14it/s]\u001b[A\n",
      " 36% 80/221 [00:01<00:02, 53.54it/s]\u001b[A\n",
      " 39% 86/221 [00:01<00:02, 53.12it/s]\u001b[A\n",
      " 42% 93/221 [00:01<00:02, 56.19it/s]\u001b[A\n",
      " 45% 99/221 [00:01<00:02, 53.98it/s]\u001b[A\n",
      " 48% 106/221 [00:01<00:02, 55.42it/s]\u001b[A\n",
      " 51% 112/221 [00:02<00:01, 54.91it/s]\u001b[A\n",
      " 53% 118/221 [00:02<00:01, 55.26it/s]\u001b[A\n",
      " 56% 124/221 [00:02<00:01, 56.43it/s]\u001b[A\n",
      " 59% 130/221 [00:02<00:01, 55.09it/s]\u001b[A\n",
      " 62% 137/221 [00:02<00:01, 56.36it/s]\u001b[A\n",
      " 65% 143/221 [00:02<00:01, 54.02it/s]\u001b[A\n",
      " 67% 149/221 [00:02<00:01, 53.39it/s]\u001b[A\n",
      " 70% 155/221 [00:02<00:01, 51.37it/s]\u001b[A\n",
      " 73% 161/221 [00:02<00:01, 49.86it/s]\u001b[A\n",
      " 76% 167/221 [00:03<00:01, 48.93it/s]\u001b[A\n",
      " 78% 172/221 [00:03<00:01, 48.57it/s]\u001b[A\n",
      " 80% 177/221 [00:03<00:00, 46.49it/s]\u001b[A\n",
      " 83% 183/221 [00:03<00:00, 49.97it/s]\u001b[A\n",
      " 86% 189/221 [00:03<00:00, 50.33it/s]\u001b[A\n",
      " 89% 196/221 [00:03<00:00, 53.43it/s]\u001b[A\n",
      " 92% 203/221 [00:03<00:00, 55.84it/s]\u001b[A\n",
      " 95% 209/221 [00:03<00:00, 55.68it/s]\u001b[A\n",
      "100% 221/221 [00:04<00:00, 53.89it/s]\n",
      "12/20/2021 18:45:22 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:45:22 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:45:22 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:45:22 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 114/114 [00:20<00:00,  5.44it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     2.0\n",
      "  eval_HasAns_exact      = 48.8688\n",
      "  eval_HasAns_f1         = 71.7677\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 48.8688\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 71.7677\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 48.8688\n",
      "  eval_f1                = 71.7677\n",
      "  eval_samples           =     907\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 18:45:22,958 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/roberta-base-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/roberta-base-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwcKQl9Kntc3"
   },
   "source": [
    "## Model 6 - roberta-base-fiqa-sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ttZV4_Q7nrgL",
    "outputId": "0eba8653-2407-49ea-deaf-817ede36fad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 18:45:37 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 18:45:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/runs/Dec20_18-45-36_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 18:45:37 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 18:45:37 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/20/2021 18:45:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/20/2021 18:45:37 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/20/2021 18:45:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "100% 2/2 [00:00<00:00, 362.97it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 18:45:37,972 >> loading configuration file /content/drive/MyDrive/Models/roberta-base-fiqa-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 18:45:37,976 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/roberta-base-fiqa-sq\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 18:45:38,388 >> Didn't find file /content/drive/MyDrive/Models/roberta-base-fiqa-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:45:38,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-sq/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:45:38,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-sq/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:45:38,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:45:38,394 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:45:38,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:45:38,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 18:45:39,821 >> loading weights file /content/drive/MyDrive/Models/roberta-base-fiqa-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 18:45:48,846 >> All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 18:45:48,846 >> All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/roberta-base-fiqa-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:45:52 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-0474ead2edf03f5b.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:03<00:00,  3.48s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:45:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-886eb089ea1460df.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:04<00:00,  4.81s/ba]\n",
      "[INFO|trainer.py:1208] 2021-12-20 18:46:02,600 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 18:46:02,601 >>   Num examples = 3516\n",
      "[INFO|trainer.py:1210] 2021-12-20 18:46:02,601 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-20 18:46:02,601 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 18:46:02,601 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 18:46:02,601 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 18:46:02,601 >>   Total optimization steps = 880\n",
      " 23% 200/880 [01:11<04:01,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:47:13,821 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:47:13,824 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:47:13,824 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:47:13,824 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.16it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.78it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.62it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.17it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.03it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.92it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.83it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.53it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.54it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:11,  8.53it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.44it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.48it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.49it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.49it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.45it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.55it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.57it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.56it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.56it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.56it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.57it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.57it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.56it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.52it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.54it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.55it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.56it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.58it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.58it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.57it/s]\u001b[A12/20/2021 18:47:28 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 84.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 81.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 87.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 97.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 93.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 87.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 69/221 [00:00<00:01, 85.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 78/221 [00:00<00:01, 83.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 87/221 [00:01<00:02, 56.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 96/221 [00:01<00:02, 62.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 67.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 113/221 [00:01<00:01, 68.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 122/221 [00:01<00:01, 72.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:01, 72.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:01, 73.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 146/221 [00:01<00:01, 73.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 154/221 [00:02<00:00, 70.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 162/221 [00:02<00:00, 69.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:02<00:00, 67.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 66.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 185/221 [00:02<00:00, 68.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 194/221 [00:02<00:00, 71.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 202/221 [00:02<00:00, 72.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 211/221 [00:02<00:00, 76.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 74.25it/s]\n",
      "12/20/2021 18:47:31 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:47:31 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:47:31 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:47:31 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 42.081447963800905, 'eval_f1': 67.62126957076849, 'eval_total': 221, 'eval_HasAns_exact': 42.081447963800905, 'eval_HasAns_f1': 67.62126957076849, 'eval_HasAns_total': 221, 'eval_best_exact': 42.081447963800905, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 67.62126957076849, 'eval_best_f1_thresh': 0.0, 'epoch': 0.45}\n",
      " 23% 200/880 [01:28<04:01,  2.82it/s]\n",
      "100% 114/114 [00:17<00:00,  8.57it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:47:31,402 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:47:31,408 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:47:34,276 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:47:34,285 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:47:34,290 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-200/special_tokens_map.json\n",
      " 45% 400/880 [02:50<02:50,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:48:53,194 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:48:53,196 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:48:53,196 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:48:53,196 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.07it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.77it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.65it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.15it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.01it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.90it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.76it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.71it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.53it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.54it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.55it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.55it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.47it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.52it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.53it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.55it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.55it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.56it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.57it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.50it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.51it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.45it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.49it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.51it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.44it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.51it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.50it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.42it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.46it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:02,  8.49it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.53it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.54it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 98% 112/114 [00:13<00:00,  8.57it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.57it/s]\u001b[A12/20/2021 18:49:07 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 83.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 82.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 87.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 39/221 [00:00<00:01, 95.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 49/221 [00:00<00:01, 93.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 59/221 [00:00<00:01, 88.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 68/221 [00:00<00:01, 83.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 77/221 [00:00<00:01, 81.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 86/221 [00:01<00:01, 78.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 94/221 [00:01<00:01, 79.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 102/221 [00:01<00:01, 78.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 110/221 [00:01<00:01, 78.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 119/221 [00:01<00:01, 79.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 127/221 [00:01<00:01, 78.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 135/221 [00:01<00:01, 77.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:01, 75.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 71.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 159/221 [00:02<00:00, 70.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 167/221 [00:02<00:00, 68.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 174/221 [00:02<00:00, 67.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 181/221 [00:02<00:00, 66.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 189/221 [00:02<00:00, 70.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 198/221 [00:02<00:00, 74.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 206/221 [00:02<00:00, 75.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 77.48it/s]\n",
      "12/20/2021 18:49:10 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:49:10 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:49:10 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:49:10 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 42.081447963800905, 'eval_f1': 67.45969484256572, 'eval_total': 221, 'eval_HasAns_exact': 42.081447963800905, 'eval_HasAns_f1': 67.45969484256572, 'eval_HasAns_total': 221, 'eval_best_exact': 42.081447963800905, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 67.45969484256572, 'eval_best_f1_thresh': 0.0, 'epoch': 0.91}\n",
      " 45% 400/880 [03:08<02:50,  2.82it/s]\n",
      "100% 114/114 [00:17<00:00,  8.57it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:49:10,651 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:49:10,660 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:49:13,613 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:49:13,619 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:49:13,624 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:49:19,784 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 0.8877, 'learning_rate': 1.0795454545454547e-05, 'epoch': 1.14}\n",
      " 68% 600/880 [04:29<01:39,  2.80it/s][INFO|trainer.py:549] 2021-12-20 18:50:32,449 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:50:32,453 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:50:32,453 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:50:32,453 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.05it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.75it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.61it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.17it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.02it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.90it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.79it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.55it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.46it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.48it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.52it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.53it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.54it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.54it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.54it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.53it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.48it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.51it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.51it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.45it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:06,  8.46it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.52it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.53it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.46it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.49it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.44it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.47it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:04,  8.49it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.52it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.46it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.48it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.50it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.54it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.54it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.54it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.54it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 98% 112/114 [00:13<00:00,  8.53it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.54it/s]\u001b[A12/20/2021 18:50:46 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 75.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 77.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 25/221 [00:00<00:02, 80.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:02, 92.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 46/221 [00:00<00:01, 93.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25% 56/221 [00:00<00:01, 87.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 65/221 [00:00<00:01, 86.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 84.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 83/221 [00:01<00:01, 76.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 92/221 [00:01<00:01, 77.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 100/221 [00:01<00:01, 77.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 108/221 [00:01<00:01, 77.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 116/221 [00:01<00:01, 78.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 124/221 [00:01<00:01, 78.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 132/221 [00:01<00:01, 77.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 140/221 [00:01<00:01, 77.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 148/221 [00:01<00:01, 71.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 156/221 [00:02<00:00, 67.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 163/221 [00:02<00:00, 66.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:02<00:00, 66.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 64.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 185/221 [00:02<00:00, 67.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 194/221 [00:02<00:00, 72.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 203/221 [00:02<00:00, 74.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 212/221 [00:02<00:00, 77.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 76.77it/s]\n",
      "12/20/2021 18:50:49 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:50:49 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:50:49 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:50:49 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 41.1764705882353, 'eval_f1': 64.87943594140705, 'eval_total': 221, 'eval_HasAns_exact': 41.1764705882353, 'eval_HasAns_f1': 64.87943594140705, 'eval_HasAns_total': 221, 'eval_best_exact': 41.1764705882353, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 64.87943594140705, 'eval_best_f1_thresh': 0.0, 'epoch': 1.36}\n",
      " 68% 600/880 [04:47<01:39,  2.80it/s]\n",
      "100% 114/114 [00:17<00:00,  8.54it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:50:49,982 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:50:49,989 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:50:52,615 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:50:52,621 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:50:52,625 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:50:58,485 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 91% 800/880 [06:07<00:28,  2.81it/s][INFO|trainer.py:549] 2021-12-20 18:52:10,361 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:52:10,363 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:52:10,364 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:52:10,364 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.13it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.63it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.49it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.09it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  8.97it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.86it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.78it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.72it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.57it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.51it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.53it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:10,  8.37it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.42it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.45it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.41it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.46it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.49it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.50it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.51it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.53it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.53it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.51it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.54it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.51it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.53it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.52it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.46it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.50it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.55it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.57it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.51it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.51it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.48it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.43it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.46it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.54it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.53it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.50it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.51it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.53it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 98% 112/114 [00:13<00:00,  8.53it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.53it/s]\u001b[A12/20/2021 18:52:24 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 83.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 75.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 81.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 39/221 [00:00<00:01, 92.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 49/221 [00:00<00:01, 91.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 59/221 [00:00<00:01, 88.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 68/221 [00:00<00:01, 80.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 77/221 [00:00<00:01, 80.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 86/221 [00:01<00:01, 78.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 95/221 [00:01<00:01, 79.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 103/221 [00:01<00:01, 76.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 111/221 [00:01<00:01, 75.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 119/221 [00:01<00:01, 75.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 127/221 [00:01<00:01, 76.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 135/221 [00:01<00:01, 76.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:01, 77.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 74.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 159/221 [00:02<00:00, 71.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 167/221 [00:02<00:00, 68.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 174/221 [00:02<00:00, 68.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 181/221 [00:02<00:00, 64.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 190/221 [00:02<00:00, 69.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 199/221 [00:02<00:00, 73.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 207/221 [00:02<00:00, 74.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 76.99it/s]\n",
      "12/20/2021 18:52:27 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:52:27 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:52:27 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:52:27 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 43.43891402714932, 'eval_f1': 67.46042811092273, 'eval_total': 221, 'eval_HasAns_exact': 43.43891402714932, 'eval_HasAns_f1': 67.46042811092273, 'eval_HasAns_total': 221, 'eval_best_exact': 43.43891402714932, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 67.46042811092273, 'eval_best_f1_thresh': 0.0, 'epoch': 1.82}\n",
      " 91% 800/880 [06:25<00:28,  2.81it/s]\n",
      "100% 114/114 [00:17<00:00,  8.53it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:52:27,852 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:52:27,859 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:52:30,737 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:52:30,743 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:52:30,748 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:52:37,153 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "100% 880/880 [07:03<00:00,  3.23it/s][INFO|trainer.py:1429] 2021-12-20 18:53:05,961 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 423.3606, 'train_samples_per_second': 16.61, 'train_steps_per_second': 2.079, 'train_loss': 0.7261479464444247, 'epoch': 2.0}\n",
      "100% 880/880 [07:03<00:00,  2.08it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 18:53:06,009 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:53:06,016 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:53:08,905 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:53:08,914 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:53:08,919 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =     0.7261\n",
      "  train_runtime            = 0:07:03.36\n",
      "  train_samples            =       3516\n",
      "  train_samples_per_second =      16.61\n",
      "  train_steps_per_second   =      2.079\n",
      "12/20/2021 18:53:09 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 18:53:09,095 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:53:09,099 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:53:09,099 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:53:09,099 >>   Batch size = 8\n",
      " 99% 113/114 [00:13<00:00,  7.89it/s]12/20/2021 18:53:24 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 5/221 [00:00<00:04, 46.03it/s]\u001b[A\n",
      "  5% 12/221 [00:00<00:03, 53.31it/s]\u001b[A\n",
      "  8% 18/221 [00:00<00:04, 47.38it/s]\u001b[A\n",
      " 12% 26/221 [00:00<00:03, 57.35it/s]\u001b[A\n",
      " 15% 34/221 [00:00<00:03, 61.93it/s]\u001b[A\n",
      " 19% 42/221 [00:00<00:02, 66.82it/s]\u001b[A\n",
      " 22% 49/221 [00:00<00:03, 54.12it/s]\u001b[A\n",
      " 25% 56/221 [00:00<00:02, 56.60it/s]\u001b[A\n",
      " 28% 62/221 [00:01<00:02, 55.48it/s]\u001b[A\n",
      " 31% 68/221 [00:01<00:02, 55.32it/s]\u001b[A\n",
      " 33% 74/221 [00:01<00:02, 52.43it/s]\u001b[A\n",
      " 36% 80/221 [00:01<00:02, 53.49it/s]\u001b[A\n",
      " 39% 86/221 [00:01<00:02, 54.93it/s]\u001b[A\n",
      " 42% 92/221 [00:01<00:02, 53.29it/s]\u001b[A\n",
      " 44% 98/221 [00:01<00:02, 54.15it/s]\u001b[A\n",
      " 47% 104/221 [00:01<00:02, 51.83it/s]\u001b[A\n",
      " 50% 110/221 [00:02<00:02, 52.15it/s]\u001b[A\n",
      " 52% 116/221 [00:02<00:01, 54.16it/s]\u001b[A\n",
      " 55% 122/221 [00:02<00:01, 52.84it/s]\u001b[A\n",
      " 58% 129/221 [00:02<00:01, 54.70it/s]\u001b[A\n",
      " 61% 135/221 [00:02<00:01, 53.01it/s]\u001b[A\n",
      " 64% 141/221 [00:02<00:01, 54.02it/s]\u001b[A\n",
      " 67% 147/221 [00:02<00:01, 51.87it/s]\u001b[A\n",
      " 69% 153/221 [00:02<00:01, 47.06it/s]\u001b[A\n",
      " 71% 158/221 [00:02<00:01, 46.18it/s]\u001b[A\n",
      " 74% 163/221 [00:03<00:01, 46.97it/s]\u001b[A\n",
      " 76% 168/221 [00:03<00:01, 46.12it/s]\u001b[A\n",
      " 78% 173/221 [00:03<00:01, 44.68it/s]\u001b[A\n",
      " 81% 178/221 [00:03<00:00, 44.55it/s]\u001b[A\n",
      " 84% 185/221 [00:03<00:00, 49.99it/s]\u001b[A\n",
      " 88% 194/221 [00:03<00:00, 59.87it/s]\u001b[A\n",
      " 92% 203/221 [00:03<00:00, 66.67it/s]\u001b[A\n",
      " 96% 212/221 [00:03<00:00, 71.72it/s]\u001b[A\n",
      "100% 221/221 [00:03<00:00, 55.52it/s]\n",
      "12/20/2021 18:53:28 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:53:28 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:53:28 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:53:28 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 114/114 [00:19<00:00,  5.76it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     2.0\n",
      "  eval_HasAns_exact      = 45.2489\n",
      "  eval_HasAns_f1         = 68.6413\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 45.2489\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 68.6413\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 45.2489\n",
      "  eval_f1                = 68.6413\n",
      "  eval_samples           =     907\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 18:53:29,394 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/roberta-base-fiqa-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/roberta-base-fiqa-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSbx4kdPQbvn"
   },
   "source": [
    "## Model 7 - roberta-base-flm-sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i0tq7tdWQbwD",
    "outputId": "cd002d94-2edf-4de2-9d93-bd55702f6cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 18:53:42 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 18:53:42 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/runs/Dec20_18-53-42_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 18:53:43 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 18:53:43 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/20/2021 18:53:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/20/2021 18:53:43 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/20/2021 18:53:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "100% 2/2 [00:00<00:00, 219.20it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 18:53:43,551 >> loading configuration file /content/drive/MyDrive/Models/roberta-base-flm-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 18:53:43,555 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/roberta-base-flm-sq\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 18:53:43,957 >> Didn't find file /content/drive/MyDrive/Models/roberta-base-flm-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:53:43,963 >> loading file /content/drive/MyDrive/Models/roberta-base-flm-sq/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:53:43,963 >> loading file /content/drive/MyDrive/Models/roberta-base-flm-sq/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:53:43,963 >> loading file /content/drive/MyDrive/Models/roberta-base-flm-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:53:43,963 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:53:43,964 >> loading file /content/drive/MyDrive/Models/roberta-base-flm-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 18:53:43,964 >> loading file /content/drive/MyDrive/Models/roberta-base-flm-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 18:53:45,449 >> loading weights file /content/drive/MyDrive/Models/roberta-base-flm-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 18:53:54,412 >> All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 18:53:54,412 >> All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/roberta-base-flm-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:53:57 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-57ec9ce8b17a7a6c.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:03<00:00,  3.68s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 18:53:58 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-0a0219ae0fe7864b.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:04<00:00,  4.52s/ba]\n",
      "[INFO|trainer.py:1208] 2021-12-20 18:54:08,572 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 18:54:08,572 >>   Num examples = 3516\n",
      "[INFO|trainer.py:1210] 2021-12-20 18:54:08,572 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-20 18:54:08,573 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 18:54:08,573 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 18:54:08,573 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 18:54:08,573 >>   Total optimization steps = 880\n",
      " 23% 200/880 [01:10<03:59,  2.84it/s][INFO|trainer.py:549] 2021-12-20 18:55:19,276 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:55:19,279 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:55:19,279 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:55:19,279 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.09it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.82it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.69it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.23it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.07it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.93it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.85it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.77it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.72it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.57it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:11,  8.51it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.59it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.58it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.58it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.57it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.59it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.59it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.56it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.56it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.56it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.56it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.59it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.59it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 68% 78/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.58it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.53it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.55it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.59it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.59it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.58it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.59it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.58it/s]\u001b[A12/20/2021 18:55:33 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 87.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 82.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 29/221 [00:00<00:02, 92.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 41/221 [00:00<00:01, 102.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 52/221 [00:00<00:01, 98.18it/s] \u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:01, 92.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 72/221 [00:00<00:01, 90.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 82/221 [00:00<00:01, 86.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 91/221 [00:01<00:01, 86.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 100/221 [00:01<00:01, 86.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 109/221 [00:01<00:01, 60.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 118/221 [00:01<00:01, 65.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 126/221 [00:01<00:01, 67.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 70.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:01, 73.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 72.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 159/221 [00:02<00:00, 72.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 167/221 [00:02<00:00, 72.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:02<00:00, 67.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 182/221 [00:02<00:00, 67.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 192/221 [00:02<00:00, 74.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 78.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 210/221 [00:02<00:00, 80.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 78.29it/s]\n",
      "12/20/2021 18:55:36 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:55:36 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:55:36 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:55:36 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 40.723981900452486, 'eval_f1': 64.69146509182272, 'eval_total': 221, 'eval_HasAns_exact': 40.723981900452486, 'eval_HasAns_f1': 64.69146509182272, 'eval_HasAns_total': 221, 'eval_best_exact': 40.723981900452486, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 64.69146509182272, 'eval_best_f1_thresh': 0.0, 'epoch': 0.45}\n",
      " 23% 200/880 [01:28<03:59,  2.84it/s]\n",
      "100% 114/114 [00:17<00:00,  8.58it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:55:36,621 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:55:36,628 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:55:39,473 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:55:39,479 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:55:39,487 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-200/special_tokens_map.json\n",
      " 45% 400/880 [02:49<02:49,  2.84it/s][INFO|trainer.py:549] 2021-12-20 18:56:58,035 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:56:58,037 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:56:58,038 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:56:58,038 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.25it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.84it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.69it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.20it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.06it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.94it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.85it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.78it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.71it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.56it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.54it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.55it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.58it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.58it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.58it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.61it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.60it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.52it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.54it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.57it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.53it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.57it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.58it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.58it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.59it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 78/114 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.49it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.55it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.55it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.55it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.56it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.56it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.55it/s]\u001b[A12/20/2021 18:57:12 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 86.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 85.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 90.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 100.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 51/221 [00:00<00:01, 95.64it/s] \u001b[A\u001b[A\n",
      "\n",
      " 28% 61/221 [00:00<00:01, 91.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 71/221 [00:00<00:01, 86.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 80/221 [00:00<00:01, 83.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 89/221 [00:01<00:01, 83.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 83.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 107/221 [00:01<00:01, 83.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 116/221 [00:01<00:01, 84.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 125/221 [00:01<00:01, 83.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 82.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:00, 82.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 152/221 [00:01<00:00, 76.69it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 160/221 [00:01<00:00, 73.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 168/221 [00:02<00:00, 72.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 176/221 [00:02<00:00, 71.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 71.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 193/221 [00:02<00:00, 76.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 202/221 [00:02<00:00, 79.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 211/221 [00:02<00:00, 77.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 81.66it/s]\n",
      "12/20/2021 18:57:15 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:57:15 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:57:15 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:57:15 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 47.05882352941177, 'eval_f1': 69.51748905695617, 'eval_total': 221, 'eval_HasAns_exact': 47.05882352941177, 'eval_HasAns_f1': 69.51748905695617, 'eval_HasAns_total': 221, 'eval_best_exact': 47.05882352941177, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 69.51748905695617, 'eval_best_f1_thresh': 0.0, 'epoch': 0.91}\n",
      " 45% 400/880 [03:06<02:49,  2.84it/s]\n",
      "100% 114/114 [00:17<00:00,  8.55it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:57:15,330 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:57:15,340 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:57:18,249 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:57:18,257 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:57:18,272 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:57:25,515 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 0.8636, 'learning_rate': 1.0795454545454547e-05, 'epoch': 1.14}\n",
      " 68% 600/880 [04:28<01:39,  2.82it/s][INFO|trainer.py:549] 2021-12-20 18:58:37,175 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 18:58:37,177 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 18:58:37,177 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 18:58:37,177 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.24it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.84it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.67it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.15it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.00it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.90it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.81it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.66it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.59it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.52it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.54it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.57it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.58it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.55it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.58it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.58it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.54it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.58it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.58it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.59it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.59it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.57it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.56it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.52it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.54it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 68% 78/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.58it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.55it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.49it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.56it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.56it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.56it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.59it/s]\u001b[A12/20/2021 18:58:51 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 86.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 86.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 92.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 101.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 51/221 [00:00<00:01, 94.49it/s] \u001b[A\u001b[A\n",
      "\n",
      " 28% 61/221 [00:00<00:01, 92.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 71/221 [00:00<00:01, 89.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 80/221 [00:00<00:01, 85.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 89/221 [00:01<00:01, 79.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 80.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 107/221 [00:01<00:01, 82.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 116/221 [00:01<00:01, 81.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 125/221 [00:01<00:01, 80.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 82.34it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:00, 82.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 152/221 [00:01<00:00, 76.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 160/221 [00:01<00:00, 75.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 168/221 [00:02<00:00, 69.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 176/221 [00:02<00:00, 70.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 71.49it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 193/221 [00:02<00:00, 74.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 202/221 [00:02<00:00, 78.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 211/221 [00:02<00:00, 81.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 81.46it/s]\n",
      "12/20/2021 18:58:54 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 18:58:54 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 18:58:54 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 18:58:54 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 42.081447963800905, 'eval_f1': 66.23648475738852, 'eval_total': 221, 'eval_HasAns_exact': 42.081447963800905, 'eval_HasAns_f1': 66.23648475738852, 'eval_HasAns_total': 221, 'eval_best_exact': 42.081447963800905, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 66.23648475738852, 'eval_best_f1_thresh': 0.0, 'epoch': 1.36}\n",
      " 68% 600/880 [04:45<01:39,  2.82it/s]\n",
      "100% 114/114 [00:17<00:00,  8.59it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 18:58:54,399 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 18:58:54,406 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 18:58:57,596 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 18:58:57,608 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 18:58:57,614 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 18:59:03,469 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 91% 800/880 [06:05<00:28,  2.84it/s][INFO|trainer.py:549] 2021-12-20 19:00:14,502 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:00:14,504 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:00:14,504 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:00:14,504 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.15it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.70it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.61it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.17it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.02it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.90it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.81it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.75it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.58it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.47it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.52it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.53it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.57it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.55it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.54it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:08,  8.47it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.56it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.47it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.42it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.45it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.48it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:06,  8.50it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.44it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.49it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.53it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.53it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.55it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.55it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.49it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.47it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.42it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.45it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.41it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.49it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.51it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.55it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.56it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.55it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.54it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 98% 112/114 [00:13<00:00,  8.56it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.56it/s]\u001b[A12/20/2021 19:00:28 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 83.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 84.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 89.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 100.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 51/221 [00:00<00:01, 94.78it/s] \u001b[A\u001b[A\n",
      "\n",
      " 28% 61/221 [00:00<00:01, 93.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 71/221 [00:00<00:01, 87.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 80/221 [00:00<00:01, 82.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 89/221 [00:01<00:01, 81.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 83.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 107/221 [00:01<00:01, 82.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 116/221 [00:01<00:01, 79.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 125/221 [00:01<00:01, 80.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 79.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:00, 78.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 75.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 159/221 [00:01<00:00, 71.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 167/221 [00:02<00:00, 71.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:02<00:00, 69.86it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 183/221 [00:02<00:00, 69.39it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 192/221 [00:02<00:00, 73.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 76.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 77.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 79.95it/s]\n",
      "12/20/2021 19:00:31 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:00:31 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:00:31 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:00:31 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 47.51131221719457, 'eval_f1': 69.95843140422826, 'eval_total': 221, 'eval_HasAns_exact': 47.51131221719457, 'eval_HasAns_f1': 69.95843140422826, 'eval_HasAns_total': 221, 'eval_best_exact': 47.51131221719457, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 69.95843140422826, 'eval_best_f1_thresh': 0.0, 'epoch': 1.82}\n",
      " 91% 800/880 [06:23<00:28,  2.84it/s]\n",
      "100% 114/114 [00:17<00:00,  8.56it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:00:31,833 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:00:31,843 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:00:34,730 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:00:34,737 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:00:34,745 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:00:41,259 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "100% 880/880 [07:00<00:00,  3.27it/s][INFO|trainer.py:1429] 2021-12-20 19:01:09,505 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 420.9334, 'train_samples_per_second': 16.706, 'train_steps_per_second': 2.091, 'train_loss': 0.7214942758733576, 'epoch': 2.0}\n",
      "100% 880/880 [07:00<00:00,  2.09it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 19:01:09,513 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:01:09,519 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:01:12,715 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:01:12,723 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:01:12,734 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =     0.7215\n",
      "  train_runtime            = 0:07:00.93\n",
      "  train_samples            =       3516\n",
      "  train_samples_per_second =     16.706\n",
      "  train_steps_per_second   =      2.091\n",
      "12/20/2021 19:01:13 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 19:01:13,037 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:01:13,039 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:01:13,039 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:01:13,039 >>   Batch size = 8\n",
      " 99% 113/114 [00:13<00:00,  8.06it/s]12/20/2021 19:01:28 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  3% 6/221 [00:00<00:03, 56.34it/s]\u001b[A\n",
      "  5% 12/221 [00:00<00:03, 56.08it/s]\u001b[A\n",
      "  9% 19/221 [00:00<00:03, 58.93it/s]\u001b[A\n",
      " 12% 26/221 [00:00<00:03, 61.18it/s]\u001b[A\n",
      " 15% 33/221 [00:00<00:03, 60.80it/s]\u001b[A\n",
      " 18% 40/221 [00:00<00:02, 63.59it/s]\u001b[A\n",
      " 21% 47/221 [00:00<00:02, 63.13it/s]\u001b[A\n",
      " 24% 54/221 [00:00<00:02, 60.05it/s]\u001b[A\n",
      " 28% 61/221 [00:01<00:02, 60.42it/s]\u001b[A\n",
      " 31% 68/221 [00:01<00:02, 55.46it/s]\u001b[A\n",
      " 34% 75/221 [00:01<00:02, 56.26it/s]\u001b[A\n",
      " 37% 81/221 [00:01<00:02, 52.12it/s]\u001b[A\n",
      " 39% 87/221 [00:01<00:02, 53.28it/s]\u001b[A\n",
      " 43% 94/221 [00:01<00:02, 55.80it/s]\u001b[A\n",
      " 45% 100/221 [00:01<00:02, 55.83it/s]\u001b[A\n",
      " 48% 107/221 [00:01<00:01, 59.09it/s]\u001b[A\n",
      " 51% 113/221 [00:01<00:01, 54.51it/s]\u001b[A\n",
      " 54% 120/221 [00:02<00:01, 57.31it/s]\u001b[A\n",
      " 57% 126/221 [00:02<00:01, 56.94it/s]\u001b[A\n",
      " 60% 132/221 [00:02<00:01, 57.32it/s]\u001b[A\n",
      " 62% 138/221 [00:02<00:01, 56.39it/s]\u001b[A\n",
      " 65% 144/221 [00:02<00:01, 54.41it/s]\u001b[A\n",
      " 68% 150/221 [00:02<00:01, 51.95it/s]\u001b[A\n",
      " 71% 156/221 [00:02<00:01, 52.06it/s]\u001b[A\n",
      " 73% 162/221 [00:02<00:01, 48.89it/s]\u001b[A\n",
      " 76% 167/221 [00:03<00:01, 48.45it/s]\u001b[A\n",
      " 78% 173/221 [00:03<00:00, 48.64it/s]\u001b[A\n",
      " 81% 178/221 [00:03<00:00, 46.13it/s]\u001b[A\n",
      " 83% 184/221 [00:03<00:00, 48.11it/s]\u001b[A\n",
      " 86% 191/221 [00:03<00:00, 51.96it/s]\u001b[A\n",
      " 89% 197/221 [00:03<00:00, 51.59it/s]\u001b[A\n",
      " 92% 203/221 [00:03<00:00, 53.76it/s]\u001b[A\n",
      " 95% 210/221 [00:03<00:00, 55.60it/s]\u001b[A\n",
      "100% 221/221 [00:04<00:00, 54.83it/s]\n",
      "12/20/2021 19:01:32 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:01:32 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:01:32 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:01:33 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 114/114 [00:19<00:00,  5.70it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     2.0\n",
      "  eval_HasAns_exact      = 47.9638\n",
      "  eval_HasAns_f1         = 71.4083\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 47.9638\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 71.4083\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 47.9638\n",
      "  eval_f1                = 71.4083\n",
      "  eval_samples           =     907\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 19:01:33,618 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/roberta-base-flm-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/roberta-base-flm-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLVi0OCOQ6nS"
   },
   "source": [
    "## Model 8 - roberta-base-fiqa-flm-sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vVV_rnz3hp1",
    "outputId": "659ab9b1-03d9-4de7-e1ac-db2a0eaa1cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 19:01:47 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 19:01:47 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/runs/Dec20_19-01-47_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 19:01:48 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 19:01:48 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/20/2021 19:01:48 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/20/2021 19:01:48 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/20/2021 19:01:48 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "100% 2/2 [00:00<00:00, 279.55it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 19:01:48,489 >> loading configuration file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 19:01:48,493 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 19:01:48,842 >> Didn't find file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:01:48,848 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:01:48,848 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:01:48,848 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:01:48,848 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:01:48,848 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:01:48,848 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 19:01:50,267 >> loading weights file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 19:01:58,756 >> All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 19:01:58,757 >> All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 19:02:02 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-5209475fd04124e6.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:03<00:00,  3.55s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/20/2021 19:02:03 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-8e1fdd2cf8195755.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:05<00:00,  5.05s/ba]\n",
      "[INFO|trainer.py:1208] 2021-12-20 19:02:12,619 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 19:02:12,619 >>   Num examples = 3516\n",
      "[INFO|trainer.py:1210] 2021-12-20 19:02:12,619 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-20 19:02:12,619 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 19:02:12,619 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 19:02:12,619 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 19:02:12,619 >>   Total optimization steps = 880\n",
      " 23% 200/880 [01:10<03:59,  2.83it/s][INFO|trainer.py:549] 2021-12-20 19:03:23,390 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:03:23,392 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:03:23,392 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:03:23,392 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.23it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.83it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.63it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.20it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.06it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.95it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.86it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.79it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.73it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.61it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.61it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.57it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.58it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.58it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.58it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.56it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.55it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.56it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.55it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.50it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.55it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.55it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.49it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.53it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.52it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:04,  8.49it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.51it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.52it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.51it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.44it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.46it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.45it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.40it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.43it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.47it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.49it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.50it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.46it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.49it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 98% 112/114 [00:13<00:00,  8.53it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.53it/s]\u001b[A12/20/2021 19:03:37 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 80.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 79.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 86.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 38/221 [00:00<00:02, 91.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 89.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 58/221 [00:00<00:01, 86.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 67/221 [00:00<00:01, 84.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 76/221 [00:00<00:01, 80.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 85/221 [00:01<00:02, 54.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42% 93/221 [00:01<00:02, 59.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 101/221 [00:01<00:01, 64.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 109/221 [00:01<00:01, 64.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 117/221 [00:01<00:01, 67.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 126/221 [00:01<00:01, 71.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 73.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 142/221 [00:01<00:01, 74.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 150/221 [00:02<00:00, 73.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 158/221 [00:02<00:00, 67.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 165/221 [00:02<00:00, 67.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 172/221 [00:02<00:00, 66.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 179/221 [00:02<00:00, 63.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 187/221 [00:02<00:00, 66.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 196/221 [00:02<00:00, 71.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 205/221 [00:02<00:00, 74.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:03<00:00, 72.59it/s]\n",
      "12/20/2021 19:03:40 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:03:40 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:03:40 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:03:41 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 43.43891402714932, 'eval_f1': 69.1661607072733, 'eval_total': 221, 'eval_HasAns_exact': 43.43891402714932, 'eval_HasAns_f1': 69.1661607072733, 'eval_HasAns_total': 221, 'eval_best_exact': 43.43891402714932, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 69.1661607072733, 'eval_best_f1_thresh': 0.0, 'epoch': 0.45}\n",
      " 23% 200/880 [01:28<03:59,  2.83it/s]\n",
      "100% 114/114 [00:17<00:00,  8.53it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:03:41,061 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:03:41,067 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:03:44,265 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:03:44,273 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:03:44,278 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200/special_tokens_map.json\n",
      " 45% 400/880 [02:50<02:49,  2.84it/s][INFO|trainer.py:549] 2021-12-20 19:05:03,241 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:05:03,243 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:05:03,243 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:05:03,244 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.25it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.85it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.68it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.22it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.07it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.87it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.80it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.74it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.71it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.55it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.55it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.59it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.59it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.59it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.57it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.59it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.59it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:06,  8.58it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.59it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.59it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.60it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.61it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.61it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.61it/s]\u001b[A\n",
      " 54% 61/114 [00:06<00:06,  8.60it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.61it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.60it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.60it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.54it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 68% 78/114 [00:08<00:04,  8.60it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.60it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.60it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.60it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.60it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.60it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.59it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.59it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.53it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.59it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.60it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.60it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.61it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.61it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.60it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.60it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.62it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.62it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.62it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.59it/s]\u001b[A12/20/2021 19:05:17 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 85.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 84.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 89.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 99.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 95.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 90.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 70/221 [00:00<00:01, 87.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 79/221 [00:00<00:01, 83.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 88/221 [00:01<00:01, 78.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 97/221 [00:01<00:01, 79.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 79.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 115/221 [00:01<00:01, 79.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 124/221 [00:01<00:01, 79.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 133/221 [00:01<00:01, 80.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 142/221 [00:01<00:00, 79.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 150/221 [00:01<00:00, 75.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 158/221 [00:01<00:00, 73.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 166/221 [00:02<00:00, 70.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 174/221 [00:02<00:00, 68.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 181/221 [00:02<00:00, 67.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 190/221 [00:02<00:00, 72.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 198/221 [00:02<00:00, 74.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 207/221 [00:02<00:00, 77.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 79.78it/s]\n",
      "12/20/2021 19:05:20 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:05:20 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:05:20 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:05:20 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 49.321266968325794, 'eval_f1': 70.42596830206043, 'eval_total': 221, 'eval_HasAns_exact': 49.321266968325794, 'eval_HasAns_f1': 70.42596830206043, 'eval_HasAns_total': 221, 'eval_best_exact': 49.321266968325794, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 70.42596830206043, 'eval_best_f1_thresh': 0.0, 'epoch': 0.91}\n",
      " 45% 400/880 [03:07<02:49,  2.84it/s]\n",
      "100% 114/114 [00:17<00:00,  8.59it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:05:20,593 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:05:20,600 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:05:23,288 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:05:23,296 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:05:23,301 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:05:29,762 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 0.8745, 'learning_rate': 1.0795454545454547e-05, 'epoch': 1.14}\n",
      " 68% 600/880 [04:29<01:38,  2.84it/s][INFO|trainer.py:549] 2021-12-20 19:06:41,799 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:06:41,801 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:06:41,801 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:06:41,801 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.25it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.83it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.68it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.16it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.04it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.93it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.85it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.79it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.74it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.61it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.62it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.47it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.53it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.56it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.58it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.58it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.56it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.60it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.60it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.59it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.60it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.59it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.57it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.60it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.59it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.60it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.59it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:06,  8.59it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.60it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.60it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.61it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.61it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.49it/s]\u001b[A\n",
      " 54% 61/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.53it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.60it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.60it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.60it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:04,  8.60it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.60it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.60it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.60it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.58it/s]\u001b[A\n",
      " 68% 78/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.59it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.59it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.60it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.60it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.60it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.58it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.59it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.59it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.59it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.60it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.61it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.60it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.60it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.56it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.59it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.60it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.59it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.59it/s]\u001b[A12/20/2021 19:06:56 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 83.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 82.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 88.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 100.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 51/221 [00:00<00:01, 96.17it/s] \u001b[A\u001b[A\n",
      "\n",
      " 28% 61/221 [00:00<00:01, 91.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 71/221 [00:00<00:01, 84.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 80/221 [00:00<00:01, 80.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 89/221 [00:01<00:01, 80.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:01<00:01, 81.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 107/221 [00:01<00:01, 80.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 116/221 [00:01<00:01, 81.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 125/221 [00:01<00:01, 83.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 134/221 [00:01<00:01, 82.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 143/221 [00:01<00:00, 81.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 152/221 [00:01<00:00, 74.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 160/221 [00:01<00:00, 73.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 168/221 [00:02<00:00, 70.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 176/221 [00:02<00:00, 68.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 184/221 [00:02<00:00, 70.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 193/221 [00:02<00:00, 73.13it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 202/221 [00:02<00:00, 77.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 211/221 [00:02<00:00, 80.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 80.47it/s]\n",
      "12/20/2021 19:06:58 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:06:58 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:06:58 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:06:59 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 45.70135746606335, 'eval_f1': 67.08475754056293, 'eval_total': 221, 'eval_HasAns_exact': 45.70135746606335, 'eval_HasAns_f1': 67.08475754056293, 'eval_HasAns_total': 221, 'eval_best_exact': 45.70135746606335, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 67.08475754056293, 'eval_best_f1_thresh': 0.0, 'epoch': 1.36}\n",
      " 68% 600/880 [04:46<01:38,  2.84it/s]\n",
      "100% 114/114 [00:17<00:00,  8.59it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:06:59,074 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:06:59,080 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:07:01,808 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:07:01,815 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:07:01,820 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:07:07,630 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 91% 800/880 [06:05<00:28,  2.83it/s][INFO|trainer.py:549] 2021-12-20 19:08:18,595 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:08:18,597 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:08:18,598 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:08:18,598 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.22it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.73it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.62it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.18it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.04it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.92it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.84it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.78it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.74it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.60it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.61it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.60it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.59it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.61it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.61it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:09,  8.61it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.61it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.61it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.61it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.61it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.60it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.52it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.57it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.57it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.57it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.58it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.57it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.56it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.58it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.59it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.58it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.58it/s]\u001b[A\n",
      " 54% 61/114 [00:06<00:06,  8.58it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.54it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.53it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.54it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.51it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 68% 78/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.58it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.58it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.50it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.53it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.55it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.59it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.60it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.60it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.61it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.61it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.61it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.60it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.60it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.61it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.61it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.61it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.61it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.61it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.62it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.63it/s]\u001b[A12/20/2021 19:08:32 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 75.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7% 16/221 [00:00<00:02, 77.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 25/221 [00:00<00:02, 80.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 37/221 [00:00<00:01, 95.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 47/221 [00:00<00:01, 96.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26% 57/221 [00:00<00:01, 91.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30% 67/221 [00:00<00:01, 89.28it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34% 76/221 [00:00<00:01, 84.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 85/221 [00:00<00:01, 83.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 94/221 [00:01<00:01, 81.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47% 103/221 [00:01<00:01, 79.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 112/221 [00:01<00:01, 80.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 121/221 [00:01<00:01, 81.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:01, 79.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 139/221 [00:01<00:01, 80.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 148/221 [00:01<00:00, 78.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 156/221 [00:01<00:00, 75.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 164/221 [00:02<00:00, 72.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 172/221 [00:02<00:00, 66.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 179/221 [00:02<00:00, 66.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 188/221 [00:02<00:00, 70.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 196/221 [00:02<00:00, 72.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 205/221 [00:02<00:00, 76.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 79.47it/s]\n",
      "12/20/2021 19:08:35 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:08:35 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:08:35 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:08:35 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact': 45.248868778280546, 'eval_f1': 67.36800189264167, 'eval_total': 221, 'eval_HasAns_exact': 45.248868778280546, 'eval_HasAns_f1': 67.36800189264167, 'eval_HasAns_total': 221, 'eval_best_exact': 45.248868778280546, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 67.36800189264167, 'eval_best_f1_thresh': 0.0, 'epoch': 1.82}\n",
      " 91% 800/880 [06:23<00:28,  2.83it/s]\n",
      "100% 114/114 [00:17<00:00,  8.63it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:08:35,896 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:08:35,904 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:08:38,783 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:08:38,788 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:08:38,793 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:08:44,880 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "100% 880/880 [07:00<00:00,  3.27it/s][INFO|trainer.py:1429] 2021-12-20 19:09:13,437 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 420.8192, 'train_samples_per_second': 16.71, 'train_steps_per_second': 2.091, 'train_loss': 0.7235306653109463, 'epoch': 2.0}\n",
      "100% 880/880 [07:00<00:00,  2.09it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 19:09:13,447 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:09:13,455 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:09:16,564 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:09:16,572 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:09:16,579 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =     0.7235\n",
      "  train_runtime            = 0:07:00.81\n",
      "  train_samples            =       3516\n",
      "  train_samples_per_second =      16.71\n",
      "  train_steps_per_second   =      2.091\n",
      "12/20/2021 19:09:16 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 19:09:16,746 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:09:16,748 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:09:16,749 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:09:16,749 >>   Batch size = 8\n",
      " 99% 113/114 [00:13<00:00,  8.03it/s]12/20/2021 19:09:32 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  3% 7/221 [00:00<00:03, 60.73it/s]\u001b[A\n",
      "  6% 14/221 [00:00<00:04, 48.34it/s]\u001b[A\n",
      " 10% 21/221 [00:00<00:03, 52.86it/s]\u001b[A\n",
      " 13% 28/221 [00:00<00:03, 58.00it/s]\u001b[A\n",
      " 16% 35/221 [00:00<00:03, 58.86it/s]\u001b[A\n",
      " 19% 42/221 [00:00<00:02, 61.83it/s]\u001b[A\n",
      " 22% 49/221 [00:00<00:02, 58.13it/s]\u001b[A\n",
      " 25% 56/221 [00:00<00:02, 60.94it/s]\u001b[A\n",
      " 29% 63/221 [00:01<00:02, 61.44it/s]\u001b[A\n",
      " 32% 70/221 [00:01<00:02, 59.92it/s]\u001b[A\n",
      " 35% 77/221 [00:01<00:02, 56.63it/s]\u001b[A\n",
      " 38% 83/221 [00:01<00:02, 57.37it/s]\u001b[A\n",
      " 40% 89/221 [00:01<00:02, 57.30it/s]\u001b[A\n",
      " 43% 95/221 [00:01<00:02, 57.34it/s]\u001b[A\n",
      " 46% 102/221 [00:01<00:01, 60.57it/s]\u001b[A\n",
      " 49% 109/221 [00:01<00:01, 56.78it/s]\u001b[A\n",
      " 52% 116/221 [00:01<00:01, 60.21it/s]\u001b[A\n",
      " 56% 123/221 [00:02<00:01, 59.47it/s]\u001b[A\n",
      " 59% 130/221 [00:02<00:01, 60.41it/s]\u001b[A\n",
      " 62% 137/221 [00:02<00:01, 57.34it/s]\u001b[A\n",
      " 65% 144/221 [00:02<00:01, 59.31it/s]\u001b[A\n",
      " 68% 150/221 [00:02<00:01, 55.14it/s]\u001b[A\n",
      " 71% 156/221 [00:02<00:01, 54.81it/s]\u001b[A\n",
      " 73% 162/221 [00:02<00:01, 50.97it/s]\u001b[A\n",
      " 76% 168/221 [00:02<00:01, 52.24it/s]\u001b[A\n",
      " 79% 174/221 [00:03<00:00, 51.35it/s]\u001b[A\n",
      " 81% 180/221 [00:03<00:00, 52.44it/s]\u001b[A\n",
      " 85% 187/221 [00:03<00:00, 55.33it/s]\u001b[A\n",
      " 88% 194/221 [00:03<00:00, 56.25it/s]\u001b[A\n",
      " 91% 201/221 [00:03<00:00, 57.99it/s]\u001b[A\n",
      " 95% 209/221 [00:03<00:00, 62.99it/s]\u001b[A\n",
      "100% 221/221 [00:03<00:00, 58.03it/s]\n",
      "12/20/2021 19:09:36 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:09:36 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:09:36 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:09:36 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 114/114 [00:19<00:00,  5.83it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     2.0\n",
      "  eval_HasAns_exact      = 46.6063\n",
      "  eval_HasAns_f1         = 70.0128\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 46.6063\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 70.0128\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 46.6063\n",
      "  eval_f1                = 70.0128\n",
      "  eval_samples           =     907\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 19:09:36,857 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-yQIcEAMHSo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmEGTLNIQRBc"
   },
   "source": [
    "## Model 8 - roberta-base-fiqa-flm-sq - 3 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bodu5c-eQRBf",
    "outputId": "de6feafc-80be-4c04-e24b-b0a0f57512d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/20/2021 19:11:37 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/20/2021 19:11:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/runs/Dec20_19-11-37_5bd044a83a98,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/20/2021 19:11:37 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/20/2021 19:11:37 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/20/2021 19:11:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/20/2021 19:11:37 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/20/2021 19:11:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "100% 2/2 [00:00<00:00, 618.04it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-20 19:11:37,892 >> loading configuration file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-20 19:11:37,894 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-20 19:11:37,908 >> Didn't find file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:11:37,910 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:11:37,910 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:11:37,910 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:11:37,910 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:11:37,910 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-20 19:11:37,910 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-20 19:11:38,083 >> loading weights file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-20 19:11:41,376 >> All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-20 19:11:41,376 >> All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
      "12/20/2021 19:11:41 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-5209475fd04124e6.arrow\n",
      "12/20/2021 19:11:41 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-8e1fdd2cf8195755.arrow\n",
      "[INFO|trainer.py:1208] 2021-12-20 19:11:46,816 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-20 19:11:46,816 >>   Num examples = 3516\n",
      "[INFO|trainer.py:1210] 2021-12-20 19:11:46,816 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1211] 2021-12-20 19:11:46,816 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1212] 2021-12-20 19:11:46,816 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1213] 2021-12-20 19:11:46,816 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-20 19:11:46,816 >>   Total optimization steps = 1320\n",
      " 15% 200/1320 [01:11<06:38,  2.81it/s][INFO|trainer.py:549] 2021-12-20 19:12:58,111 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:12:58,114 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:12:58,114 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:12:58,114 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.13it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.80it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.65it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.19it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.04it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.92it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.82it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.75it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.67it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.58it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.56it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.56it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.50it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.54it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.54it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.46it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.49it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.46it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.48it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.50it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.45it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.42it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.45it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.51it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.52it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.53it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.54it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.56it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.48it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.51it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.55it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.55it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.56it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.54it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.56it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.56it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.56it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.49it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.51it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.55it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.55it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.49it/s]\u001b[A12/20/2021 19:13:12 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 86.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 84.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 85.30it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 39/221 [00:00<00:01, 96.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 49/221 [00:00<00:01, 95.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 59/221 [00:00<00:01, 91.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 69/221 [00:00<00:01, 87.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 78/221 [00:00<00:01, 85.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 87/221 [00:00<00:01, 83.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 96/221 [00:01<00:01, 82.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 82.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 79.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 123/221 [00:01<00:01, 80.65it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 132/221 [00:01<00:01, 80.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 141/221 [00:01<00:01, 79.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 149/221 [00:01<00:00, 76.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 157/221 [00:01<00:00, 72.33it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 165/221 [00:02<00:00, 71.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 173/221 [00:02<00:00, 70.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 181/221 [00:02<00:00, 67.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 189/221 [00:02<00:00, 71.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 197/221 [00:02<00:00, 50.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 206/221 [00:02<00:00, 57.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 75.40it/s]\n",
      "12/20/2021 19:13:15 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:13:15 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:13:15 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:13:15 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                      \n",
      "\u001b[A{'eval_exact': 43.89140271493213, 'eval_f1': 67.88219758858226, 'eval_total': 221, 'eval_HasAns_exact': 43.89140271493213, 'eval_HasAns_f1': 67.88219758858226, 'eval_HasAns_total': 221, 'eval_best_exact': 43.89140271493213, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 67.88219758858226, 'eval_best_f1_thresh': 0.0, 'epoch': 0.45}\n",
      " 15% 200/1320 [01:28<06:38,  2.81it/s]\n",
      "100% 114/114 [00:17<00:00,  8.49it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:13:15,611 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:13:15,618 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:13:18,555 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:13:18,562 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:13:18,568 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:13:24,838 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800] due to args.save_total_limit\n",
      " 30% 400/1320 [02:50<05:26,  2.82it/s][INFO|trainer.py:549] 2021-12-20 19:14:37,427 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:14:37,430 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:14:37,430 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:14:37,430 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.23it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.87it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.71it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.19it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.06it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.96it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.88it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.81it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.75it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.72it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.69it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.66it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.61it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.61it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.62it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.62it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.62it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.61it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.62it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.62it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.62it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:09,  8.62it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.62it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.57it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.59it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.60it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.61it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.62it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.62it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.60it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.61it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.61it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.61it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.61it/s]\u001b[A\n",
      " 39% 44/114 [00:04<00:08,  8.61it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.62it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.63it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.64it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.64it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.64it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.63it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.62it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.62it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.63it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:06,  8.63it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.63it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.62it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.62it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.59it/s]\u001b[A\n",
      " 54% 61/114 [00:06<00:06,  8.60it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.61it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.61it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.61it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.61it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.60it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.61it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.61it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.62it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:04,  8.62it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.62it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.62it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.61it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 68% 78/114 [00:08<00:04,  8.59it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.60it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.61it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.61it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.61it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.60it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.61it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.61it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.61it/s]\u001b[A\n",
      " 76% 87/114 [00:09<00:03,  8.62it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.63it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.62it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.60it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.60it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.59it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.62it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.62it/s]\u001b[A\n",
      " 91% 104/114 [00:11<00:01,  8.61it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.62it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.61it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.61it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.61it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.58it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.60it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.61it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.61it/s]\u001b[A12/20/2021 19:14:51 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 89.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 89.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 93.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19% 41/221 [00:00<00:01, 105.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 52/221 [00:00<00:01, 96.24it/s] \u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:01, 93.38it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 72/221 [00:00<00:01, 90.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 82/221 [00:00<00:01, 87.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 91/221 [00:00<00:01, 87.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 100/221 [00:01<00:01, 87.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 109/221 [00:01<00:01, 86.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 118/221 [00:01<00:01, 86.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 127/221 [00:01<00:01, 85.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 136/221 [00:01<00:01, 79.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 145/221 [00:01<00:00, 79.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 153/221 [00:01<00:00, 77.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:01<00:00, 75.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 169/221 [00:02<00:00, 73.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 71.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 185/221 [00:02<00:00, 73.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 195/221 [00:02<00:00, 78.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 204/221 [00:02<00:00, 79.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96% 212/221 [00:02<00:00, 79.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 83.38it/s]\n",
      "12/20/2021 19:14:54 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:14:54 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:14:54 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:14:54 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                      \n",
      "\u001b[A{'eval_exact': 48.86877828054298, 'eval_f1': 70.14499803196861, 'eval_total': 221, 'eval_HasAns_exact': 48.86877828054298, 'eval_HasAns_f1': 70.14499803196861, 'eval_HasAns_total': 221, 'eval_best_exact': 48.86877828054298, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 70.14499803196861, 'eval_best_f1_thresh': 0.0, 'epoch': 0.91}\n",
      " 30% 400/1320 [03:07<05:26,  2.82it/s]\n",
      "100% 114/114 [00:16<00:00,  8.61it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:14:54,525 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:14:54,536 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:14:57,027 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:14:57,033 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:14:57,039 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:15:02,800 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-200] due to args.save_total_limit\n",
      "{'loss': 0.893, 'learning_rate': 1.553030303030303e-05, 'epoch': 1.14}\n",
      " 45% 600/1320 [04:27<04:16,  2.81it/s][INFO|trainer.py:549] 2021-12-20 19:16:13,890 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:16:13,892 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:16:13,892 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:16:13,892 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 16.76it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.73it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.62it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.18it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.03it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.91it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.80it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.69it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.58it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.58it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.54it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.55it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.55it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.54it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.48it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.55it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.54it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.54it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.56it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.57it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.57it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.52it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.56it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.56it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.56it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.56it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.53it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.54it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.55it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.46it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.49it/s]\u001b[A12/20/2021 19:16:28 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 8/221 [00:00<00:02, 76.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 17/221 [00:00<00:02, 82.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12% 27/221 [00:00<00:02, 88.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 39/221 [00:00<00:01, 100.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 98.05it/s] \u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 91.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 70/221 [00:00<00:01, 89.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36% 79/221 [00:00<00:01, 87.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 88/221 [00:00<00:01, 84.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 97/221 [00:01<00:01, 80.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 82.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 115/221 [00:01<00:01, 81.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 124/221 [00:01<00:01, 82.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 133/221 [00:01<00:01, 82.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 142/221 [00:01<00:00, 80.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 74.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72% 159/221 [00:01<00:00, 73.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 167/221 [00:02<00:00, 71.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:02<00:00, 69.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 182/221 [00:02<00:00, 68.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 191/221 [00:02<00:00, 74.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 200/221 [00:02<00:00, 78.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:02<00:00, 81.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 81.34it/s]\n",
      "12/20/2021 19:16:31 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:16:31 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:16:31 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:16:31 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                      \n",
      "\u001b[A{'eval_exact': 42.98642533936651, 'eval_f1': 66.92462882918217, 'eval_total': 221, 'eval_HasAns_exact': 42.98642533936651, 'eval_HasAns_f1': 66.92462882918217, 'eval_HasAns_total': 221, 'eval_best_exact': 42.98642533936651, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 66.92462882918217, 'eval_best_f1_thresh': 0.0, 'epoch': 1.36}\n",
      " 45% 600/1320 [04:44<04:16,  2.81it/s]\n",
      "100% 114/114 [00:17<00:00,  8.49it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:16:31,186 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:16:31,193 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:16:33,803 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:16:33,812 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:16:33,819 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:16:39,272 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-400] due to args.save_total_limit\n",
      " 61% 800/1320 [06:03<03:05,  2.80it/s][INFO|trainer.py:549] 2021-12-20 19:17:50,657 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:17:50,659 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:17:50,659 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:17:50,659 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.19it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.80it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.64it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.15it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  9.02it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.91it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.82it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.68it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.64it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.58it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.50it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.51it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.53it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.53it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.47it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:10,  8.50it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.52it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.49it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.51it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.52it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.53it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.54it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.55it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.51it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.54it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.55it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.48it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.50it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.53it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.54it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.48it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.51it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.53it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.54it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.55it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.55it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.52it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.54it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.54it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.53it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.55it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.54it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.55it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.52it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.54it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.53it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.52it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.52it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.54it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.55it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.56it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.56it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.57it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.49it/s]\u001b[A\n",
      " 98% 112/114 [00:13<00:00,  8.51it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.52it/s]\u001b[A12/20/2021 19:18:05 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 83.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 83.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 88.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 99.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 89.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 88.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 69/221 [00:00<00:01, 84.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 78/221 [00:00<00:01, 83.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 87/221 [00:01<00:01, 83.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 96/221 [00:01<00:01, 81.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 81.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 82.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 123/221 [00:01<00:01, 81.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 132/221 [00:01<00:01, 79.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 141/221 [00:01<00:01, 78.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 149/221 [00:01<00:00, 77.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 157/221 [00:01<00:00, 75.41it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 165/221 [00:02<00:00, 70.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 173/221 [00:02<00:00, 69.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 180/221 [00:02<00:00, 69.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 188/221 [00:02<00:00, 70.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 197/221 [00:02<00:00, 75.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 206/221 [00:02<00:00, 78.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 80.13it/s]\n",
      "12/20/2021 19:18:07 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:18:07 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:18:07 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:18:08 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                      \n",
      "\u001b[A{'eval_exact': 47.05882352941177, 'eval_f1': 71.15915076933301, 'eval_total': 221, 'eval_HasAns_exact': 47.05882352941177, 'eval_HasAns_f1': 71.15915076933301, 'eval_HasAns_total': 221, 'eval_best_exact': 47.05882352941177, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 71.15915076933301, 'eval_best_f1_thresh': 0.0, 'epoch': 1.82}\n",
      " 61% 800/1320 [06:21<03:05,  2.80it/s]\n",
      "100% 114/114 [00:17<00:00,  8.52it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:18:08,014 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:18:08,021 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:18:10,638 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:18:10,644 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:18:10,649 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:18:16,080 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-600] due to args.save_total_limit\n",
      "{'loss': 0.5081, 'learning_rate': 6.060606060606061e-06, 'epoch': 2.27}\n",
      " 76% 1000/1320 [07:40<01:53,  2.82it/s][INFO|trainer.py:549] 2021-12-20 19:19:27,287 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:19:27,290 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:19:27,290 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:19:27,290 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.14it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.66it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.58it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.11it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  8.98it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.88it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.80it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.70it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.66it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.63it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.61it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.57it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.57it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.57it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.55it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.55it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.56it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.56it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.56it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.49it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.52it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.53it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.55it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.56it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.57it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.58it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.59it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.57it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.57it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.53it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.55it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.56it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.54it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.53it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.54it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.57it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.56it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 83% 95/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.57it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.59it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.58it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.57it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.51it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.53it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.50it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.52it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.54it/s]\u001b[A12/20/2021 19:19:41 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 87.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 86.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 87.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 99.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 51/221 [00:00<00:01, 93.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 61/221 [00:00<00:01, 92.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 71/221 [00:00<00:01, 90.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37% 81/221 [00:00<00:01, 85.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41% 90/221 [00:01<00:01, 86.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45% 99/221 [00:01<00:01, 85.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 108/221 [00:01<00:01, 81.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 117/221 [00:01<00:01, 80.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 126/221 [00:01<00:01, 82.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 135/221 [00:01<00:01, 80.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 144/221 [00:01<00:00, 80.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 153/221 [00:01<00:00, 76.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:01<00:00, 73.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 169/221 [00:02<00:00, 72.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:02<00:00, 70.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 185/221 [00:02<00:00, 72.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 194/221 [00:02<00:00, 75.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 203/221 [00:02<00:00, 77.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 82.04it/s]\n",
      "12/20/2021 19:19:44 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:19:44 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:19:44 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:19:44 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                       \n",
      "\u001b[A{'eval_exact': 45.248868778280546, 'eval_f1': 65.9303041047786, 'eval_total': 221, 'eval_HasAns_exact': 45.248868778280546, 'eval_HasAns_f1': 65.9303041047786, 'eval_HasAns_total': 221, 'eval_best_exact': 45.248868778280546, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 65.9303041047786, 'eval_best_f1_thresh': 0.0, 'epoch': 2.27}\n",
      " 76% 1000/1320 [07:57<01:53,  2.82it/s]\n",
      "100% 114/114 [00:17<00:00,  8.54it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:19:44,550 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:19:44,558 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:19:47,415 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:19:47,423 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:19:47,430 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:19:53,342 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-800] due to args.save_total_limit\n",
      " 91% 1200/1320 [09:17<00:42,  2.82it/s][INFO|trainer.py:549] 2021-12-20 19:21:04,488 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:21:04,491 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:21:04,491 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:21:04,491 >>   Batch size = 8\n",
      "\n",
      "  0% 0/114 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 2/114 [00:00<00:06, 17.16it/s]\u001b[A\n",
      "  4% 4/114 [00:00<00:10, 10.78it/s]\u001b[A\n",
      "  5% 6/114 [00:00<00:11,  9.57it/s]\u001b[A\n",
      "  7% 8/114 [00:00<00:11,  9.10it/s]\u001b[A\n",
      "  8% 9/114 [00:00<00:11,  8.98it/s]\u001b[A\n",
      "  9% 10/114 [00:01<00:11,  8.88it/s]\u001b[A\n",
      " 10% 11/114 [00:01<00:11,  8.80it/s]\u001b[A\n",
      " 11% 12/114 [00:01<00:11,  8.65it/s]\u001b[A\n",
      " 11% 13/114 [00:01<00:11,  8.62it/s]\u001b[A\n",
      " 12% 14/114 [00:01<00:11,  8.60it/s]\u001b[A\n",
      " 13% 15/114 [00:01<00:11,  8.59it/s]\u001b[A\n",
      " 14% 16/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 15% 17/114 [00:01<00:11,  8.58it/s]\u001b[A\n",
      " 16% 18/114 [00:01<00:11,  8.51it/s]\u001b[A\n",
      " 17% 19/114 [00:02<00:11,  8.52it/s]\u001b[A\n",
      " 18% 20/114 [00:02<00:11,  8.54it/s]\u001b[A\n",
      " 18% 21/114 [00:02<00:10,  8.54it/s]\u001b[A\n",
      " 19% 22/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 20% 23/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 21% 24/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 22% 25/114 [00:02<00:10,  8.55it/s]\u001b[A\n",
      " 23% 26/114 [00:02<00:10,  8.56it/s]\u001b[A\n",
      " 24% 27/114 [00:03<00:10,  8.56it/s]\u001b[A\n",
      " 25% 28/114 [00:03<00:10,  8.55it/s]\u001b[A\n",
      " 25% 29/114 [00:03<00:09,  8.56it/s]\u001b[A\n",
      " 26% 30/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 27% 31/114 [00:03<00:09,  8.48it/s]\u001b[A\n",
      " 28% 32/114 [00:03<00:09,  8.51it/s]\u001b[A\n",
      " 29% 33/114 [00:03<00:09,  8.53it/s]\u001b[A\n",
      " 30% 34/114 [00:03<00:09,  8.54it/s]\u001b[A\n",
      " 31% 35/114 [00:03<00:09,  8.55it/s]\u001b[A\n",
      " 32% 36/114 [00:04<00:09,  8.54it/s]\u001b[A\n",
      " 32% 37/114 [00:04<00:09,  8.55it/s]\u001b[A\n",
      " 33% 38/114 [00:04<00:08,  8.56it/s]\u001b[A\n",
      " 34% 39/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 35% 40/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 36% 41/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 37% 42/114 [00:04<00:08,  8.57it/s]\u001b[A\n",
      " 38% 43/114 [00:04<00:08,  8.58it/s]\u001b[A\n",
      " 39% 44/114 [00:05<00:08,  8.53it/s]\u001b[A\n",
      " 39% 45/114 [00:05<00:08,  8.55it/s]\u001b[A\n",
      " 40% 46/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 41% 47/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 42% 48/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 43% 49/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 44% 50/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 45% 51/114 [00:05<00:07,  8.55it/s]\u001b[A\n",
      " 46% 52/114 [00:05<00:07,  8.56it/s]\u001b[A\n",
      " 46% 53/114 [00:06<00:07,  8.57it/s]\u001b[A\n",
      " 47% 54/114 [00:06<00:07,  8.57it/s]\u001b[A\n",
      " 48% 55/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 49% 56/114 [00:06<00:06,  8.57it/s]\u001b[A\n",
      " 50% 57/114 [00:06<00:06,  8.50it/s]\u001b[A\n",
      " 51% 58/114 [00:06<00:06,  8.52it/s]\u001b[A\n",
      " 52% 59/114 [00:06<00:06,  8.54it/s]\u001b[A\n",
      " 53% 60/114 [00:06<00:06,  8.55it/s]\u001b[A\n",
      " 54% 61/114 [00:07<00:06,  8.55it/s]\u001b[A\n",
      " 54% 62/114 [00:07<00:06,  8.56it/s]\u001b[A\n",
      " 55% 63/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 56% 64/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 57% 65/114 [00:07<00:05,  8.57it/s]\u001b[A\n",
      " 58% 66/114 [00:07<00:05,  8.58it/s]\u001b[A\n",
      " 59% 67/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 60% 68/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 69/114 [00:07<00:05,  8.56it/s]\u001b[A\n",
      " 61% 70/114 [00:08<00:05,  8.57it/s]\u001b[A\n",
      " 62% 71/114 [00:08<00:05,  8.56it/s]\u001b[A\n",
      " 63% 72/114 [00:08<00:04,  8.57it/s]\u001b[A\n",
      " 64% 73/114 [00:08<00:04,  8.56it/s]\u001b[A\n",
      " 65% 74/114 [00:08<00:04,  8.48it/s]\u001b[A\n",
      " 66% 75/114 [00:08<00:04,  8.42it/s]\u001b[A\n",
      " 67% 76/114 [00:08<00:04,  8.47it/s]\u001b[A\n",
      " 68% 77/114 [00:08<00:04,  8.50it/s]\u001b[A\n",
      " 68% 78/114 [00:09<00:04,  8.52it/s]\u001b[A\n",
      " 69% 79/114 [00:09<00:04,  8.52it/s]\u001b[A\n",
      " 70% 80/114 [00:09<00:03,  8.52it/s]\u001b[A\n",
      " 71% 81/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 72% 82/114 [00:09<00:03,  8.55it/s]\u001b[A\n",
      " 73% 83/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 74% 84/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 75% 85/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 75% 86/114 [00:09<00:03,  8.56it/s]\u001b[A\n",
      " 76% 87/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 77% 88/114 [00:10<00:03,  8.57it/s]\u001b[A\n",
      " 78% 89/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 79% 90/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 80% 91/114 [00:10<00:02,  8.57it/s]\u001b[A\n",
      " 81% 92/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 82% 93/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 82% 94/114 [00:10<00:02,  8.58it/s]\u001b[A\n",
      " 83% 95/114 [00:11<00:02,  8.59it/s]\u001b[A\n",
      " 84% 96/114 [00:11<00:02,  8.58it/s]\u001b[A\n",
      " 85% 97/114 [00:11<00:01,  8.58it/s]\u001b[A\n",
      " 86% 98/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 87% 99/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 88% 100/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 101/114 [00:11<00:01,  8.56it/s]\u001b[A\n",
      " 89% 102/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 90% 103/114 [00:11<00:01,  8.57it/s]\u001b[A\n",
      " 91% 104/114 [00:12<00:01,  8.56it/s]\u001b[A\n",
      " 92% 105/114 [00:12<00:01,  8.52it/s]\u001b[A\n",
      " 93% 106/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 94% 107/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 95% 108/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 96% 109/114 [00:12<00:00,  8.56it/s]\u001b[A\n",
      " 96% 110/114 [00:12<00:00,  8.54it/s]\u001b[A\n",
      " 97% 111/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 98% 112/114 [00:12<00:00,  8.55it/s]\u001b[A\n",
      " 99% 113/114 [00:13<00:00,  8.56it/s]\u001b[A12/20/2021 19:21:18 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4% 9/221 [00:00<00:02, 86.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8% 18/221 [00:00<00:02, 86.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13% 28/221 [00:00<00:02, 90.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 40/221 [00:00<00:01, 98.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 94.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 89.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31% 69/221 [00:00<00:01, 88.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 78/221 [00:00<00:01, 86.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 87/221 [00:00<00:01, 83.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 96/221 [00:01<00:01, 84.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:01<00:01, 85.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 114/221 [00:01<00:01, 84.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 123/221 [00:01<00:01, 83.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 132/221 [00:01<00:01, 80.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 141/221 [00:01<00:00, 80.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 150/221 [00:01<00:00, 77.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 158/221 [00:01<00:00, 76.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75% 166/221 [00:02<00:00, 72.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 174/221 [00:02<00:00, 70.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 182/221 [00:02<00:00, 70.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 190/221 [00:02<00:00, 72.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 200/221 [00:02<00:00, 77.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94% 208/221 [00:02<00:00, 78.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 81.48it/s]\n",
      "12/20/2021 19:21:21 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:21:21 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:21:21 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:21:21 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "                                       \n",
      "\u001b[A{'eval_exact': 47.963800904977376, 'eval_f1': 70.00228630858491, 'eval_total': 221, 'eval_HasAns_exact': 47.963800904977376, 'eval_HasAns_f1': 70.00228630858491, 'eval_HasAns_total': 221, 'eval_best_exact': 47.963800904977376, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 70.00228630858491, 'eval_best_f1_thresh': 0.0, 'epoch': 2.73}\n",
      " 91% 1200/1320 [09:34<00:42,  2.82it/s]\n",
      "100% 114/114 [00:17<00:00,  8.56it/s]\u001b[A\n",
      "                                     \u001b[A[INFO|trainer.py:2037] 2021-12-20 19:21:21,752 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1200\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:21:21,760 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:21:24,334 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:21:24,340 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:21:24,346 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1200/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-20 19:21:29,878 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000] due to args.save_total_limit\n",
      "100% 1320/1320 [10:25<00:00,  3.24it/s][INFO|trainer.py:1429] 2021-12-20 19:22:12,530 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 625.7142, 'train_samples_per_second': 16.858, 'train_steps_per_second': 2.11, 'train_loss': 0.6072982556892164, 'epoch': 3.0}\n",
      "100% 1320/1320 [10:25<00:00,  2.11it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-20 19:22:12,539 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-20 19:22:12,560 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-20 19:22:15,335 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-20 19:22:15,341 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-20 19:22:15,346 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        3.0\n",
      "  train_loss               =     0.6073\n",
      "  train_runtime            = 0:10:25.71\n",
      "  train_samples            =       3516\n",
      "  train_samples_per_second =     16.858\n",
      "  train_steps_per_second   =       2.11\n",
      "12/20/2021 19:22:15 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-20 19:22:15,511 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-20 19:22:15,513 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-20 19:22:15,513 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-20 19:22:15,513 >>   Batch size = 8\n",
      " 99% 113/114 [00:13<00:00,  7.74it/s]12/20/2021 19:22:31 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  2% 5/221 [00:00<00:04, 44.94it/s]\u001b[A\n",
      "  6% 13/221 [00:00<00:03, 59.01it/s]\u001b[A\n",
      "  9% 19/221 [00:00<00:03, 56.11it/s]\u001b[A\n",
      " 12% 26/221 [00:00<00:03, 59.39it/s]\u001b[A\n",
      " 16% 35/221 [00:00<00:02, 67.94it/s]\u001b[A\n",
      " 19% 43/221 [00:00<00:02, 67.90it/s]\u001b[A\n",
      " 23% 51/221 [00:00<00:02, 68.35it/s]\u001b[A\n",
      " 26% 58/221 [00:00<00:02, 60.89it/s]\u001b[A\n",
      " 29% 65/221 [00:01<00:02, 62.82it/s]\u001b[A\n",
      " 33% 72/221 [00:01<00:02, 56.22it/s]\u001b[A\n",
      " 35% 78/221 [00:01<00:02, 56.07it/s]\u001b[A\n",
      " 38% 84/221 [00:01<00:02, 50.53it/s]\u001b[A\n",
      " 41% 90/221 [00:01<00:02, 52.19it/s]\u001b[A\n",
      " 43% 96/221 [00:01<00:02, 52.55it/s]\u001b[A\n",
      " 46% 102/221 [00:01<00:02, 53.55it/s]\u001b[A\n",
      " 49% 108/221 [00:01<00:02, 54.16it/s]\u001b[A\n",
      " 52% 114/221 [00:01<00:01, 54.14it/s]\u001b[A\n",
      " 55% 121/221 [00:02<00:01, 58.24it/s]\u001b[A\n",
      " 57% 127/221 [00:02<00:01, 55.58it/s]\u001b[A\n",
      " 60% 133/221 [00:02<00:01, 54.68it/s]\u001b[A\n",
      " 63% 139/221 [00:02<00:01, 54.56it/s]\u001b[A\n",
      " 66% 145/221 [00:02<00:01, 52.13it/s]\u001b[A\n",
      " 68% 151/221 [00:02<00:01, 53.55it/s]\u001b[A\n",
      " 71% 157/221 [00:02<00:01, 51.11it/s]\u001b[A\n",
      " 74% 163/221 [00:02<00:01, 51.38it/s]\u001b[A\n",
      " 76% 169/221 [00:03<00:01, 47.49it/s]\u001b[A\n",
      " 79% 174/221 [00:03<00:01, 46.42it/s]\u001b[A\n",
      " 81% 179/221 [00:03<00:00, 44.58it/s]\u001b[A\n",
      " 83% 184/221 [00:03<00:00, 45.90it/s]\u001b[A\n",
      " 86% 190/221 [00:03<00:00, 47.77it/s]\u001b[A\n",
      " 90% 198/221 [00:03<00:00, 53.75it/s]\u001b[A\n",
      " 92% 204/221 [00:03<00:00, 52.02it/s]\u001b[A\n",
      " 95% 211/221 [00:03<00:00, 56.60it/s]\u001b[A\n",
      "100% 221/221 [00:04<00:00, 54.59it/s]\n",
      "12/20/2021 19:22:35 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/20/2021 19:22:35 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/20/2021 19:22:35 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/20/2021 19:22:35 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 114/114 [00:19<00:00,  5.72it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =     3.0\n",
      "  eval_HasAns_exact      = 46.1538\n",
      "  eval_HasAns_f1         = 67.4655\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 46.1538\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 67.4655\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 46.1538\n",
      "  eval_f1                = 67.4655\n",
      "  eval_samples           =     907\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-20 19:22:36,056 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 8 \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ck0axkorc_2X"
   },
   "source": [
    "## Model 8 - roberta-base-fiqa-flm-sq - 10 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Z85C8vqc_2u",
    "outputId": "d15d4760-09d1-4832-b7e8-0e94ecb8c6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/21/2021 10:06:09 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/21/2021 10:06:09 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=500,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/runs/Dec21_10-06-09_01444a28871e,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/21/2021 10:06:09 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/21/2021 10:06:09 - INFO - datasets.builder - Generating dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426...\n",
      "\r",
      "  0% 0/2 [00:00<?, ?it/s]\r",
      "100% 2/2 [00:00<00:00, 4070.16it/s]\n",
      "12/21/2021 10:06:09 - INFO - datasets.utils.download_manager - Downloading took 0.0 min\n",
      "12/21/2021 10:06:10 - INFO - datasets.utils.download_manager - Checksum Computation took 0.0 min\n",
      "100% 2/2 [00:00<00:00, 136.62it/s]\n",
      "12/21/2021 10:06:10 - INFO - datasets.utils.info_utils - Unable to verify checksums.\n",
      "12/21/2021 10:06:10 - INFO - datasets.builder - Generating split train\n",
      "12/21/2021 10:06:10 - INFO - datasets.builder - Generating split validation\n",
      "12/21/2021 10:06:10 - INFO - datasets.utils.info_utils - Unable to verify splits sizes.\n",
      "Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426. Subsequent calls will reuse this data.\n",
      "100% 2/2 [00:00<00:00, 310.62it/s]\n",
      "[INFO|configuration_utils.py:602] 2021-12-21 10:06:11,183 >> loading configuration file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/config.json\n",
      "[INFO|configuration_utils.py:641] 2021-12-21 10:06:11,184 >> Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"/content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1671] 2021-12-21 10:06:11,392 >> Didn't find file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/added_tokens.json. We won't load it.\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 10:06:11,393 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 10:06:11,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 10:06:11,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 10:06:11,394 >> loading file None\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 10:06:11,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1740] 2021-12-21 10:06:11,394 >> loading file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:1352] 2021-12-21 10:06:11,947 >> loading weights file /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:1621] 2021-12-21 10:06:17,192 >> All model checkpoint weights were used when initializing RobertaForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-21 10:06:17,192 >> All the weights of RobertaForQuestionAnswering were initialized from the model checkpoint at /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForQuestionAnswering for predictions without further training.\n",
      "Running tokenizer on train dataset:   0% 0/1 [00:00<?, ?ba/s]12/21/2021 10:06:19 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-5209475fd04124e6.arrow\n",
      "Running tokenizer on train dataset: 100% 1/1 [00:02<00:00,  2.19s/ba]\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/21/2021 10:06:20 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-8e1fdd2cf8195755.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:03<00:00,  3.10s/ba]\n",
      "12/21/2021 10:06:22 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/squad_v2.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpd7xzr7if\n",
      "Downloading: 6.49kB [00:00, 5.43MB/s]       \n",
      "12/21/2021 10:06:23 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/squad_v2.py in cache at /root/.cache/huggingface/datasets/downloads/0b3aa4626c2b631dc45b2bf3f7c968f6165a3ad6b3c7792564675873e2d22fd2.55618b68ec0f2e152f32610f6601b047ef46121780662ab1208d50ddcfbcafed.py\n",
      "12/21/2021 10:06:23 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/0b3aa4626c2b631dc45b2bf3f7c968f6165a3ad6b3c7792564675873e2d22fd2.55618b68ec0f2e152f32610f6601b047ef46121780662ab1208d50ddcfbcafed.py\n",
      "12/21/2021 10:06:23 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/evaluate.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpnvbh10gy\n",
      "Downloading: 11.3kB [00:00, 10.4MB/s]       \n",
      "12/21/2021 10:06:23 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad_v2/evaluate.py in cache at /root/.cache/huggingface/datasets/downloads/6447ac1aeba6266d8ff009449c27843a180b7359a4d1b0594f2836e2726a0380.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n",
      "12/21/2021 10:06:23 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/6447ac1aeba6266d8ff009449c27843a180b7359a4d1b0594f2836e2726a0380.05a1750dbac0faed211b316ff86719fdec19d084c7ea3ae500a954598bcf548c.py\n",
      "[INFO|trainer.py:1208] 2021-12-21 10:06:33,524 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-21 10:06:33,524 >>   Num examples = 3516\n",
      "[INFO|trainer.py:1210] 2021-12-21 10:06:33,524 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:1211] 2021-12-21 10:06:33,524 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:1212] 2021-12-21 10:06:33,524 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1213] 2021-12-21 10:06:33,524 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-21 10:06:33,524 >>   Total optimization steps = 2200\n",
      "{'loss': 0.8053, 'learning_rate': 1.931818181818182e-05, 'epoch': 2.27}\n",
      " 23% 500/2200 [05:17<18:00,  1.57it/s][INFO|trainer.py:549] 2021-12-21 10:11:51,313 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 10:11:51,316 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 10:11:51,316 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-21 10:11:51,316 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:05,  9.19it/s]\u001b[A\n",
      "  5% 3/57 [00:00<00:08,  6.48it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:09,  5.62it/s]\u001b[A\n",
      "  9% 5/57 [00:00<00:09,  5.22it/s]\u001b[A\n",
      " 11% 6/57 [00:01<00:10,  4.99it/s]\u001b[A\n",
      " 12% 7/57 [00:01<00:10,  4.85it/s]\u001b[A\n",
      " 14% 8/57 [00:01<00:10,  4.76it/s]\u001b[A\n",
      " 16% 9/57 [00:01<00:10,  4.71it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:10,  4.67it/s]\u001b[A\n",
      " 19% 11/57 [00:02<00:09,  4.65it/s]\u001b[A\n",
      " 21% 12/57 [00:02<00:09,  4.63it/s]\u001b[A\n",
      " 23% 13/57 [00:02<00:09,  4.62it/s]\u001b[A\n",
      " 25% 14/57 [00:02<00:09,  4.62it/s]\u001b[A\n",
      " 26% 15/57 [00:03<00:09,  4.61it/s]\u001b[A\n",
      " 28% 16/57 [00:03<00:08,  4.60it/s]\u001b[A\n",
      " 30% 17/57 [00:03<00:08,  4.60it/s]\u001b[A\n",
      " 32% 18/57 [00:03<00:08,  4.59it/s]\u001b[A\n",
      " 33% 19/57 [00:03<00:08,  4.59it/s]\u001b[A\n",
      " 35% 20/57 [00:04<00:08,  4.57it/s]\u001b[A\n",
      " 37% 21/57 [00:04<00:07,  4.58it/s]\u001b[A\n",
      " 39% 22/57 [00:04<00:07,  4.57it/s]\u001b[A\n",
      " 40% 23/57 [00:04<00:07,  4.58it/s]\u001b[A\n",
      " 42% 24/57 [00:05<00:07,  4.57it/s]\u001b[A\n",
      " 44% 25/57 [00:05<00:06,  4.57it/s]\u001b[A\n",
      " 46% 26/57 [00:05<00:06,  4.58it/s]\u001b[A\n",
      " 47% 27/57 [00:05<00:06,  4.59it/s]\u001b[A\n",
      " 49% 28/57 [00:05<00:06,  4.59it/s]\u001b[A\n",
      " 51% 29/57 [00:06<00:06,  4.58it/s]\u001b[A\n",
      " 53% 30/57 [00:06<00:05,  4.56it/s]\u001b[A\n",
      " 54% 31/57 [00:06<00:05,  4.57it/s]\u001b[A\n",
      " 56% 32/57 [00:06<00:05,  4.58it/s]\u001b[A\n",
      " 58% 33/57 [00:06<00:05,  4.58it/s]\u001b[A\n",
      " 60% 34/57 [00:07<00:05,  4.59it/s]\u001b[A\n",
      " 61% 35/57 [00:07<00:04,  4.59it/s]\u001b[A\n",
      " 63% 36/57 [00:07<00:04,  4.59it/s]\u001b[A\n",
      " 65% 37/57 [00:07<00:04,  4.57it/s]\u001b[A\n",
      " 67% 38/57 [00:08<00:04,  4.58it/s]\u001b[A\n",
      " 68% 39/57 [00:08<00:03,  4.58it/s]\u001b[A\n",
      " 70% 40/57 [00:08<00:03,  4.59it/s]\u001b[A\n",
      " 72% 41/57 [00:08<00:03,  4.59it/s]\u001b[A\n",
      " 74% 42/57 [00:08<00:03,  4.59it/s]\u001b[A\n",
      " 75% 43/57 [00:09<00:03,  4.59it/s]\u001b[A\n",
      " 77% 44/57 [00:09<00:02,  4.59it/s]\u001b[A\n",
      " 79% 45/57 [00:09<00:02,  4.59it/s]\u001b[A\n",
      " 81% 46/57 [00:09<00:02,  4.60it/s]\u001b[A\n",
      " 82% 47/57 [00:10<00:02,  4.60it/s]\u001b[A\n",
      " 84% 48/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 86% 49/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 88% 50/57 [00:10<00:01,  4.59it/s]\u001b[A\n",
      " 89% 51/57 [00:10<00:01,  4.57it/s]\u001b[A\n",
      " 91% 52/57 [00:11<00:01,  4.58it/s]\u001b[A\n",
      " 93% 53/57 [00:11<00:00,  4.56it/s]\u001b[A\n",
      " 95% 54/57 [00:11<00:00,  4.57it/s]\u001b[A\n",
      " 96% 55/57 [00:11<00:00,  4.57it/s]\u001b[A\n",
      " 98% 56/57 [00:11<00:00,  4.58it/s]\u001b[A\n",
      "100% 57/57 [00:12<00:00,  5.05it/s]\u001b[A12/21/2021 10:12:04 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 11/221 [00:00<00:01, 109.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 22/221 [00:00<00:01, 109.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17% 37/221 [00:00<00:01, 125.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23% 50/221 [00:00<00:01, 119.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:01, 115.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 110.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 86/221 [00:00<00:01, 107.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 97/221 [00:00<00:01, 107.76it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 108/221 [00:00<00:01, 106.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 119/221 [00:01<00:00, 105.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:00, 104.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 141/221 [00:01<00:00, 103.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 152/221 [00:01<00:00, 94.20it/s] \u001b[A\u001b[A\n",
      "\n",
      " 73% 162/221 [00:01<00:00, 91.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78% 172/221 [00:01<00:00, 89.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 181/221 [00:01<00:00, 88.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 191/221 [00:01<00:00, 91.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 203/221 [00:01<00:00, 98.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 102.86it/s]\n",
      "12/21/2021 10:12:06 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/21/2021 10:12:06 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/21/2021 10:12:07 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/21/2021 10:12:07 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "\n",
      "{'eval_exact': 46.60633484162896, 'eval_f1': 67.85052738394826, 'eval_total': 221, 'eval_HasAns_exact': 46.60633484162896, 'eval_HasAns_f1': 67.85052738394826, 'eval_HasAns_total': 221, 'eval_best_exact': 46.60633484162896, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 67.85052738394826, 'eval_best_f1_thresh': 0.0, 'epoch': 2.27}\n",
      "\n",
      " 23% 500/2200 [05:33<18:00,  1.57it/s]\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 10:12:07,496 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-500\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 10:12:07,501 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-500/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 10:12:09,833 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-500/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 10:12:09,840 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 10:12:09,853 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-500/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-21 10:12:14,158 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1200] due to args.save_total_limit\n",
      "{'loss': 0.3209, 'learning_rate': 1.3636363636363637e-05, 'epoch': 4.55}\n",
      " 45% 1000/2200 [10:58<12:41,  1.58it/s][INFO|trainer.py:549] 2021-12-21 10:17:31,961 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 10:17:31,963 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 10:17:31,963 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-21 10:17:31,963 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:05,  9.19it/s]\u001b[A\n",
      "  5% 3/57 [00:00<00:08,  6.47it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:09,  5.60it/s]\u001b[A\n",
      "  9% 5/57 [00:00<00:10,  5.18it/s]\u001b[A\n",
      " 11% 6/57 [00:01<00:10,  4.97it/s]\u001b[A\n",
      " 12% 7/57 [00:01<00:10,  4.85it/s]\u001b[A\n",
      " 14% 8/57 [00:01<00:10,  4.77it/s]\u001b[A\n",
      " 16% 9/57 [00:01<00:10,  4.69it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:10,  4.66it/s]\u001b[A\n",
      " 19% 11/57 [00:02<00:09,  4.64it/s]\u001b[A\n",
      " 21% 12/57 [00:02<00:09,  4.63it/s]\u001b[A\n",
      " 23% 13/57 [00:02<00:09,  4.62it/s]\u001b[A\n",
      " 25% 14/57 [00:02<00:09,  4.61it/s]\u001b[A\n",
      " 26% 15/57 [00:03<00:09,  4.58it/s]\u001b[A\n",
      " 28% 16/57 [00:03<00:08,  4.59it/s]\u001b[A\n",
      " 30% 17/57 [00:03<00:08,  4.59it/s]\u001b[A\n",
      " 32% 18/57 [00:03<00:08,  4.59it/s]\u001b[A\n",
      " 33% 19/57 [00:03<00:08,  4.60it/s]\u001b[A\n",
      " 35% 20/57 [00:04<00:08,  4.60it/s]\u001b[A\n",
      " 37% 21/57 [00:04<00:07,  4.60it/s]\u001b[A\n",
      " 39% 22/57 [00:04<00:07,  4.60it/s]\u001b[A\n",
      " 40% 23/57 [00:04<00:07,  4.60it/s]\u001b[A\n",
      " 42% 24/57 [00:05<00:07,  4.60it/s]\u001b[A\n",
      " 44% 25/57 [00:05<00:06,  4.60it/s]\u001b[A\n",
      " 46% 26/57 [00:05<00:06,  4.60it/s]\u001b[A\n",
      " 47% 27/57 [00:05<00:06,  4.60it/s]\u001b[A\n",
      " 49% 28/57 [00:05<00:06,  4.60it/s]\u001b[A\n",
      " 51% 29/57 [00:06<00:06,  4.60it/s]\u001b[A\n",
      " 53% 30/57 [00:06<00:05,  4.60it/s]\u001b[A\n",
      " 54% 31/57 [00:06<00:05,  4.60it/s]\u001b[A\n",
      " 56% 32/57 [00:06<00:05,  4.60it/s]\u001b[A\n",
      " 58% 33/57 [00:06<00:05,  4.60it/s]\u001b[A\n",
      " 60% 34/57 [00:07<00:05,  4.59it/s]\u001b[A\n",
      " 61% 35/57 [00:07<00:04,  4.59it/s]\u001b[A\n",
      " 63% 36/57 [00:07<00:04,  4.59it/s]\u001b[A\n",
      " 65% 37/57 [00:07<00:04,  4.60it/s]\u001b[A\n",
      " 67% 38/57 [00:08<00:04,  4.60it/s]\u001b[A\n",
      " 68% 39/57 [00:08<00:03,  4.60it/s]\u001b[A\n",
      " 70% 40/57 [00:08<00:03,  4.59it/s]\u001b[A\n",
      " 72% 41/57 [00:08<00:03,  4.58it/s]\u001b[A\n",
      " 74% 42/57 [00:08<00:03,  4.59it/s]\u001b[A\n",
      " 75% 43/57 [00:09<00:03,  4.59it/s]\u001b[A\n",
      " 77% 44/57 [00:09<00:02,  4.60it/s]\u001b[A\n",
      " 79% 45/57 [00:09<00:02,  4.60it/s]\u001b[A\n",
      " 81% 46/57 [00:09<00:02,  4.60it/s]\u001b[A\n",
      " 82% 47/57 [00:10<00:02,  4.58it/s]\u001b[A\n",
      " 84% 48/57 [00:10<00:01,  4.59it/s]\u001b[A\n",
      " 86% 49/57 [00:10<00:01,  4.59it/s]\u001b[A\n",
      " 88% 50/57 [00:10<00:01,  4.59it/s]\u001b[A\n",
      " 89% 51/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 91% 52/57 [00:11<00:01,  4.60it/s]\u001b[A\n",
      " 93% 53/57 [00:11<00:00,  4.60it/s]\u001b[A\n",
      " 95% 54/57 [00:11<00:00,  4.60it/s]\u001b[A\n",
      " 96% 55/57 [00:11<00:00,  4.60it/s]\u001b[A\n",
      " 98% 56/57 [00:11<00:00,  4.60it/s]\u001b[A\n",
      "100% 57/57 [00:12<00:00,  5.07it/s]\u001b[A12/21/2021 10:17:45 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 12/221 [00:00<00:01, 107.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11% 24/221 [00:00<00:01, 113.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18% 39/221 [00:00<00:01, 126.81it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24% 52/221 [00:00<00:01, 123.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29% 65/221 [00:00<00:01, 114.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35% 77/221 [00:00<00:01, 111.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40% 89/221 [00:00<00:01, 110.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46% 101/221 [00:00<00:01, 107.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51% 113/221 [00:01<00:00, 108.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56% 124/221 [00:01<00:00, 108.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61% 135/221 [00:01<00:00, 107.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66% 146/221 [00:01<00:00, 103.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71% 157/221 [00:01<00:00, 99.41it/s] \u001b[A\u001b[A\n",
      "\n",
      " 76% 167/221 [00:01<00:00, 92.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80% 177/221 [00:01<00:00, 90.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85% 187/221 [00:01<00:00, 93.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 199/221 [00:01<00:00, 98.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 105.28it/s]\n",
      "12/21/2021 10:17:47 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/21/2021 10:17:47 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/21/2021 10:17:47 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/21/2021 10:17:47 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "\n",
      "{'eval_exact': 43.43891402714932, 'eval_f1': 66.93954657430605, 'eval_total': 221, 'eval_HasAns_exact': 43.43891402714932, 'eval_HasAns_f1': 66.93954657430605, 'eval_HasAns_total': 221, 'eval_best_exact': 43.43891402714932, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 66.93954657430605, 'eval_best_f1_thresh': 0.0, 'epoch': 4.55}\n",
      "\n",
      " 45% 1000/2200 [11:13<12:41,  1.58it/s]\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 10:17:47,434 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 10:17:47,438 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 10:17:49,520 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 10:17:49,987 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 10:17:49,991 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-21 10:17:54,252 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-500] due to args.save_total_limit\n",
      "{'loss': 0.118, 'learning_rate': 7.954545454545455e-06, 'epoch': 6.82}\n",
      " 68% 1500/2200 [16:38<07:24,  1.57it/s][INFO|trainer.py:549] 2021-12-21 10:23:11,863 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 10:23:11,865 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 10:23:11,865 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-21 10:23:11,865 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:06,  9.13it/s]\u001b[A\n",
      "  5% 3/57 [00:00<00:08,  6.48it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:09,  5.62it/s]\u001b[A\n",
      "  9% 5/57 [00:00<00:09,  5.22it/s]\u001b[A\n",
      " 11% 6/57 [00:01<00:10,  4.99it/s]\u001b[A\n",
      " 12% 7/57 [00:01<00:10,  4.82it/s]\u001b[A\n",
      " 14% 8/57 [00:01<00:10,  4.75it/s]\u001b[A\n",
      " 16% 9/57 [00:01<00:10,  4.70it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:10,  4.67it/s]\u001b[A\n",
      " 19% 11/57 [00:02<00:09,  4.65it/s]\u001b[A\n",
      " 21% 12/57 [00:02<00:09,  4.63it/s]\u001b[A\n",
      " 23% 13/57 [00:02<00:09,  4.62it/s]\u001b[A\n",
      " 25% 14/57 [00:02<00:09,  4.62it/s]\u001b[A\n",
      " 26% 15/57 [00:03<00:09,  4.61it/s]\u001b[A\n",
      " 28% 16/57 [00:03<00:08,  4.61it/s]\u001b[A\n",
      " 30% 17/57 [00:03<00:08,  4.59it/s]\u001b[A\n",
      " 32% 18/57 [00:03<00:08,  4.59it/s]\u001b[A\n",
      " 33% 19/57 [00:03<00:08,  4.58it/s]\u001b[A\n",
      " 35% 20/57 [00:04<00:08,  4.59it/s]\u001b[A\n",
      " 37% 21/57 [00:04<00:07,  4.59it/s]\u001b[A\n",
      " 39% 22/57 [00:04<00:07,  4.59it/s]\u001b[A\n",
      " 40% 23/57 [00:04<00:07,  4.60it/s]\u001b[A\n",
      " 42% 24/57 [00:05<00:07,  4.59it/s]\u001b[A\n",
      " 44% 25/57 [00:05<00:07,  4.56it/s]\u001b[A\n",
      " 46% 26/57 [00:05<00:06,  4.57it/s]\u001b[A\n",
      " 47% 27/57 [00:05<00:06,  4.58it/s]\u001b[A\n",
      " 49% 28/57 [00:05<00:06,  4.58it/s]\u001b[A\n",
      " 51% 29/57 [00:06<00:06,  4.58it/s]\u001b[A\n",
      " 53% 30/57 [00:06<00:05,  4.59it/s]\u001b[A\n",
      " 54% 31/57 [00:06<00:05,  4.58it/s]\u001b[A\n",
      " 56% 32/57 [00:06<00:05,  4.59it/s]\u001b[A\n",
      " 58% 33/57 [00:06<00:05,  4.59it/s]\u001b[A\n",
      " 60% 34/57 [00:07<00:05,  4.59it/s]\u001b[A\n",
      " 61% 35/57 [00:07<00:04,  4.58it/s]\u001b[A\n",
      " 63% 36/57 [00:07<00:04,  4.59it/s]\u001b[A\n",
      " 65% 37/57 [00:07<00:04,  4.59it/s]\u001b[A\n",
      " 67% 38/57 [00:08<00:04,  4.59it/s]\u001b[A\n",
      " 68% 39/57 [00:08<00:03,  4.59it/s]\u001b[A\n",
      " 70% 40/57 [00:08<00:03,  4.59it/s]\u001b[A\n",
      " 72% 41/57 [00:08<00:03,  4.60it/s]\u001b[A\n",
      " 74% 42/57 [00:08<00:03,  4.60it/s]\u001b[A\n",
      " 75% 43/57 [00:09<00:03,  4.60it/s]\u001b[A\n",
      " 77% 44/57 [00:09<00:02,  4.60it/s]\u001b[A\n",
      " 79% 45/57 [00:09<00:02,  4.60it/s]\u001b[A\n",
      " 81% 46/57 [00:09<00:02,  4.60it/s]\u001b[A\n",
      " 82% 47/57 [00:10<00:02,  4.60it/s]\u001b[A\n",
      " 84% 48/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 86% 49/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 88% 50/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 89% 51/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 91% 52/57 [00:11<00:01,  4.60it/s]\u001b[A\n",
      " 93% 53/57 [00:11<00:00,  4.59it/s]\u001b[A\n",
      " 95% 54/57 [00:11<00:00,  4.59it/s]\u001b[A\n",
      " 96% 55/57 [00:11<00:00,  4.59it/s]\u001b[A\n",
      " 98% 56/57 [00:11<00:00,  4.59it/s]\u001b[A\n",
      "100% 57/57 [00:12<00:00,  5.05it/s]\u001b[A12/21/2021 10:23:25 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 11/221 [00:00<00:01, 109.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 22/221 [00:00<00:01, 108.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:01, 120.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 49/221 [00:00<00:01, 124.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:01, 116.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 113.83it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 86/221 [00:00<00:01, 110.19it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 98/221 [00:00<00:01, 105.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50% 110/221 [00:00<00:01, 107.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55% 122/221 [00:01<00:00, 108.43it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60% 133/221 [00:01<00:00, 106.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65% 144/221 [00:01<00:00, 104.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70% 155/221 [00:01<00:00, 98.43it/s] \u001b[A\u001b[A\n",
      "\n",
      " 75% 165/221 [00:01<00:00, 96.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79% 175/221 [00:01<00:00, 93.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84% 185/221 [00:01<00:00, 93.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89% 197/221 [00:01<00:00, 99.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95% 209/221 [00:01<00:00, 103.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 105.54it/s]\n",
      "12/21/2021 10:23:27 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/21/2021 10:23:27 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/21/2021 10:23:27 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/21/2021 10:23:27 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "\n",
      "{'eval_exact': 44.796380090497735, 'eval_f1': 65.92470083753952, 'eval_total': 221, 'eval_HasAns_exact': 44.796380090497735, 'eval_HasAns_f1': 65.92470083753952, 'eval_HasAns_total': 221, 'eval_best_exact': 44.796380090497735, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 65.92470083753952, 'eval_best_f1_thresh': 0.0, 'epoch': 6.82}\n",
      "\n",
      " 68% 1500/2200 [16:53<07:24,  1.57it/s]\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 10:23:27,319 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1500\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 10:23:27,345 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1500/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 10:23:29,309 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1500/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 10:23:29,314 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 10:23:29,319 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1500/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-21 10:23:33,467 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1000] due to args.save_total_limit\n",
      "{'loss': 0.0549, 'learning_rate': 2.2727272727272728e-06, 'epoch': 9.09}\n",
      " 91% 2000/2200 [22:17<02:07,  1.57it/s][INFO|trainer.py:549] 2021-12-21 10:28:50,917 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 10:28:50,920 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 10:28:50,920 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-21 10:28:50,920 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:05,  9.21it/s]\u001b[A\n",
      "  5% 3/57 [00:00<00:08,  6.50it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:09,  5.63it/s]\u001b[A\n",
      "  9% 5/57 [00:00<00:09,  5.23it/s]\u001b[A\n",
      " 11% 6/57 [00:01<00:10,  5.00it/s]\u001b[A\n",
      " 12% 7/57 [00:01<00:10,  4.83it/s]\u001b[A\n",
      " 14% 8/57 [00:01<00:10,  4.76it/s]\u001b[A\n",
      " 16% 9/57 [00:01<00:10,  4.70it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:10,  4.67it/s]\u001b[A\n",
      " 19% 11/57 [00:02<00:09,  4.65it/s]\u001b[A\n",
      " 21% 12/57 [00:02<00:09,  4.63it/s]\u001b[A\n",
      " 23% 13/57 [00:02<00:09,  4.59it/s]\u001b[A\n",
      " 25% 14/57 [00:02<00:09,  4.59it/s]\u001b[A\n",
      " 26% 15/57 [00:03<00:09,  4.60it/s]\u001b[A\n",
      " 28% 16/57 [00:03<00:08,  4.60it/s]\u001b[A\n",
      " 30% 17/57 [00:03<00:08,  4.60it/s]\u001b[A\n",
      " 32% 18/57 [00:03<00:08,  4.60it/s]\u001b[A\n",
      " 33% 19/57 [00:03<00:08,  4.60it/s]\u001b[A\n",
      " 35% 20/57 [00:04<00:08,  4.60it/s]\u001b[A\n",
      " 37% 21/57 [00:04<00:07,  4.60it/s]\u001b[A\n",
      " 39% 22/57 [00:04<00:07,  4.60it/s]\u001b[A\n",
      " 40% 23/57 [00:04<00:07,  4.60it/s]\u001b[A\n",
      " 42% 24/57 [00:05<00:07,  4.60it/s]\u001b[A\n",
      " 44% 25/57 [00:05<00:06,  4.60it/s]\u001b[A\n",
      " 46% 26/57 [00:05<00:06,  4.60it/s]\u001b[A\n",
      " 47% 27/57 [00:05<00:06,  4.60it/s]\u001b[A\n",
      " 49% 28/57 [00:05<00:06,  4.60it/s]\u001b[A\n",
      " 51% 29/57 [00:06<00:06,  4.59it/s]\u001b[A\n",
      " 53% 30/57 [00:06<00:05,  4.59it/s]\u001b[A\n",
      " 54% 31/57 [00:06<00:05,  4.59it/s]\u001b[A\n",
      " 56% 32/57 [00:06<00:05,  4.59it/s]\u001b[A\n",
      " 58% 33/57 [00:06<00:05,  4.60it/s]\u001b[A\n",
      " 60% 34/57 [00:07<00:05,  4.60it/s]\u001b[A\n",
      " 61% 35/57 [00:07<00:04,  4.60it/s]\u001b[A\n",
      " 63% 36/57 [00:07<00:04,  4.60it/s]\u001b[A\n",
      " 65% 37/57 [00:07<00:04,  4.60it/s]\u001b[A\n",
      " 67% 38/57 [00:08<00:04,  4.60it/s]\u001b[A\n",
      " 68% 39/57 [00:08<00:03,  4.60it/s]\u001b[A\n",
      " 70% 40/57 [00:08<00:03,  4.60it/s]\u001b[A\n",
      " 72% 41/57 [00:08<00:03,  4.60it/s]\u001b[A\n",
      " 74% 42/57 [00:08<00:03,  4.60it/s]\u001b[A\n",
      " 75% 43/57 [00:09<00:03,  4.58it/s]\u001b[A\n",
      " 77% 44/57 [00:09<00:02,  4.59it/s]\u001b[A\n",
      " 79% 45/57 [00:09<00:02,  4.59it/s]\u001b[A\n",
      " 81% 46/57 [00:09<00:02,  4.60it/s]\u001b[A\n",
      " 82% 47/57 [00:10<00:02,  4.60it/s]\u001b[A\n",
      " 84% 48/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 86% 49/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 88% 50/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 89% 51/57 [00:10<00:01,  4.60it/s]\u001b[A\n",
      " 91% 52/57 [00:11<00:01,  4.60it/s]\u001b[A\n",
      " 93% 53/57 [00:11<00:00,  4.60it/s]\u001b[A\n",
      " 95% 54/57 [00:11<00:00,  4.60it/s]\u001b[A\n",
      " 96% 55/57 [00:11<00:00,  4.60it/s]\u001b[A\n",
      " 98% 56/57 [00:11<00:00,  4.58it/s]\u001b[A\n",
      "100% 57/57 [00:12<00:00,  5.05it/s]\u001b[A12/21/2021 10:29:04 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 10/221 [00:00<00:02, 96.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 21/221 [00:00<00:01, 103.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 35/221 [00:00<00:01, 119.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 122.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 61/221 [00:00<00:01, 117.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 73/221 [00:00<00:01, 114.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 85/221 [00:00<00:01, 111.55it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 97/221 [00:00<00:01, 108.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 108/221 [00:00<00:01, 108.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 119/221 [00:01<00:00, 107.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:00, 106.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 141/221 [00:01<00:00, 107.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69% 152/221 [00:01<00:00, 100.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74% 163/221 [00:01<00:00, 95.99it/s] \u001b[A\u001b[A\n",
      "\n",
      " 78% 173/221 [00:01<00:00, 92.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83% 183/221 [00:01<00:00, 92.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88% 194/221 [00:01<00:00, 96.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93% 206/221 [00:01<00:00, 101.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 104.86it/s]\n",
      "12/21/2021 10:29:06 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/21/2021 10:29:06 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/21/2021 10:29:06 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/21/2021 10:29:06 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "\n",
      "{'eval_exact': 44.34389140271493, 'eval_f1': 66.95642927964296, 'eval_total': 221, 'eval_HasAns_exact': 44.34389140271493, 'eval_HasAns_f1': 66.95642927964296, 'eval_HasAns_total': 221, 'eval_best_exact': 44.34389140271493, 'eval_best_exact_thresh': 0.0, 'eval_best_f1': 66.95642927964296, 'eval_best_f1_thresh': 0.0, 'epoch': 9.09}\n",
      "\n",
      " 91% 2000/2200 [22:32<02:07,  1.57it/s]\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 10:29:06,404 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-2000\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 10:29:06,410 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-2000/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 10:29:08,507 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-2000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 10:29:08,518 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-2000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 10:29:08,523 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-2000/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-21 10:29:13,276 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/checkpoint-1500] due to args.save_total_limit\n",
      "100% 2200/2200 [24:46<00:00,  1.70it/s][INFO|trainer.py:1429] 2021-12-21 10:31:20,342 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 1486.8204, 'train_samples_per_second': 23.648, 'train_steps_per_second': 1.48, 'train_loss': 0.2987114258245988, 'epoch': 10.0}\n",
      "100% 2200/2200 [24:46<00:00,  1.48it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-21 10:31:20,362 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 10:31:20,663 >> Configuration saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 10:31:30,567 >> Model weights saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 10:31:30,903 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 10:31:31,114 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  train_loss               =     0.2987\n",
      "  train_runtime            = 0:24:46.82\n",
      "  train_samples            =       3516\n",
      "  train_samples_per_second =     23.648\n",
      "  train_steps_per_second   =       1.48\n",
      "12/21/2021 10:31:33 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-21 10:31:33,330 >> The following columns in the evaluation set  don't have a corresponding argument in `RobertaForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 10:31:33,333 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 10:31:33,333 >>   Num examples = 907\n",
      "[INFO|trainer.py:2290] 2021-12-21 10:31:33,333 >>   Batch size = 16\n",
      "100% 57/57 [00:12<00:00,  4.89it/s]12/21/2021 10:31:47 - INFO - utils_qa - Post-processing 221 example predictions split into 907 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  3% 7/221 [00:00<00:03, 69.39it/s]\u001b[A\n",
      "  7% 15/221 [00:00<00:02, 70.16it/s]\u001b[A\n",
      " 10% 23/221 [00:00<00:02, 68.52it/s]\u001b[A\n",
      " 14% 32/221 [00:00<00:02, 74.43it/s]\u001b[A\n",
      " 19% 42/221 [00:00<00:02, 79.96it/s]\u001b[A\n",
      " 23% 51/221 [00:00<00:02, 75.79it/s]\u001b[A\n",
      " 27% 59/221 [00:00<00:02, 73.94it/s]\u001b[A\n",
      " 30% 67/221 [00:00<00:02, 72.64it/s]\u001b[A\n",
      " 34% 75/221 [00:01<00:02, 69.26it/s]\u001b[A\n",
      " 37% 82/221 [00:01<00:02, 67.55it/s]\u001b[A\n",
      " 40% 89/221 [00:01<00:01, 67.60it/s]\u001b[A\n",
      " 43% 96/221 [00:01<00:01, 65.89it/s]\u001b[A\n",
      " 47% 103/221 [00:01<00:01, 63.19it/s]\u001b[A\n",
      " 50% 110/221 [00:01<00:01, 63.06it/s]\u001b[A\n",
      " 53% 117/221 [00:01<00:01, 61.66it/s]\u001b[A\n",
      " 56% 124/221 [00:01<00:01, 62.57it/s]\u001b[A\n",
      " 59% 131/221 [00:01<00:01, 63.40it/s]\u001b[A\n",
      " 62% 138/221 [00:02<00:01, 62.06it/s]\u001b[A\n",
      " 66% 145/221 [00:02<00:01, 59.24it/s]\u001b[A\n",
      " 68% 151/221 [00:02<00:01, 54.25it/s]\u001b[A\n",
      " 71% 157/221 [00:02<00:01, 52.30it/s]\u001b[A\n",
      " 74% 163/221 [00:02<00:01, 50.13it/s]\u001b[A\n",
      " 76% 169/221 [00:02<00:01, 50.88it/s]\u001b[A\n",
      " 79% 175/221 [00:02<00:00, 51.63it/s]\u001b[A\n",
      " 82% 181/221 [00:02<00:00, 53.50it/s]\u001b[A\n",
      " 86% 190/221 [00:03<00:00, 62.16it/s]\u001b[A\n",
      " 89% 197/221 [00:03<00:00, 64.00it/s]\u001b[A\n",
      " 93% 205/221 [00:03<00:00, 67.06it/s]\u001b[A\n",
      " 96% 212/221 [00:03<00:00, 66.31it/s]\u001b[A\n",
      "100% 221/221 [00:03<00:00, 63.98it/s]\n",
      "12/21/2021 10:31:51 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_predictions.json.\n",
      "12/21/2021 10:31:51 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_nbest_predictions.json.\n",
      "12/21/2021 10:31:51 - INFO - utils_qa - Saving null_odds to /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/eval_null_odds.json.\n",
      "12/21/2021 10:31:51 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad_v2/default/default_experiment-1-0.arrow\n",
      "100% 57/57 [00:17<00:00,  3.22it/s]\n",
      "***** eval metrics *****\n",
      "  epoch                  =    10.0\n",
      "  eval_HasAns_exact      = 43.8914\n",
      "  eval_HasAns_f1         = 66.6376\n",
      "  eval_HasAns_total      =     221\n",
      "  eval_best_exact        = 43.8914\n",
      "  eval_best_exact_thresh =     0.0\n",
      "  eval_best_f1           = 66.6376\n",
      "  eval_best_f1_thresh    =     0.0\n",
      "  eval_exact             = 43.8914\n",
      "  eval_f1                = 66.6376\n",
      "  eval_samples           =     907\n",
      "  eval_total             =     221\n",
      "[INFO|modelcard.py:456] 2021-12-21 10:31:51,718 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path /content/drive/MyDrive/Models/roberta-base-fiqa-flm-sq \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --version_2_with_negative \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 16 \\\n",
    "  --per_device_train_batch_size 16 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 500 \\\n",
    "  --save_steps 500 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 10 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/roberta-base-fiqa-flm-sq-flit/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d83dh_ctnkLp"
   },
   "source": [
    "## Model 9 - distilbert-base-cased-distilled-squad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cN88F2AznkLz",
    "outputId": "de4da0db-86a8-4cd8-a858-9dd26245295c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/21/2021 10:53:37 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/21/2021 10:53:37 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=200,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/runs/Dec21_10-53-37_01444a28871e,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=2.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/,\n",
      "save_on_each_node=False,\n",
      "save_steps=200,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/21/2021 10:53:37 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/21/2021 10:53:37 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/21/2021 10:53:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/21/2021 10:53:37 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/21/2021 10:53:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "\r",
      "  0% 0/2 [00:00<?, ?it/s]\r",
      "100% 2/2 [00:00<00:00, 722.22it/s]\n",
      "[INFO|configuration_utils.py:604] 2021-12-21 10:53:37,398 >> loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "[INFO|configuration_utils.py:641] 2021-12-21 10:53:37,399 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:604] 2021-12-21 10:53:37,694 >> loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "[INFO|configuration_utils.py:641] 2021-12-21 10:53:37,695 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 10:53:38,280 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/5e66e5f3d499a2fe36f07906eced96e223d283818c9a5fc17efd3e7bf4753711.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 10:53:38,280 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/3b10caec238c150efa989f0540fb8a3876bc7e010fe50aa9d7a9d42c84fc0587.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 10:53:38,280 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 10:53:38,280 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 10:53:38,280 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/b018780df739378fb3b8eec9c2c2c302c45fc3c3a74157f206cbc8db54229abf.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "[INFO|configuration_utils.py:604] 2021-12-21 10:53:38,475 >> loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "[INFO|configuration_utils.py:641] 2021-12-21 10:53:38,476 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1354] 2021-12-21 10:53:38,612 >> loading weights file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/02f483764e26e1acfddfcd6e4879785f2908b2806a962d01b888bfe2b988075b.bd96a9432b167ab5e2b086cf0b688ca3c43c027091377eddfcfd39bdde851c35\n",
      "[INFO|modeling_utils.py:1621] 2021-12-21 10:53:40,156 >> All model checkpoint weights were used when initializing DistilBertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-21 10:53:40,156 >> All the weights of DistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-cased-distilled-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n",
      "12/21/2021 10:53:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-751dc4804977dcf0.arrow\n",
      "Running tokenizer on validation dataset:   0% 0/1 [00:00<?, ?ba/s]12/21/2021 10:53:40 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-5d99cdd7b3e13dd2.arrow\n",
      "Running tokenizer on validation dataset: 100% 1/1 [00:03<00:00,  3.24s/ba]\n",
      "12/21/2021 10:53:43 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad/squad.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpzd720ni3\n",
      "Downloading: 4.51kB [00:00, 4.99MB/s]       \n",
      "12/21/2021 10:53:43 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad/squad.py in cache at /root/.cache/huggingface/datasets/downloads/18e9766cf069f2c09673c7b0cf45fc1c9175aff05880031dbc8b9242834c8154.ab3a5db6a587c35cfd241275240e52547dd1e093c74b3ee4f7798d9f6c6304ec.py\n",
      "12/21/2021 10:53:43 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/18e9766cf069f2c09673c7b0cf45fc1c9175aff05880031dbc8b9242834c8154.ab3a5db6a587c35cfd241275240e52547dd1e093c74b3ee4f7798d9f6c6304ec.py\n",
      "12/21/2021 10:53:44 - INFO - datasets.utils.file_utils - https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad/evaluate.py not found in cache or force_download set to True, downloading to /root/.cache/huggingface/datasets/downloads/tmpu7g612t_\n",
      "Downloading: 3.31kB [00:00, 4.32MB/s]       \n",
      "12/21/2021 10:53:44 - INFO - datasets.utils.file_utils - storing https://raw.githubusercontent.com/huggingface/datasets/1.16.1/metrics/squad/evaluate.py in cache at /root/.cache/huggingface/datasets/downloads/03cf2d9aec2e972d655fe867e615cfc23e44c9ff0240821cfdaf71784f5b604b.6f69c3ff9e10aa1cbdc6e91d27e158ea86a785f54a36a9e964ef8b3b78cf3cd6.py\n",
      "12/21/2021 10:53:44 - INFO - datasets.utils.file_utils - creating metadata file for /root/.cache/huggingface/datasets/downloads/03cf2d9aec2e972d655fe867e615cfc23e44c9ff0240821cfdaf71784f5b604b.6f69c3ff9e10aa1cbdc6e91d27e158ea86a785f54a36a9e964ef8b3b78cf3cd6.py\n",
      "[INFO|trainer.py:1208] 2021-12-21 10:53:48,252 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-21 10:53:48,253 >>   Num examples = 3707\n",
      "[INFO|trainer.py:1210] 2021-12-21 10:53:48,253 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1211] 2021-12-21 10:53:48,253 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:1212] 2021-12-21 10:53:48,253 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1213] 2021-12-21 10:53:48,253 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-21 10:53:48,253 >>   Total optimization steps = 464\n",
      " 43% 200/464 [01:04<01:25,  3.08it/s][INFO|trainer.py:549] 2021-12-21 10:54:53,172 >> The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-21 10:54:53,174 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 10:54:53,174 >>   Num examples = 912\n",
      "[INFO|trainer.py:2290] 2021-12-21 10:54:53,174 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:03, 17.73it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:04, 11.17it/s]\u001b[A\n",
      " 11% 6/57 [00:00<00:05, 10.00it/s]\u001b[A\n",
      " 14% 8/57 [00:00<00:05,  9.51it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:05,  9.27it/s]\u001b[A\n",
      " 19% 11/57 [00:01<00:05,  9.19it/s]\u001b[A\n",
      " 21% 12/57 [00:01<00:04,  9.12it/s]\u001b[A\n",
      " 23% 13/57 [00:01<00:04,  9.07it/s]\u001b[A\n",
      " 25% 14/57 [00:01<00:04,  9.02it/s]\u001b[A\n",
      " 26% 15/57 [00:01<00:04,  8.98it/s]\u001b[A\n",
      " 28% 16/57 [00:01<00:04,  8.95it/s]\u001b[A\n",
      " 30% 17/57 [00:01<00:04,  8.87it/s]\u001b[A\n",
      " 32% 18/57 [00:01<00:04,  8.86it/s]\u001b[A\n",
      " 33% 19/57 [00:02<00:04,  8.87it/s]\u001b[A\n",
      " 35% 20/57 [00:02<00:04,  8.87it/s]\u001b[A\n",
      " 37% 21/57 [00:02<00:04,  8.86it/s]\u001b[A\n",
      " 39% 22/57 [00:02<00:03,  8.86it/s]\u001b[A\n",
      " 40% 23/57 [00:02<00:03,  8.87it/s]\u001b[A\n",
      " 42% 24/57 [00:02<00:03,  8.83it/s]\u001b[A\n",
      " 44% 25/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 46% 26/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 47% 27/57 [00:02<00:03,  8.86it/s]\u001b[A\n",
      " 49% 28/57 [00:03<00:03,  8.86it/s]\u001b[A\n",
      " 51% 29/57 [00:03<00:03,  8.87it/s]\u001b[A\n",
      " 53% 30/57 [00:03<00:03,  8.88it/s]\u001b[A\n",
      " 54% 31/57 [00:03<00:02,  8.89it/s]\u001b[A\n",
      " 56% 32/57 [00:03<00:02,  8.89it/s]\u001b[A\n",
      " 58% 33/57 [00:03<00:02,  8.87it/s]\u001b[A\n",
      " 60% 34/57 [00:03<00:02,  8.87it/s]\u001b[A\n",
      " 61% 35/57 [00:03<00:02,  8.88it/s]\u001b[A\n",
      " 63% 36/57 [00:03<00:02,  8.88it/s]\u001b[A\n",
      " 65% 37/57 [00:04<00:02,  8.89it/s]\u001b[A\n",
      " 67% 38/57 [00:04<00:02,  8.87it/s]\u001b[A\n",
      " 68% 39/57 [00:04<00:02,  8.88it/s]\u001b[A\n",
      " 70% 40/57 [00:04<00:01,  8.88it/s]\u001b[A\n",
      " 72% 41/57 [00:04<00:01,  8.88it/s]\u001b[A\n",
      " 74% 42/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 75% 43/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 77% 44/57 [00:04<00:01,  8.88it/s]\u001b[A\n",
      " 79% 45/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 81% 46/57 [00:05<00:01,  8.88it/s]\u001b[A\n",
      " 82% 47/57 [00:05<00:01,  8.87it/s]\u001b[A\n",
      " 84% 48/57 [00:05<00:01,  8.80it/s]\u001b[A\n",
      " 86% 49/57 [00:05<00:00,  8.82it/s]\u001b[A\n",
      " 88% 50/57 [00:05<00:00,  8.84it/s]\u001b[A\n",
      " 89% 51/57 [00:05<00:00,  8.84it/s]\u001b[A\n",
      " 91% 52/57 [00:05<00:00,  8.85it/s]\u001b[A\n",
      " 93% 53/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 95% 54/57 [00:05<00:00,  8.87it/s]\u001b[A\n",
      " 96% 55/57 [00:06<00:00,  8.88it/s]\u001b[A\n",
      " 98% 56/57 [00:06<00:00,  8.87it/s]\u001b[A\n",
      "100% 57/57 [00:06<00:00,  8.88it/s]\u001b[A12/21/2021 10:55:00 - INFO - utils_qa - Post-processing 221 example predictions split into 912 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 11/221 [00:00<00:01, 106.06it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 22/221 [00:00<00:01, 106.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:01, 119.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 116.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 60/221 [00:00<00:01, 111.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 72/221 [00:00<00:01, 107.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 83/221 [00:00<00:01, 104.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 94/221 [00:00<00:01, 102.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:00<00:01, 100.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 116/221 [00:01<00:01, 101.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 127/221 [00:01<00:00, 99.26it/s] \u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:00, 101.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 149/221 [00:01<00:00, 94.41it/s] \u001b[A\u001b[A\n",
      "\n",
      " 72% 159/221 [00:01<00:00, 92.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 169/221 [00:01<00:00, 89.62it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 179/221 [00:01<00:00, 87.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 190/221 [00:01<00:00, 91.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 202/221 [00:02<00:00, 96.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 100.43it/s]\n",
      "12/21/2021 10:55:02 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/eval_predictions.json.\n",
      "12/21/2021 10:55:02 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/eval_nbest_predictions.json.\n",
      "12/21/2021 10:55:02 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact_match': 31.67420814479638, 'eval_f1': 56.58898131863339, 'epoch': 0.86}\n",
      " 43% 200/464 [01:14<01:25,  3.08it/s]\n",
      "100% 57/57 [00:09<00:00,  8.88it/s]\u001b[A\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 10:55:02,805 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-200\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 10:55:02,810 >> Configuration saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-200/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 10:55:03,891 >> Model weights saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-200/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 10:55:03,899 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 10:55:04,270 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-200/special_tokens_map.json\n",
      " 86% 400/464 [02:23<00:20,  3.08it/s][INFO|trainer.py:549] 2021-12-21 10:56:11,513 >> The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-21 10:56:11,514 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 10:56:11,514 >>   Num examples = 912\n",
      "[INFO|trainer.py:2290] 2021-12-21 10:56:11,515 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:03, 17.23it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:04, 11.11it/s]\u001b[A\n",
      " 11% 6/57 [00:00<00:05,  9.98it/s]\u001b[A\n",
      " 14% 8/57 [00:00<00:05,  9.48it/s]\u001b[A\n",
      " 16% 9/57 [00:00<00:05,  9.34it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:05,  9.23it/s]\u001b[A\n",
      " 19% 11/57 [00:01<00:05,  9.14it/s]\u001b[A\n",
      " 21% 12/57 [00:01<00:04,  9.07it/s]\u001b[A\n",
      " 23% 13/57 [00:01<00:04,  9.02it/s]\u001b[A\n",
      " 25% 14/57 [00:01<00:04,  8.98it/s]\u001b[A\n",
      " 26% 15/57 [00:01<00:04,  8.95it/s]\u001b[A\n",
      " 28% 16/57 [00:01<00:04,  8.94it/s]\u001b[A\n",
      " 30% 17/57 [00:01<00:04,  8.92it/s]\u001b[A\n",
      " 32% 18/57 [00:01<00:04,  8.91it/s]\u001b[A\n",
      " 33% 19/57 [00:02<00:04,  8.91it/s]\u001b[A\n",
      " 35% 20/57 [00:02<00:04,  8.91it/s]\u001b[A\n",
      " 37% 21/57 [00:02<00:04,  8.91it/s]\u001b[A\n",
      " 39% 22/57 [00:02<00:03,  8.91it/s]\u001b[A\n",
      " 40% 23/57 [00:02<00:03,  8.88it/s]\u001b[A\n",
      " 42% 24/57 [00:02<00:03,  8.87it/s]\u001b[A\n",
      " 44% 25/57 [00:02<00:03,  8.88it/s]\u001b[A\n",
      " 46% 26/57 [00:02<00:03,  8.88it/s]\u001b[A\n",
      " 47% 27/57 [00:02<00:03,  8.89it/s]\u001b[A\n",
      " 49% 28/57 [00:03<00:03,  8.89it/s]\u001b[A\n",
      " 51% 29/57 [00:03<00:03,  8.89it/s]\u001b[A\n",
      " 53% 30/57 [00:03<00:03,  8.89it/s]\u001b[A\n",
      " 54% 31/57 [00:03<00:02,  8.89it/s]\u001b[A\n",
      " 56% 32/57 [00:03<00:02,  8.88it/s]\u001b[A\n",
      " 58% 33/57 [00:03<00:02,  8.89it/s]\u001b[A\n",
      " 60% 34/57 [00:03<00:02,  8.87it/s]\u001b[A\n",
      " 61% 35/57 [00:03<00:02,  8.84it/s]\u001b[A\n",
      " 63% 36/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 65% 37/57 [00:04<00:02,  8.87it/s]\u001b[A\n",
      " 67% 38/57 [00:04<00:02,  8.88it/s]\u001b[A\n",
      " 68% 39/57 [00:04<00:02,  8.88it/s]\u001b[A\n",
      " 70% 40/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 72% 41/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 74% 42/57 [00:04<00:01,  8.86it/s]\u001b[A\n",
      " 75% 43/57 [00:04<00:01,  8.85it/s]\u001b[A\n",
      " 77% 44/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 79% 45/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 81% 46/57 [00:05<00:01,  8.86it/s]\u001b[A\n",
      " 82% 47/57 [00:05<00:01,  8.87it/s]\u001b[A\n",
      " 84% 48/57 [00:05<00:01,  8.81it/s]\u001b[A\n",
      " 86% 49/57 [00:05<00:00,  8.84it/s]\u001b[A\n",
      " 88% 50/57 [00:05<00:00,  8.84it/s]\u001b[A\n",
      " 89% 51/57 [00:05<00:00,  8.85it/s]\u001b[A\n",
      " 91% 52/57 [00:05<00:00,  8.84it/s]\u001b[A\n",
      " 93% 53/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 95% 54/57 [00:05<00:00,  8.88it/s]\u001b[A\n",
      " 96% 55/57 [00:06<00:00,  8.88it/s]\u001b[A\n",
      " 98% 56/57 [00:06<00:00,  8.88it/s]\u001b[A\n",
      "100% 57/57 [00:06<00:00,  8.88it/s]\u001b[A12/21/2021 10:56:18 - INFO - utils_qa - Post-processing 221 example predictions split into 912 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 10/221 [00:00<00:02, 99.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 21/221 [00:00<00:01, 103.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 35/221 [00:00<00:01, 118.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 48/221 [00:00<00:01, 120.14it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 61/221 [00:00<00:01, 111.57it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 73/221 [00:00<00:01, 107.61it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 84/221 [00:00<00:01, 105.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 95/221 [00:00<00:01, 98.18it/s] \u001b[A\u001b[A\n",
      "\n",
      " 48% 106/221 [00:01<00:01, 99.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 117/221 [00:01<00:01, 99.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 128/221 [00:01<00:00, 99.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 139/221 [00:01<00:00, 100.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 150/221 [00:01<00:00, 93.99it/s] \u001b[A\u001b[A\n",
      "\n",
      " 72% 160/221 [00:01<00:00, 92.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 170/221 [00:01<00:00, 89.91it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 180/221 [00:01<00:00, 87.75it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 190/221 [00:01<00:00, 90.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 201/221 [00:02<00:00, 95.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 99.74it/s]\n",
      "12/21/2021 10:56:21 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/eval_predictions.json.\n",
      "12/21/2021 10:56:21 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/eval_nbest_predictions.json.\n",
      "12/21/2021 10:56:21 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
      "                                     \n",
      "\u001b[A{'eval_exact_match': 32.126696832579185, 'eval_f1': 56.31120671314669, 'epoch': 1.72}\n",
      " 86% 400/464 [02:32<00:20,  3.08it/s]\n",
      "100% 57/57 [00:09<00:00,  8.88it/s]\u001b[A\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 10:56:21,169 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-400\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 10:56:21,173 >> Configuration saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-400/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 10:56:22,215 >> Model weights saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-400/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 10:56:22,220 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 10:56:22,223 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-400/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-21 10:56:24,744 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/checkpoint-200] due to args.save_total_limit\n",
      "100% 464/464 [02:57<00:00,  3.38it/s][INFO|trainer.py:1429] 2021-12-21 10:56:45,781 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 177.533, 'train_samples_per_second': 41.761, 'train_steps_per_second': 2.614, 'train_loss': 0.9519663843615301, 'epoch': 2.0}\n",
      "100% 464/464 [02:57<00:00,  2.61it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-21 10:56:45,805 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 10:56:45,811 >> Configuration saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 10:56:46,850 >> Model weights saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 10:56:46,857 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 10:56:46,861 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =        2.0\n",
      "  train_loss               =      0.952\n",
      "  train_runtime            = 0:02:57.53\n",
      "  train_samples            =       3707\n",
      "  train_samples_per_second =     41.761\n",
      "  train_steps_per_second   =      2.614\n",
      "12/21/2021 10:56:46 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-21 10:56:46,923 >> The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: offset_mapping, example_id.\n",
      "[INFO|trainer.py:2285] 2021-12-21 10:56:46,925 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 10:56:46,925 >>   Num examples = 912\n",
      "[INFO|trainer.py:2290] 2021-12-21 10:56:46,925 >>   Batch size = 16\n",
      "100% 57/57 [00:06<00:00,  8.85it/s]12/21/2021 10:56:54 - INFO - utils_qa - Post-processing 221 example predictions split into 912 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  5% 11/221 [00:00<00:01, 107.46it/s]\u001b[A\n",
      " 10% 23/221 [00:00<00:01, 111.23it/s]\u001b[A\n",
      " 17% 38/221 [00:00<00:01, 125.21it/s]\u001b[A\n",
      " 23% 51/221 [00:00<00:01, 123.80it/s]\u001b[A\n",
      " 29% 64/221 [00:00<00:01, 118.83it/s]\u001b[A\n",
      " 34% 76/221 [00:00<00:01, 110.56it/s]\u001b[A\n",
      " 40% 88/221 [00:00<00:01, 106.11it/s]\u001b[A\n",
      " 45% 99/221 [00:00<00:01, 104.93it/s]\u001b[A\n",
      " 50% 110/221 [00:00<00:01, 104.88it/s]\u001b[A\n",
      " 55% 121/221 [00:01<00:00, 104.35it/s]\u001b[A\n",
      " 60% 132/221 [00:01<00:00, 105.63it/s]\u001b[A\n",
      " 65% 143/221 [00:01<00:00, 101.16it/s]\u001b[A\n",
      " 70% 154/221 [00:01<00:00, 97.64it/s] \u001b[A\n",
      " 74% 164/221 [00:01<00:00, 94.33it/s]\u001b[A\n",
      " 79% 174/221 [00:01<00:00, 88.65it/s]\u001b[A\n",
      " 83% 183/221 [00:01<00:00, 77.50it/s]\u001b[A\n",
      " 86% 191/221 [00:01<00:00, 76.36it/s]\u001b[A\n",
      " 90% 199/221 [00:02<00:00, 76.02it/s]\u001b[A\n",
      " 94% 207/221 [00:02<00:00, 74.63it/s]\u001b[A\n",
      "100% 221/221 [00:02<00:00, 94.33it/s]\n",
      "12/21/2021 10:56:56 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/eval_predictions.json.\n",
      "12/21/2021 10:56:56 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/eval_nbest_predictions.json.\n",
      "12/21/2021 10:56:56 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
      "100% 57/57 [00:09<00:00,  5.87it/s]\n",
      "***** eval metrics *****\n",
      "  epoch            =     2.0\n",
      "  eval_exact_match = 32.5792\n",
      "  eval_f1          = 56.6215\n",
      "  eval_samples     =     912\n",
      "[INFO|modelcard.py:456] 2021-12-21 10:56:56,898 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path distilbert-base-cased-distilled-squad \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 16 \\\n",
    "  --per_device_train_batch_size 16 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 200 \\\n",
    "  --save_steps 200 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 2 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-squad/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzYnCt0SpXMs"
   },
   "source": [
    "## Model 9 - distilbert-base-cased-distilled-squad - 10 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xGmV2NbKpXMs",
    "outputId": "9671f05c-e6c7-4b49-9343-5f1779dbdf05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/21/2021 11:00:09 - WARNING - __main__ - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "12/21/2021 11:00:09 - INFO - __main__ - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=500,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/runs/Dec21_11-00-09_01444a28871e,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=10.0,\n",
      "output_dir=/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=1,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.2,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n",
      "12/21/2021 11:00:09 - WARNING - datasets.builder - Using custom data configuration default-04b5ea097a8b9b15\n",
      "12/21/2021 11:00:09 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "12/21/2021 11:00:09 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "12/21/2021 11:00:09 - WARNING - datasets.builder - Reusing dataset json (/root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426)\n",
      "12/21/2021 11:00:09 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426\n",
      "\r",
      "  0% 0/2 [00:00<?, ?it/s]\r",
      "100% 2/2 [00:00<00:00, 657.88it/s]\n",
      "[INFO|configuration_utils.py:604] 2021-12-21 11:00:10,129 >> loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "[INFO|configuration_utils.py:641] 2021-12-21 11:00:10,131 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:604] 2021-12-21 11:00:10,436 >> loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "[INFO|configuration_utils.py:641] 2021-12-21 11:00:10,437 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 11:00:11,020 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/5e66e5f3d499a2fe36f07906eced96e223d283818c9a5fc17efd3e7bf4753711.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 11:00:11,020 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/3b10caec238c150efa989f0540fb8a3876bc7e010fe50aa9d7a9d42c84fc0587.2b9a196704f2f183fe3f4b48d6e662dba8203fdcb3346bfa896831378edf6f97\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 11:00:11,020 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 11:00:11,020 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1742] 2021-12-21 11:00:11,020 >> loading file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/b018780df739378fb3b8eec9c2c2c302c45fc3c3a74157f206cbc8db54229abf.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "[INFO|configuration_utils.py:604] 2021-12-21 11:00:11,220 >> loading configuration file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/81e8dfe090123eff18dd06533ead3ae407b82e30834c50c7c82c2305ce3ace12.ca0305b1f128274fa0c6e4859d1c1477d0e34a20be25da95eea888b30ece9cf3\n",
      "[INFO|configuration_utils.py:641] 2021-12-21 11:00:11,221 >> Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-cased-distilled-squad\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForQuestionAnswering\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": true,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.15.0.dev0\",\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1354] 2021-12-21 11:00:11,363 >> loading weights file https://huggingface.co/distilbert-base-cased-distilled-squad/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/02f483764e26e1acfddfcd6e4879785f2908b2806a962d01b888bfe2b988075b.bd96a9432b167ab5e2b086cf0b688ca3c43c027091377eddfcfd39bdde851c35\n",
      "[INFO|modeling_utils.py:1621] 2021-12-21 11:00:12,893 >> All model checkpoint weights were used when initializing DistilBertForQuestionAnswering.\n",
      "\n",
      "[INFO|modeling_utils.py:1630] 2021-12-21 11:00:12,893 >> All the weights of DistilBertForQuestionAnswering were initialized from the model checkpoint at distilbert-base-cased-distilled-squad.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForQuestionAnswering for predictions without further training.\n",
      "12/21/2021 11:00:12 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-751dc4804977dcf0.arrow\n",
      "12/21/2021 11:00:12 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/json/default-04b5ea097a8b9b15/0.0.0/c2d554c3377ea79c7664b93dc65d0803b45e3279000f993c7bfd18937fd7f426/cache-5d99cdd7b3e13dd2.arrow\n",
      "[INFO|trainer.py:1208] 2021-12-21 11:00:16,886 >> ***** Running training *****\n",
      "[INFO|trainer.py:1209] 2021-12-21 11:00:16,886 >>   Num examples = 3707\n",
      "[INFO|trainer.py:1210] 2021-12-21 11:00:16,887 >>   Num Epochs = 10\n",
      "[INFO|trainer.py:1211] 2021-12-21 11:00:16,887 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:1212] 2021-12-21 11:00:16,887 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1213] 2021-12-21 11:00:16,887 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1214] 2021-12-21 11:00:16,887 >>   Total optimization steps = 2320\n",
      "{'loss': 1.081, 'learning_rate': 1.9612068965517245e-05, 'epoch': 2.16}\n",
      " 22% 500/2320 [02:42<09:53,  3.07it/s][INFO|trainer.py:549] 2021-12-21 11:02:59,449 >> The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 11:02:59,451 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 11:02:59,451 >>   Num examples = 912\n",
      "[INFO|trainer.py:2290] 2021-12-21 11:02:59,451 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:03, 17.78it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:04, 11.22it/s]\u001b[A\n",
      " 11% 6/57 [00:00<00:05, 10.03it/s]\u001b[A\n",
      " 14% 8/57 [00:00<00:05,  9.48it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:05,  9.27it/s]\u001b[A\n",
      " 19% 11/57 [00:01<00:05,  9.19it/s]\u001b[A\n",
      " 21% 12/57 [00:01<00:04,  9.12it/s]\u001b[A\n",
      " 23% 13/57 [00:01<00:04,  9.06it/s]\u001b[A\n",
      " 25% 14/57 [00:01<00:04,  9.02it/s]\u001b[A\n",
      " 26% 15/57 [00:01<00:04,  8.99it/s]\u001b[A\n",
      " 28% 16/57 [00:01<00:04,  8.95it/s]\u001b[A\n",
      " 30% 17/57 [00:01<00:04,  8.79it/s]\u001b[A\n",
      " 32% 18/57 [00:01<00:04,  8.81it/s]\u001b[A\n",
      " 33% 19/57 [00:02<00:04,  8.81it/s]\u001b[A\n",
      " 35% 20/57 [00:02<00:04,  8.83it/s]\u001b[A\n",
      " 37% 21/57 [00:02<00:04,  8.84it/s]\u001b[A\n",
      " 39% 22/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 40% 23/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 42% 24/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 44% 25/57 [00:02<00:03,  8.84it/s]\u001b[A\n",
      " 46% 26/57 [00:02<00:03,  8.75it/s]\u001b[A\n",
      " 47% 27/57 [00:02<00:03,  8.79it/s]\u001b[A\n",
      " 49% 28/57 [00:03<00:03,  8.81it/s]\u001b[A\n",
      " 51% 29/57 [00:03<00:03,  8.83it/s]\u001b[A\n",
      " 53% 30/57 [00:03<00:03,  8.85it/s]\u001b[A\n",
      " 54% 31/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 56% 32/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 58% 33/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 60% 34/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 61% 35/57 [00:03<00:02,  8.77it/s]\u001b[A\n",
      " 63% 36/57 [00:03<00:02,  8.81it/s]\u001b[A\n",
      " 65% 37/57 [00:04<00:02,  8.83it/s]\u001b[A\n",
      " 67% 38/57 [00:04<00:02,  8.83it/s]\u001b[A\n",
      " 68% 39/57 [00:04<00:02,  8.85it/s]\u001b[A\n",
      " 70% 40/57 [00:04<00:01,  8.85it/s]\u001b[A\n",
      " 72% 41/57 [00:04<00:01,  8.86it/s]\u001b[A\n",
      " 74% 42/57 [00:04<00:01,  8.82it/s]\u001b[A\n",
      " 75% 43/57 [00:04<00:01,  8.83it/s]\u001b[A\n",
      " 77% 44/57 [00:04<00:01,  8.76it/s]\u001b[A\n",
      " 79% 45/57 [00:04<00:01,  8.80it/s]\u001b[A\n",
      " 81% 46/57 [00:05<00:01,  8.83it/s]\u001b[A\n",
      " 82% 47/57 [00:05<00:01,  8.84it/s]\u001b[A\n",
      " 84% 48/57 [00:05<00:01,  8.84it/s]\u001b[A\n",
      " 86% 49/57 [00:05<00:00,  8.85it/s]\u001b[A\n",
      " 88% 50/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 89% 51/57 [00:05<00:00,  8.81it/s]\u001b[A\n",
      " 91% 52/57 [00:05<00:00,  8.81it/s]\u001b[A\n",
      " 93% 53/57 [00:05<00:00,  8.72it/s]\u001b[A\n",
      " 95% 54/57 [00:06<00:00,  8.77it/s]\u001b[A\n",
      " 96% 55/57 [00:06<00:00,  8.79it/s]\u001b[A\n",
      " 98% 56/57 [00:06<00:00,  8.81it/s]\u001b[A\n",
      "100% 57/57 [00:06<00:00,  8.83it/s]\u001b[A12/21/2021 11:03:06 - INFO - utils_qa - Post-processing 221 example predictions split into 912 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 11/221 [00:00<00:02, 101.58it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 22/221 [00:00<00:01, 106.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:01, 120.84it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 49/221 [00:00<00:01, 122.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:01, 117.77it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 106.85it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 85/221 [00:00<00:01, 104.87it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 96/221 [00:00<00:01, 103.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 107/221 [00:00<00:01, 101.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 118/221 [00:01<00:01, 102.17it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 129/221 [00:01<00:00, 102.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 140/221 [00:01<00:00, 101.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 96.97it/s] \u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:01<00:00, 93.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 171/221 [00:01<00:00, 88.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 180/221 [00:01<00:00, 85.59it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 189/221 [00:01<00:00, 85.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 200/221 [00:02<00:00, 90.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 99.78it/s]\n",
      "12/21/2021 11:03:09 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_predictions.json.\n",
      "12/21/2021 11:03:09 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_nbest_predictions.json.\n",
      "12/21/2021 11:03:09 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
      "                                      \n",
      "\u001b[A{'eval_exact_match': 32.126696832579185, 'eval_f1': 56.959032279837196, 'epoch': 2.16}\n",
      " 22% 500/2320 [02:52<09:53,  3.07it/s]\n",
      "100% 57/57 [00:09<00:00,  8.83it/s]\u001b[A\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 11:03:09,110 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-500\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 11:03:09,115 >> Configuration saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-500/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 11:03:10,520 >> Model weights saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-500/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 11:03:10,531 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 11:03:10,535 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-500/special_tokens_map.json\n",
      "{'loss': 0.5086, 'learning_rate': 1.4224137931034483e-05, 'epoch': 4.31}\n",
      " 43% 1000/2320 [05:39<07:11,  3.06it/s][INFO|trainer.py:549] 2021-12-21 11:05:56,214 >> The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 11:05:56,216 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 11:05:56,216 >>   Num examples = 912\n",
      "[INFO|trainer.py:2290] 2021-12-21 11:05:56,216 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:03, 17.75it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:04, 11.17it/s]\u001b[A\n",
      " 11% 6/57 [00:00<00:05, 10.01it/s]\u001b[A\n",
      " 14% 8/57 [00:00<00:05,  9.54it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:05,  9.29it/s]\u001b[A\n",
      " 19% 11/57 [00:01<00:05,  9.16it/s]\u001b[A\n",
      " 21% 12/57 [00:01<00:04,  9.10it/s]\u001b[A\n",
      " 23% 13/57 [00:01<00:04,  9.06it/s]\u001b[A\n",
      " 25% 14/57 [00:01<00:04,  9.01it/s]\u001b[A\n",
      " 26% 15/57 [00:01<00:04,  8.98it/s]\u001b[A\n",
      " 28% 16/57 [00:01<00:04,  8.95it/s]\u001b[A\n",
      " 30% 17/57 [00:01<00:04,  8.92it/s]\u001b[A\n",
      " 32% 18/57 [00:01<00:04,  8.89it/s]\u001b[A\n",
      " 33% 19/57 [00:02<00:04,  8.89it/s]\u001b[A\n",
      " 35% 20/57 [00:02<00:04,  8.88it/s]\u001b[A\n",
      " 37% 21/57 [00:02<00:04,  8.86it/s]\u001b[A\n",
      " 39% 22/57 [00:02<00:03,  8.86it/s]\u001b[A\n",
      " 40% 23/57 [00:02<00:03,  8.86it/s]\u001b[A\n",
      " 42% 24/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 44% 25/57 [00:02<00:03,  8.86it/s]\u001b[A\n",
      " 46% 26/57 [00:02<00:03,  8.80it/s]\u001b[A\n",
      " 47% 27/57 [00:02<00:03,  8.83it/s]\u001b[A\n",
      " 49% 28/57 [00:03<00:03,  8.83it/s]\u001b[A\n",
      " 51% 29/57 [00:03<00:03,  8.83it/s]\u001b[A\n",
      " 53% 30/57 [00:03<00:03,  8.84it/s]\u001b[A\n",
      " 54% 31/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 56% 32/57 [00:03<00:02,  8.87it/s]\u001b[A\n",
      " 58% 33/57 [00:03<00:02,  8.88it/s]\u001b[A\n",
      " 60% 34/57 [00:03<00:02,  8.87it/s]\u001b[A\n",
      " 61% 35/57 [00:03<00:02,  8.83it/s]\u001b[A\n",
      " 63% 36/57 [00:03<00:02,  8.85it/s]\u001b[A\n",
      " 65% 37/57 [00:04<00:02,  8.84it/s]\u001b[A\n",
      " 67% 38/57 [00:04<00:02,  8.85it/s]\u001b[A\n",
      " 68% 39/57 [00:04<00:02,  8.86it/s]\u001b[A\n",
      " 70% 40/57 [00:04<00:01,  8.85it/s]\u001b[A\n",
      " 72% 41/57 [00:04<00:01,  8.85it/s]\u001b[A\n",
      " 74% 42/57 [00:04<00:01,  8.84it/s]\u001b[A\n",
      " 75% 43/57 [00:04<00:01,  8.83it/s]\u001b[A\n",
      " 77% 44/57 [00:04<00:01,  8.84it/s]\u001b[A\n",
      " 79% 45/57 [00:04<00:01,  8.86it/s]\u001b[A\n",
      " 81% 46/57 [00:05<00:01,  8.87it/s]\u001b[A\n",
      " 82% 47/57 [00:05<00:01,  8.86it/s]\u001b[A\n",
      " 84% 48/57 [00:05<00:01,  8.86it/s]\u001b[A\n",
      " 86% 49/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 88% 50/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 89% 51/57 [00:05<00:00,  8.80it/s]\u001b[A\n",
      " 91% 52/57 [00:05<00:00,  8.82it/s]\u001b[A\n",
      " 93% 53/57 [00:05<00:00,  8.80it/s]\u001b[A\n",
      " 95% 54/57 [00:05<00:00,  8.83it/s]\u001b[A\n",
      " 96% 55/57 [00:06<00:00,  8.84it/s]\u001b[A\n",
      " 98% 56/57 [00:06<00:00,  8.86it/s]\u001b[A\n",
      "100% 57/57 [00:06<00:00,  8.87it/s]\u001b[A12/21/2021 11:06:03 - INFO - utils_qa - Post-processing 221 example predictions split into 912 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 10/221 [00:00<00:02, 95.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 21/221 [00:00<00:01, 101.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:01, 119.64it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 49/221 [00:00<00:01, 121.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:01, 116.10it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 109.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 85/221 [00:00<00:01, 106.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 96/221 [00:00<00:01, 104.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 107/221 [00:00<00:01, 104.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53% 118/221 [00:01<00:01, 102.20it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58% 129/221 [00:01<00:00, 100.78it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63% 140/221 [00:01<00:00, 102.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 94.61it/s] \u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:01<00:00, 92.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 171/221 [00:01<00:00, 90.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82% 181/221 [00:01<00:00, 87.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87% 192/221 [00:01<00:00, 93.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92% 204/221 [00:02<00:00, 98.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 100.70it/s]\n",
      "12/21/2021 11:06:05 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_predictions.json.\n",
      "12/21/2021 11:06:05 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_nbest_predictions.json.\n",
      "12/21/2021 11:06:05 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
      "                                       \n",
      "\u001b[A{'eval_exact_match': 32.57918552036199, 'eval_f1': 58.05137877382451, 'epoch': 4.31}\n",
      " 43% 1000/2320 [05:48<07:11,  3.06it/s]\n",
      "100% 57/57 [00:09<00:00,  8.87it/s]\u001b[A\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 11:06:05,830 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1000\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 11:06:05,835 >> Configuration saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1000/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 11:06:06,917 >> Model weights saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 11:06:06,921 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 11:06:06,924 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1000/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-21 11:06:09,260 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-500] due to args.save_total_limit\n",
      "{'loss': 0.2024, 'learning_rate': 8.836206896551725e-06, 'epoch': 6.47}\n",
      " 65% 1500/2320 [08:35<04:27,  3.06it/s][INFO|trainer.py:549] 2021-12-21 11:08:52,413 >> The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 11:08:52,414 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 11:08:52,414 >>   Num examples = 912\n",
      "[INFO|trainer.py:2290] 2021-12-21 11:08:52,415 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:03, 17.71it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:04, 11.04it/s]\u001b[A\n",
      " 11% 6/57 [00:00<00:05,  9.94it/s]\u001b[A\n",
      " 14% 8/57 [00:00<00:05,  9.48it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:05,  9.26it/s]\u001b[A\n",
      " 19% 11/57 [00:01<00:05,  9.14it/s]\u001b[A\n",
      " 21% 12/57 [00:01<00:04,  9.04it/s]\u001b[A\n",
      " 23% 13/57 [00:01<00:04,  9.01it/s]\u001b[A\n",
      " 25% 14/57 [00:01<00:04,  8.97it/s]\u001b[A\n",
      " 26% 15/57 [00:01<00:04,  8.95it/s]\u001b[A\n",
      " 28% 16/57 [00:01<00:04,  8.93it/s]\u001b[A\n",
      " 30% 17/57 [00:01<00:04,  8.91it/s]\u001b[A\n",
      " 32% 18/57 [00:01<00:04,  8.89it/s]\u001b[A\n",
      " 33% 19/57 [00:02<00:04,  8.87it/s]\u001b[A\n",
      " 35% 20/57 [00:02<00:04,  8.87it/s]\u001b[A\n",
      " 37% 21/57 [00:02<00:04,  8.86it/s]\u001b[A\n",
      " 39% 22/57 [00:02<00:03,  8.87it/s]\u001b[A\n",
      " 40% 23/57 [00:02<00:03,  8.84it/s]\u001b[A\n",
      " 42% 24/57 [00:02<00:03,  8.84it/s]\u001b[A\n",
      " 44% 25/57 [00:02<00:03,  8.78it/s]\u001b[A\n",
      " 46% 26/57 [00:02<00:03,  8.81it/s]\u001b[A\n",
      " 47% 27/57 [00:02<00:03,  8.82it/s]\u001b[A\n",
      " 49% 28/57 [00:03<00:03,  8.84it/s]\u001b[A\n",
      " 51% 29/57 [00:03<00:03,  8.86it/s]\u001b[A\n",
      " 53% 30/57 [00:03<00:03,  8.86it/s]\u001b[A\n",
      " 54% 31/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 56% 32/57 [00:03<00:02,  8.85it/s]\u001b[A\n",
      " 58% 33/57 [00:03<00:02,  8.85it/s]\u001b[A\n",
      " 60% 34/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 61% 35/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 63% 36/57 [00:03<00:02,  8.87it/s]\u001b[A\n",
      " 65% 37/57 [00:04<00:02,  8.87it/s]\u001b[A\n",
      " 67% 38/57 [00:04<00:02,  8.87it/s]\u001b[A\n",
      " 68% 39/57 [00:04<00:02,  8.82it/s]\u001b[A\n",
      " 70% 40/57 [00:04<00:01,  8.84it/s]\u001b[A\n",
      " 72% 41/57 [00:04<00:01,  8.85it/s]\u001b[A\n",
      " 74% 42/57 [00:04<00:01,  8.86it/s]\u001b[A\n",
      " 75% 43/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 77% 44/57 [00:04<00:01,  8.85it/s]\u001b[A\n",
      " 79% 45/57 [00:04<00:01,  8.85it/s]\u001b[A\n",
      " 81% 46/57 [00:05<00:01,  8.86it/s]\u001b[A\n",
      " 82% 47/57 [00:05<00:01,  8.85it/s]\u001b[A\n",
      " 84% 48/57 [00:05<00:01,  8.85it/s]\u001b[A\n",
      " 86% 49/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 88% 50/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 89% 51/57 [00:05<00:00,  8.85it/s]\u001b[A\n",
      " 91% 52/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 93% 53/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 95% 54/57 [00:05<00:00,  8.87it/s]\u001b[A\n",
      " 96% 55/57 [00:06<00:00,  8.87it/s]\u001b[A\n",
      " 98% 56/57 [00:06<00:00,  8.88it/s]\u001b[A\n",
      "100% 57/57 [00:06<00:00,  8.87it/s]\u001b[A12/21/2021 11:08:59 - INFO - utils_qa - Post-processing 221 example predictions split into 912 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 11/221 [00:00<00:02, 101.51it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 22/221 [00:00<00:01, 103.47it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 35/221 [00:00<00:01, 115.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21% 47/221 [00:00<00:01, 115.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27% 59/221 [00:00<00:01, 113.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32% 71/221 [00:00<00:01, 110.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38% 83/221 [00:00<00:01, 105.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43% 94/221 [00:00<00:01, 101.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48% 105/221 [00:00<00:01, 103.27it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52% 116/221 [00:01<00:01, 101.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57% 127/221 [00:01<00:00, 101.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62% 138/221 [00:01<00:00, 102.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67% 149/221 [00:01<00:00, 98.32it/s] \u001b[A\u001b[A\n",
      "\n",
      " 72% 159/221 [00:01<00:00, 94.04it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76% 169/221 [00:01<00:00, 91.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 179/221 [00:01<00:00, 87.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 189/221 [00:01<00:00, 89.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90% 200/221 [00:02<00:00, 93.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 99.99it/s]\n",
      "12/21/2021 11:09:01 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_predictions.json.\n",
      "12/21/2021 11:09:01 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_nbest_predictions.json.\n",
      "12/21/2021 11:09:02 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
      "                                       \n",
      "\u001b[A{'eval_exact_match': 33.93665158371041, 'eval_f1': 58.80784481655893, 'epoch': 6.47}\n",
      " 65% 1500/2320 [08:45<04:27,  3.06it/s]\n",
      "100% 57/57 [00:09<00:00,  8.87it/s]\u001b[A\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 11:09:02,045 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1500\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 11:09:02,050 >> Configuration saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1500/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 11:09:03,066 >> Model weights saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1500/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 11:09:03,071 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 11:09:03,074 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1500/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-21 11:09:05,276 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1000] due to args.save_total_limit\n",
      "{'loss': 0.0836, 'learning_rate': 3.448275862068966e-06, 'epoch': 8.62}\n",
      " 86% 2000/2320 [11:31<01:43,  3.08it/s][INFO|trainer.py:549] 2021-12-21 11:11:48,549 >> The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 11:11:48,551 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 11:11:48,551 >>   Num examples = 912\n",
      "[INFO|trainer.py:2290] 2021-12-21 11:11:48,551 >>   Batch size = 16\n",
      "\n",
      "  0% 0/57 [00:00<?, ?it/s]\u001b[A\n",
      "  4% 2/57 [00:00<00:03, 17.82it/s]\u001b[A\n",
      "  7% 4/57 [00:00<00:04, 11.20it/s]\u001b[A\n",
      " 11% 6/57 [00:00<00:05,  9.95it/s]\u001b[A\n",
      " 14% 8/57 [00:00<00:05,  9.49it/s]\u001b[A\n",
      " 18% 10/57 [00:01<00:05,  9.27it/s]\u001b[A\n",
      " 19% 11/57 [00:01<00:05,  9.18it/s]\u001b[A\n",
      " 21% 12/57 [00:01<00:04,  9.11it/s]\u001b[A\n",
      " 23% 13/57 [00:01<00:04,  9.06it/s]\u001b[A\n",
      " 25% 14/57 [00:01<00:04,  9.02it/s]\u001b[A\n",
      " 26% 15/57 [00:01<00:04,  8.98it/s]\u001b[A\n",
      " 28% 16/57 [00:01<00:04,  8.96it/s]\u001b[A\n",
      " 30% 17/57 [00:01<00:04,  8.88it/s]\u001b[A\n",
      " 32% 18/57 [00:01<00:04,  8.90it/s]\u001b[A\n",
      " 33% 19/57 [00:02<00:04,  8.90it/s]\u001b[A\n",
      " 35% 20/57 [00:02<00:04,  8.88it/s]\u001b[A\n",
      " 37% 21/57 [00:02<00:04,  8.86it/s]\u001b[A\n",
      " 39% 22/57 [00:02<00:03,  8.83it/s]\u001b[A\n",
      " 40% 23/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 42% 24/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 44% 25/57 [00:02<00:03,  8.82it/s]\u001b[A\n",
      " 46% 26/57 [00:02<00:03,  8.85it/s]\u001b[A\n",
      " 47% 27/57 [00:02<00:03,  8.86it/s]\u001b[A\n",
      " 49% 28/57 [00:03<00:03,  8.87it/s]\u001b[A\n",
      " 51% 29/57 [00:03<00:03,  8.88it/s]\u001b[A\n",
      " 53% 30/57 [00:03<00:03,  8.87it/s]\u001b[A\n",
      " 54% 31/57 [00:03<00:02,  8.87it/s]\u001b[A\n",
      " 56% 32/57 [00:03<00:02,  8.86it/s]\u001b[A\n",
      " 58% 33/57 [00:03<00:02,  8.78it/s]\u001b[A\n",
      " 60% 34/57 [00:03<00:02,  8.81it/s]\u001b[A\n",
      " 61% 35/57 [00:03<00:02,  8.82it/s]\u001b[A\n",
      " 63% 36/57 [00:03<00:02,  8.84it/s]\u001b[A\n",
      " 65% 37/57 [00:04<00:02,  8.86it/s]\u001b[A\n",
      " 67% 38/57 [00:04<00:02,  8.86it/s]\u001b[A\n",
      " 68% 39/57 [00:04<00:02,  8.87it/s]\u001b[A\n",
      " 70% 40/57 [00:04<00:01,  8.86it/s]\u001b[A\n",
      " 72% 41/57 [00:04<00:01,  8.83it/s]\u001b[A\n",
      " 74% 42/57 [00:04<00:01,  8.82it/s]\u001b[A\n",
      " 75% 43/57 [00:04<00:01,  8.84it/s]\u001b[A\n",
      " 77% 44/57 [00:04<00:01,  8.86it/s]\u001b[A\n",
      " 79% 45/57 [00:04<00:01,  8.87it/s]\u001b[A\n",
      " 81% 46/57 [00:05<00:01,  8.83it/s]\u001b[A\n",
      " 82% 47/57 [00:05<00:01,  8.85it/s]\u001b[A\n",
      " 84% 48/57 [00:05<00:01,  8.85it/s]\u001b[A\n",
      " 86% 49/57 [00:05<00:00,  8.84it/s]\u001b[A\n",
      " 88% 50/57 [00:05<00:00,  8.83it/s]\u001b[A\n",
      " 89% 51/57 [00:05<00:00,  8.85it/s]\u001b[A\n",
      " 91% 52/57 [00:05<00:00,  8.86it/s]\u001b[A\n",
      " 93% 53/57 [00:05<00:00,  8.87it/s]\u001b[A\n",
      " 95% 54/57 [00:05<00:00,  8.88it/s]\u001b[A\n",
      " 96% 55/57 [00:06<00:00,  8.88it/s]\u001b[A\n",
      " 98% 56/57 [00:06<00:00,  8.88it/s]\u001b[A\n",
      "100% 57/57 [00:06<00:00,  8.80it/s]\u001b[A12/21/2021 11:11:55 - INFO - utils_qa - Post-processing 221 example predictions split into 912 features.\n",
      "\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5% 10/221 [00:00<00:02, 97.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10% 21/221 [00:00<00:01, 103.63it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16% 36/221 [00:00<00:01, 123.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22% 49/221 [00:00<00:01, 122.12it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28% 62/221 [00:00<00:01, 118.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33% 74/221 [00:00<00:01, 110.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39% 86/221 [00:00<00:01, 107.70it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44% 97/221 [00:00<00:01, 107.82it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49% 108/221 [00:00<00:01, 106.07it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54% 119/221 [00:01<00:00, 102.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59% 130/221 [00:01<00:00, 102.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64% 141/221 [00:01<00:00, 97.59it/s] \u001b[A\u001b[A\n",
      "\n",
      " 68% 151/221 [00:01<00:00, 93.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73% 161/221 [00:01<00:00, 90.56it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77% 171/221 [00:01<00:00, 88.79it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81% 180/221 [00:01<00:00, 88.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86% 191/221 [00:01<00:00, 93.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91% 202/221 [00:01<00:00, 96.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "100% 221/221 [00:02<00:00, 101.59it/s]\n",
      "12/21/2021 11:11:58 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_predictions.json.\n",
      "12/21/2021 11:11:58 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_nbest_predictions.json.\n",
      "12/21/2021 11:11:58 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
      "                                       \n",
      "\u001b[A{'eval_exact_match': 31.67420814479638, 'eval_f1': 57.801933434130724, 'epoch': 8.62}\n",
      " 86% 2000/2320 [11:41<01:43,  3.08it/s]\n",
      "100% 57/57 [00:09<00:00,  8.80it/s]\u001b[A\n",
      "                                   \u001b[A[INFO|trainer.py:2037] 2021-12-21 11:11:58,162 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-2000\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 11:11:58,172 >> Configuration saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-2000/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 11:11:59,317 >> Model weights saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-2000/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 11:11:59,322 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-2000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 11:11:59,329 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-2000/special_tokens_map.json\n",
      "[INFO|trainer.py:2115] 2021-12-21 11:12:01,400 >> Deleting older checkpoint [/content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/checkpoint-1500] due to args.save_total_limit\n",
      "100% 2320/2320 [13:28<00:00,  3.37it/s][INFO|trainer.py:1429] 2021-12-21 11:13:45,496 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 808.6138, 'train_samples_per_second': 45.844, 'train_steps_per_second': 2.869, 'train_loss': 0.4102463512585081, 'epoch': 10.0}\n",
      "100% 2320/2320 [13:28<00:00,  2.87it/s]\n",
      "[INFO|trainer.py:2037] 2021-12-21 11:13:45,505 >> Saving model checkpoint to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/\n",
      "[INFO|configuration_utils.py:425] 2021-12-21 11:13:45,522 >> Configuration saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/config.json\n",
      "[INFO|modeling_utils.py:1072] 2021-12-21 11:13:46,456 >> Model weights saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2043] 2021-12-21 11:13:46,460 >> tokenizer config file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2049] 2021-12-21 11:13:46,463 >> Special tokens file saved in /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/special_tokens_map.json\n",
      "***** train metrics *****\n",
      "  epoch                    =       10.0\n",
      "  train_loss               =     0.4102\n",
      "  train_runtime            = 0:13:28.61\n",
      "  train_samples            =       3707\n",
      "  train_samples_per_second =     45.844\n",
      "  train_steps_per_second   =      2.869\n",
      "12/21/2021 11:13:46 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:549] 2021-12-21 11:13:46,525 >> The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForQuestionAnswering.forward` and have been ignored: example_id, offset_mapping.\n",
      "[INFO|trainer.py:2285] 2021-12-21 11:13:46,527 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:2287] 2021-12-21 11:13:46,527 >>   Num examples = 912\n",
      "[INFO|trainer.py:2290] 2021-12-21 11:13:46,527 >>   Batch size = 16\n",
      "100% 57/57 [00:06<00:00,  8.88it/s]12/21/2021 11:13:53 - INFO - utils_qa - Post-processing 221 example predictions split into 912 features.\n",
      "\n",
      "  0% 0/221 [00:00<?, ?it/s]\u001b[A\n",
      "  5% 10/221 [00:00<00:02, 96.24it/s]\u001b[A\n",
      "  9% 20/221 [00:00<00:02, 97.08it/s]\u001b[A\n",
      " 15% 34/221 [00:00<00:01, 113.48it/s]\u001b[A\n",
      " 21% 47/221 [00:00<00:01, 119.52it/s]\u001b[A\n",
      " 27% 59/221 [00:00<00:01, 116.20it/s]\u001b[A\n",
      " 32% 71/221 [00:00<00:01, 109.68it/s]\u001b[A\n",
      " 38% 83/221 [00:00<00:01, 104.96it/s]\u001b[A\n",
      " 43% 94/221 [00:00<00:01, 98.48it/s] \u001b[A\n",
      " 47% 104/221 [00:01<00:01, 95.73it/s]\u001b[A\n",
      " 52% 114/221 [00:01<00:01, 92.38it/s]\u001b[A\n",
      " 56% 124/221 [00:01<00:01, 78.54it/s]\u001b[A\n",
      " 60% 133/221 [00:01<00:01, 76.74it/s]\u001b[A\n",
      " 64% 141/221 [00:01<00:01, 74.46it/s]\u001b[A\n",
      " 67% 149/221 [00:01<00:01, 67.36it/s]\u001b[A\n",
      " 71% 156/221 [00:01<00:00, 65.27it/s]\u001b[A\n",
      " 74% 163/221 [00:01<00:00, 62.34it/s]\u001b[A\n",
      " 77% 170/221 [00:02<00:00, 59.73it/s]\u001b[A\n",
      " 80% 177/221 [00:02<00:00, 59.16it/s]\u001b[A\n",
      " 83% 183/221 [00:02<00:00, 58.62it/s]\u001b[A\n",
      " 86% 191/221 [00:02<00:00, 62.05it/s]\u001b[A\n",
      " 90% 199/221 [00:02<00:00, 64.98it/s]\u001b[A\n",
      " 93% 206/221 [00:02<00:00, 65.80it/s]\u001b[A\n",
      " 96% 213/221 [00:02<00:00, 65.77it/s]\u001b[A\n",
      "100% 221/221 [00:02<00:00, 77.50it/s]\n",
      "12/21/2021 11:13:56 - INFO - utils_qa - Saving predictions to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_predictions.json.\n",
      "12/21/2021 11:13:56 - INFO - utils_qa - Saving nbest_preds to /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/eval_nbest_predictions.json.\n",
      "12/21/2021 11:13:56 - INFO - datasets.metric - Removing /root/.cache/huggingface/metrics/squad/default/default_experiment-1-0.arrow\n",
      "100% 57/57 [00:10<00:00,  5.56it/s]\n",
      "***** eval metrics *****\n",
      "  epoch            =    10.0\n",
      "  eval_exact_match = 31.2217\n",
      "  eval_f1          = 56.8194\n",
      "  eval_samples     =     912\n",
      "[INFO|modelcard.py:456] 2021-12-21 11:13:57,252 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}}\n"
     ]
    }
   ],
   "source": [
    "!python /content/transformers/examples/pytorch/question-answering/run_qa.py \\\n",
    "  --model_name_or_path distilbert-base-cased-distilled-squad \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --train_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_train.json\" \\\n",
    "  --validation_file \"/content/drive/MyDrive/FinLitQA/flitqa/finlitqa_val.json\" \\\n",
    "  --evaluation_strategy steps \\\n",
    "  --save_strategy steps \\\n",
    "  --weight_decay 0.01 \\\n",
    "  --warmup_ratio 0.2 \\\n",
    "  --per_device_eval_batch_size 16 \\\n",
    "  --per_device_train_batch_size 16 \\\n",
    "  --overwrite_output_dir \\\n",
    "  --eval_steps 500 \\\n",
    "  --save_steps 500 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 10 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --save_total_limit 1 \\\n",
    "  --output_dir /content/drive/MyDrive/Final_Models/distilbert-base-cased-distilled-sq-flit-10/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Fine Tuning with Custom dataset_script_2 Epochs.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
